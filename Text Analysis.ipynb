{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAfTIq_m7e57"
   },
   "source": [
    "# Text Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ioC5XKAfsJVn",
    "outputId": "4d2037f4-cc8f-4f3f-e70b-9c656d33f451"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZT_eeKNeAxq"
   },
   "source": [
    "# Part 1: Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuxYmXNt8Kol"
   },
   "source": [
    "## 1. Import libraries\n",
    "In this assignment, we are going to use two different statistical models for text classification. Those are Logistic Regression, Naive Bayes, Support Vector Machine, and RandmForest. \n",
    "The packages to reach this objective are the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZbyUuGoG7xJE",
    "outputId": "4f1ad1da-153f-4278-e827-c2bb874255f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize    \n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB,BernoulliNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from random import sample\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#!pip3 install gensim\n",
    "from gensim.models import Phrases\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from nltk.stem import PorterStemmer # Stem\n",
    "#!pip install pyLDAvis==2.1.2\n",
    "import pyLDAvis.gensim\n",
    "from nltk.corpus import stopwords\n",
    "import logging\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3i9yPlP8g85"
   },
   "source": [
    "## 2. Import data\n",
    "The data used in this assignment was gathered from the popular academic website arXiv.org for articles tagged as\n",
    "computer science content (though some of these are in mathematics or physics categories)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkMcJ1GeilHy"
   },
   "source": [
    "### 2.1 Train data\n",
    "The documents written between 1990 and 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "L54eoHfF8gM7",
    "outputId": "1af9a7af-ba84-479d-b00b-0fd81d165ed6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>InfoTheory</th>\n",
       "      <th>CompVis</th>\n",
       "      <th>Math</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cs-9301111</td>\n",
       "      <td>arxiv.org/abs/cs/9301111</td>\n",
       "      <td>1989-12-31</td>\n",
       "      <td>Nested satisfiability</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Nested satisfiability A special case of the s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cs-9301112</td>\n",
       "      <td>arxiv.org/abs/cs/9301112</td>\n",
       "      <td>1990-03-31</td>\n",
       "      <td>A note on digitized angles</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A note on digitized angles We study the confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cs-9301113</td>\n",
       "      <td>arxiv.org/abs/cs/9301113</td>\n",
       "      <td>1991-07-31</td>\n",
       "      <td>Textbook examples of recursion</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Textbook examples of recursion We discuss pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  ...                                           Abstract\n",
       "0  cs-9301111  ...   Nested satisfiability A special case of the s...\n",
       "1  cs-9301112  ...   A note on digitized angles We study the confi...\n",
       "2  cs-9301113  ...   Textbook examples of recursion We discuss pro...\n",
       "\n",
       "[3 rows x 8 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"/content/drive/My Drive/Assig1-FIT5212/axcs_train.csv\")\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j8-w7hLrHt-e"
   },
   "source": [
    "### 2.2 Test data\n",
    "The documents written between 2015 and 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "n-fSj9cPH3Yu",
    "outputId": "0cf925ad-5cce-4660-e51a-9e1ac542af24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>InfoTheory</th>\n",
       "      <th>CompVis</th>\n",
       "      <th>Math</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no-150100335</td>\n",
       "      <td>arxiv.org/abs/1501.00335</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>A Data Transparency Framework for Mobile Appli...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A Data Transparency Framework for Mobile Appl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no-14024178</td>\n",
       "      <td>arxiv.org/abs/1402.4178</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>A reclaimer scheduling problem arising in coal...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>A reclaimer scheduling problem arising in coa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no-150100263</td>\n",
       "      <td>arxiv.org/abs/1501.00263</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Communication-Efficient Distributed Optimizati...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Communication-Efficient Distributed Optimizat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  ...                                           Abstract\n",
       "0  no-150100335  ...   A Data Transparency Framework for Mobile Appl...\n",
       "1   no-14024178  ...   A reclaimer scheduling problem arising in coa...\n",
       "2  no-150100263  ...   Communication-Efficient Distributed Optimizat...\n",
       "\n",
       "[3 rows x 8 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"/content/drive/My Drive/Assig1-FIT5212/axcs_test.csv\")\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjayRjByImK2"
   },
   "source": [
    "## 3. Create Documents and Labels\n",
    "A document has three different classes are InfoTheory, CompVis and Math. These can occur in any combination, so an\n",
    "article could be all three at once, two, one or none. The job is to build text classifiers that predict each of these three classes individually using the Abstract field. That is why we drop the other columns that are useless for this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbKxAWufgIKM"
   },
   "source": [
    "### 3.1 Data Wrangling\n",
    "Before we create the documents and the labels (lists) we have to identify that all the values are valid: No NULL, NA or NaN in the datasets.\n",
    "\n",
    "From the training dataset no value was removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zDUK80hAdnjV",
    "outputId": "820f5d58-5325-406b-e449-e2906fb833d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training papers before removing NaN values: 54,731\n",
      "\n",
      "Number of training papers after removing NaN values: 54,731\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of training papers before removing NaN values: {:,}\\n'.format(df_train.shape[0]))\n",
    "df_train.dropna(axis=0, inplace=True)\n",
    "print('Number of training papers after removing NaN values: {:,}\\n'.format(df_train.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v3fa9eS5gHPP"
   },
   "source": [
    "From the testing dataset one record was removed. The one corresponding to the document **no-160308961**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 79
    },
    "id": "BAZQPMAXgs2a",
    "outputId": "e4645d1d-cf75-45af-838a-8a8b24d725db"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>InfoTheory</th>\n",
       "      <th>CompVis</th>\n",
       "      <th>Math</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19619</th>\n",
       "      <td>no-160308961</td>\n",
       "      <td>arxiv.org/abs/1603.08961</td>\n",
       "      <td>2016-03-29</td>\n",
       "      <td>Betting and Belief: Prediction Markets and Att...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                       URL  ... Math Abstract\n",
       "19619  no-160308961  arxiv.org/abs/1603.08961  ...  NaN      NaN\n",
       "\n",
       "[1 rows x 8 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2HSaWFs0ejOK",
    "outputId": "a9e50bde-20b3-44d7-dbe0-8181c4400666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of testing papers before removing NaN values: 19,679\n",
      "\n",
      "Number of testing papers after removing NaN values: 19,678\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Number of testing papers before removing NaN values: {:,}\\n'.format(df_test.shape[0]))\n",
    "df_test.dropna(axis=0, inplace=True) # Removing NaN values\n",
    "print('Number of testing papers after removing NaN values: {:,}\\n'.format(df_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8B_69VCBCQiQ"
   },
   "source": [
    "From the preview of the test data, we could observe that the labels are `float` and not `int`. Therefore, we proceed to transform them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "id": "7Rs71cpECQ93",
    "outputId": "f57d4abd-abbd-4e3d-a7e5-33b6764a0aec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>URL</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>InfoTheory</th>\n",
       "      <th>CompVis</th>\n",
       "      <th>Math</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no-150100335</td>\n",
       "      <td>arxiv.org/abs/1501.00335</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>A Data Transparency Framework for Mobile Appli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A Data Transparency Framework for Mobile Appl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no-14024178</td>\n",
       "      <td>arxiv.org/abs/1402.4178</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>A reclaimer scheduling problem arising in coal...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A reclaimer scheduling problem arising in coa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>no-150100263</td>\n",
       "      <td>arxiv.org/abs/1501.00263</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Communication-Efficient Distributed Optimizati...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Communication-Efficient Distributed Optimizat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  ...                                           Abstract\n",
       "0  no-150100335  ...   A Data Transparency Framework for Mobile Appl...\n",
       "1   no-14024178  ...   A reclaimer scheduling problem arising in coa...\n",
       "2  no-150100263  ...   Communication-Efficient Distributed Optimizat...\n",
       "\n",
       "[3 rows x 8 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[['Math', 'CompVis', 'InfoTheory']] = np.array(df_test[['Math', 'CompVis', 'InfoTheory']], dtype=int)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0vOyYpgdnLn"
   },
   "source": [
    "### 3.2 Documents\n",
    "The variables `trainDocs` and `testDocs` are lists which each element is an abstract of a different paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "rUS9wMakAYRe"
   },
   "outputs": [],
   "source": [
    "trainDocs = df_train.Abstract.tolist() # Store the abstracts of training as an element of a list\n",
    "testDocs = df_test.Abstract.tolist() # Store the abstracts of training as an element of a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUuKOcnVJ3I_"
   },
   "source": [
    "### 3.3 Labels\n",
    "We created six different variables for three different labels of two different dataframes. Two list for `InfoTheory` label, two for `CompVis`, and another two for `Math`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "CuIPMkAfJ1H6"
   },
   "outputs": [],
   "source": [
    "trainLabelInfo = np.asarray(df_train.InfoTheory.to_list()) # Train dataset InfoTheory\n",
    "trainLabelComp = np.asarray(df_train.CompVis.to_list()) # Train dataset CompVis\n",
    "trainLabelMath = np.asarray(df_train.Math.to_list()) # Train dataset Math\n",
    "testLabelInfo = np.asarray(df_test.InfoTheory.to_list()) # Test dataset InfoTheory\n",
    "testLabelComp = np.asarray(df_test.CompVis.to_list()) # Test dataset CompVis\n",
    "testLabelMath = np.asarray(df_test.Math.to_list()) # Test dataset Math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nr22jnF6oM2c"
   },
   "source": [
    "## 4. Text Preprocessing\n",
    "One of the main tasks of the assignment is to compare how two different preprocessing methods perform in a model and understand if there is any tokenization method in particular that could improve the performance of a model. \n",
    "\n",
    "That is why in order to get the same preprocessing method for each model `RNN` and `LinearSVC` we are going to build a new csv file with the abstracts already tokenized. \n",
    "\n",
    "The reason why we do that instead of tokenizing them with the **vectorizer** function in LinearSVC and **spaCy** in RNN model. Is that we can not set the same parameters in both cases, and it could be that by using these preprocessing methods we get different results. Therefore, have 4 different preprocessing results instead of 2 as it was required in the assignment.\n",
    "\n",
    "\n",
    "Before apply different method first we convert al tokens to lower case as it is required for different preprofcessing methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "iRXb9gPtoiOz"
   },
   "outputs": [],
   "source": [
    "train_abstracts1 = [] # List to store the train abstracts with preprocessing method #1\n",
    "test_abstracts1 = [] # List to store the test abstracts with preprocessing method #1\n",
    "train_abstracts2 = [] # List to store the train abstracts with preprocessing method #2\n",
    "test_abstracts2 = [] # List to store the test abstracts with preprocessing method #2\n",
    "\n",
    "for idx in range(len(trainDocs)):\n",
    "    train_abstracts1.append(trainDocs[idx].lower())  # Convert to lowercase.\n",
    "    train_abstracts2.append(trainDocs[idx].lower())  # Convert to lowercase.\n",
    "\n",
    "for idx in range(len(testDocs)):\n",
    "    test_abstracts1.append(testDocs[idx].lower())  # Convert to lowercase.  \n",
    "    test_abstracts2.append(testDocs[idx].lower())  # Convert to lowercase. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLm9yZNYrQY8"
   },
   "source": [
    "After converting every word to lower in each list, we proceed to preprocess them in two different ways as we did before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxObI9aJrZx7"
   },
   "source": [
    "### 4.1. Preprocessing #1\n",
    "   - Convert every word to lower case\n",
    "   - Tokenize each words with the following regex: `r'\\w+'`\n",
    "   - Remove numbers\n",
    "   - Remove english stop words\n",
    "   - Remove words with length equal 1\n",
    "   - Stem every words of the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "RLLDpB7Nrf0m"
   },
   "outputs": [],
   "source": [
    "# Tokenize every document of the dataset\n",
    "tokenizer = RegexpTokenizer(r'\\w+') # Tokenizer that matches every element of the corpus\n",
    "\n",
    "for idx in range(len(train_abstracts1)):\n",
    "    train_abstracts1[idx] = tokenizer.tokenize(train_abstracts1[idx])  # Split into words.\n",
    "\n",
    "for idx in range(len(test_abstracts1)):\n",
    "    test_abstracts1[idx] = tokenizer.tokenize(test_abstracts1[idx])  # Split into words.\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "train_abstracts1 = [[token for token in doc if not token.isnumeric()] for doc in train_abstracts1]\n",
    "test_abstracts1 = [[token for token in doc if not token.isnumeric()] for doc in test_abstracts1]\n",
    "\n",
    "# Remove numbers, but not words that contain numbers.\n",
    "stop_words = set(stopwords.words('english')) \n",
    "train_abstracts1 = [[token for token in doc if not token in stop_words] for doc in train_abstracts1]\n",
    "test_abstracts1 = [[token for token in doc if not token in stop_words] for doc in test_abstracts1]\n",
    "\n",
    "# Remove words that are only one character.\n",
    "train_abstracts1 = [[token for token in doc if len(token) > 1] for doc in train_abstracts1]\n",
    "test_abstracts1 = [[token for token in doc if len(token) > 1] for doc in test_abstracts1]\n",
    "\n",
    "# Steeming of all the tokens\n",
    "stemmer = PorterStemmer() # Porter Stemmer\n",
    "train_abstracts1 = [['{1}'.format(token, stemmer.stem(token)) for token in doc] for doc in train_abstracts1]\n",
    "test_abstracts1 = [['{1}'.format(token, stemmer.stem(token)) for token in doc] for doc in test_abstracts1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b1N-5l6wyrGS"
   },
   "source": [
    "### 4.2 Preprocessing #2\n",
    "   - Convert every word to lower case\n",
    "   - Tokenize each words with the following regex: `r'[a-z0-9]+'`\n",
    "   - Remove words with length equal 1\n",
    "   - Lematize every words of the corpus\n",
    "   - Create bigrams that appear at least 100 times in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BPYhNE_Tyr-X",
    "outputId": "f67f70b9-b552-4ced-e736-e35f304dd1f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "# Tokenize every document of the dataset\n",
    "tokenizer = RegexpTokenizer(r'[a-z0-9]+') # Tokenizer that matches every element of the corpus\n",
    "\n",
    "for idx in range(len(train_abstracts2)):\n",
    "    train_abstracts2[idx] = tokenizer.tokenize(train_abstracts2[idx])  # Split into words.\n",
    "\n",
    "for idx in range(len(test_abstracts2)):\n",
    "    test_abstracts2[idx] = tokenizer.tokenize(test_abstracts2[idx])  # Split into words.\n",
    "\n",
    "\n",
    "# Remove words that are only one character.\n",
    "train_abstracts2 = [[token for token in doc if len(token) > 1] for doc in train_abstracts2]\n",
    "test_abstracts2 = [[token for token in doc if len(token) > 1] for doc in test_abstracts2]\n",
    "\n",
    "# Lemmatize the documents.\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train_abstracts2 = [[lemmatizer.lemmatize(token) for token in doc] for doc in train_abstracts2]\n",
    "test_abstracts2 = [[lemmatizer.lemmatize(token) for token in doc] for doc in test_abstracts2]\n",
    "\n",
    "# Add bigrams and trigrams to docs (only ones that appear 20 times or more).\n",
    "train_bigram = Phrases(train_abstracts2, min_count=100)\n",
    "test_bigram = Phrases(test_abstracts2, min_count=100)\n",
    "\n",
    "for idx in range(len(train_abstracts2)):\n",
    "    for token in train_bigram[train_abstracts2[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            train_abstracts2[idx].append(token)\n",
    "\n",
    "for idx in range(len(test_abstracts2)):\n",
    "    for token in test_bigram[test_abstracts2[idx]]:\n",
    "        if '_' in token:\n",
    "            # Token is a bigram, add to document.\n",
    "            test_abstracts2[idx].append(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jxiAgtlB6DCN"
   },
   "source": [
    "### 4.3 Comparison between Preprocesing Methods\n",
    "After performing the tokenization with two different method we can observe the words that are in one corpus but not in the other one. In this comparisson it is pretty clear the difference between Stemming and Lemmatization with words like:\n",
    "   - claus vs. clause\n",
    "   - assum vs. assuming\n",
    "   - conveni vs. convenient\n",
    "\n",
    "Also we can observe that one method has bigrams and the other no, therefore we see words in `train_abstracts2` that we do not see in `train_abstracts1` like:\n",
    "   - have_been\n",
    "   - special_case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wY6v_HfMp1Yv",
    "outputId": "9f798c65-37d6-49af-9b4f-9ca33b6b366f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['assum', 'claus', 'conveni', 'hierarch', 'nest', 'repres',\n",
       "       'satisfi', 'solvabl', 'structur'], dtype='<U8')"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(train_abstracts1[0], train_abstracts2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vJ22GN47pSBb",
    "outputId": "d93c83ef-da4e-438e-df97-e1cc0f533536"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['assuming', 'be', 'been', 'clause', 'convenient', 'have',\n",
       "       'have_been', 'hierarchical', 'in', 'is', 'nested', 'of',\n",
       "       'represented', 'satisfiability', 'solvable', 'special_case',\n",
       "       'structure', 'that', 'the', 'to', 'which'], dtype='<U14')"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.setdiff1d(train_abstracts2[0], train_abstracts1[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QB9HQTKIpPzr"
   },
   "source": [
    "### 4.4 Export Tokenization\n",
    "After we create the tokens of each abstract with the same parameters shown before, we create different dataframes with all the information required to perform the `RNN` adn the `LinearSVC` model. That is why we build an csv file with the abstracts preprocessed as shown before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "RofC56MG8dNl"
   },
   "outputs": [],
   "source": [
    "# Convert tokens to strings again\n",
    "train_abstracts1 = [\" \".join(tokens) for tokens in train_abstracts1]\n",
    "train_abstracts2 = [\" \".join(tokens) for tokens in train_abstracts2]\n",
    "test_abstracts1 = [\" \".join(tokens) for tokens in test_abstracts1]\n",
    "test_abstracts2 = [\" \".join(tokens) for tokens in test_abstracts2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9HvJVW88u7C"
   },
   "source": [
    "After converting the tokens to string again, we store the information in different dataframes to export them later as csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ_Fb_vY9Me0"
   },
   "source": [
    "**Train Dataset with Preprocessing Method #1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "YROUPU3f8Etq",
    "outputId": "782b553a-f416-48a7-b3be-b3a64b1197ca"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InfoTheory</th>\n",
       "      <th>CompVis</th>\n",
       "      <th>Math</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nest satisfi special case satisfi problem clau...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>note digit angl studi configur pixel occur two...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   InfoTheory  CompVis  Math                                           Abstract\n",
       "0           0        0     0  nest satisfi special case satisfi problem clau...\n",
       "1           0        0     0  note digit angl studi configur pixel occur two..."
      ]
     },
     "execution_count": 71,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_prep_1 = pd.DataFrame(list(zip(trainLabelInfo, trainLabelComp, \n",
    "                                        trainLabelMath, train_abstracts1)),\n",
    "                   columns=['InfoTheory', 'CompVis', 'Math','Abstract'])\n",
    "\n",
    "df_train_prep_1[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVGH7mnf9ita"
   },
   "source": [
    "**Train Dataset with Preprocessing Method #2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "7zwtKD_w9BnX",
    "outputId": "0cafbdda-9fb6-43fe-c8b3-510fa693a536"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InfoTheory</th>\n",
       "      <th>CompVis</th>\n",
       "      <th>Math</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>nested satisfiability special case of the sati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>note on digitized angle we study the configura...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   InfoTheory  CompVis  Math                                           Abstract\n",
       "0           0        0     0  nested satisfiability special case of the sati...\n",
       "1           0        0     0  note on digitized angle we study the configura..."
      ]
     },
     "execution_count": 72,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_prep_2 = pd.DataFrame(list(zip(trainLabelInfo, trainLabelComp, \n",
    "                                        trainLabelMath, train_abstracts2)),\n",
    "                   columns=['InfoTheory', 'CompVis', 'Math','Abstract'])\n",
    "\n",
    "df_train_prep_2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PWdxZbk9kvn"
   },
   "source": [
    "**Test Dataset with Preprocessing Method #1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "rrZ-dcJj9EWa",
    "outputId": "0145a30e-9e5c-4551-e6b6-514fe74e3239"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InfoTheory</th>\n",
       "      <th>CompVis</th>\n",
       "      <th>Math</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data transpar framework mobil applic today mob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reclaim schedul problem aris coal stockyard ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   InfoTheory  CompVis  Math                                           Abstract\n",
       "0           0        0     0  data transpar framework mobil applic today mob...\n",
       "1           0        0     0  reclaim schedul problem aris coal stockyard ma..."
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_prep_1 = pd.DataFrame(list(zip(testLabelInfo, testLabelComp, \n",
    "                                        testLabelMath, test_abstracts1)),\n",
    "                   columns=['InfoTheory', 'CompVis', 'Math','Abstract'])\n",
    "\n",
    "df_test_prep_1[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EMQ91ixW9nSj"
   },
   "source": [
    "**Test Dataset with Preprocessing Method #1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "id": "uGxZR8j69EKe",
    "outputId": "b667ceaf-b8eb-4659-d31e-66bb246b0ca4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InfoTheory</th>\n",
       "      <th>CompVis</th>\n",
       "      <th>Math</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>data transparency framework for mobile applica...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>reclaimer scheduling problem arising in coal s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   InfoTheory  CompVis  Math                                           Abstract\n",
       "0           0        0     0  data transparency framework for mobile applica...\n",
       "1           0        0     0  reclaimer scheduling problem arising in coal s..."
      ]
     },
     "execution_count": 74,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_prep_2 = pd.DataFrame(list(zip(testLabelInfo, testLabelComp, \n",
    "                                        testLabelMath, test_abstracts2)),\n",
    "                   columns=['InfoTheory', 'CompVis', 'Math','Abstract'])\n",
    "\n",
    "df_test_prep_2[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROZsnIBd-Hq9"
   },
   "source": [
    "After we build these dataframes we export them to a csv file to read it, with the RNN algorithm and Linear SVC. \n",
    "\n",
    "The reason why we have 6 different dataframes is because we have one dataframe for each combination of preprocessing method, and size of dataset for train dataset. Besides we have two different preprocessing methods for testing dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "XB2fhvmF-fWG"
   },
   "outputs": [],
   "source": [
    "df_train_prep_1.to_csv(\"./train_prep_1.csv\", index=False)\n",
    "df_test_prep_1.to_csv(\"./test_prep_1.csv\", index=False)\n",
    "df_train_prep_2.to_csv(\"./train_prep_2.csv\", index=False)\n",
    "df_test_prep_2.to_csv(\"./test_prep_2.csv\", index=False)\n",
    "df_train_prep_1[:1000].to_csv(\"./train_prep_1_1000.csv\", index=False)\n",
    "df_train_prep_2[:1000].to_csv(\"./train_prep_2_1000.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z5mjsaMnkDK4"
   },
   "source": [
    "## 5. Statistical Model\n",
    "After perform the preprocessing method, we proceed to perform the classification of abstracts in three different labels: `InfoTheory`, `CompVis` and `Math`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bZPaurWXoYzg"
   },
   "source": [
    "### 5.1 Vectorizers\n",
    "After create new documents the only tokenizer that we need is split the words by space. \n",
    "Therefore, we create four different vectorizers for each combination of parameters: \n",
    "- Size of Dataset\n",
    "- Preprocessing Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "OwRvKrmihrrS"
   },
   "outputs": [],
   "source": [
    "vectorizer_1_all = TfidfVectorizer()\n",
    "vectorizer_1_1000 = TfidfVectorizer()\n",
    "vectorizer_2_all = TfidfVectorizer()\n",
    "vectorizer_2_1000 = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlEHE0KKMW63"
   },
   "source": [
    "### 5.2 Transformation of datasets\n",
    "Now we proceed to transform the eight different abstracts that we have:\n",
    "\n",
    "**Preprocessing Method #1 and All Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYjGq3_gsJVy",
    "outputId": "dc7a2182-3c84-48ed-e89f-e7a88c7d8425"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 52,229\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_1_all = vectorizer_1_all.fit_transform(train_abstracts1)\n",
    "x_test_1_all = vectorizer_1_all.transform(test_abstracts1)\n",
    "\n",
    "print('Number of tokens: {:,}\\n'.format(len(vectorizer_1_all.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1GJgfXs4M0s6"
   },
   "source": [
    "\n",
    "**Preprocessing Method #1 and 1000 Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5AQ3WSm7CDZK",
    "outputId": "9749fb85-5d21-4b91-efdb-faaa22e45602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 4,432\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_1_1000 = vectorizer_1_1000.fit_transform(train_abstracts1[:1000])\n",
    "x_test_1_1000 = vectorizer_1_1000.transform(test_abstracts1)\n",
    "\n",
    "print('Number of tokens: {:,}\\n'.format(len(vectorizer_1_1000.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C-bQHapOsU9"
   },
   "source": [
    "**Preprocessing Method #2 and All Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DLdXu_l9OtA-",
    "outputId": "b091600a-4b47-42b7-d9df-117f776d501d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 69,337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_2_all = vectorizer_2_all.fit_transform(train_abstracts2)\n",
    "x_test_2_all = vectorizer_2_all.transform(test_abstracts2)\n",
    "\n",
    "print('Number of tokens: {:,}\\n'.format(len(vectorizer_2_all.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8SvtOAFOtlc"
   },
   "source": [
    "**Preprocessing Method #2 and 1000 Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjESVgEAOt-z",
    "outputId": "01dcec98-b0c2-4b9a-90f5-a304e51d76e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 7,113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train_2_1000 = vectorizer_2_1000.fit_transform(train_abstracts2[:1000])\n",
    "x_test_2_1000 = vectorizer_2_1000.transform(test_abstracts2)\n",
    "\n",
    "print('Number of tokens: {:,}\\n'.format(len(vectorizer_2_1000.get_feature_names())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B-c9dxp7sJV0"
   },
   "source": [
    "Analysing just the training dataset, we can observe that the Preprocessing Method # 2 creates a list with more tokens, compared with the Preprocessing Method #2. The difference between these two is that even though in the first method we removed the stopwords, in the second one we added **bigrams**, and therefore, adding more words to the corpus. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PAcyRZ7sJV1"
   },
   "source": [
    "### 5.3 Model Selection\n",
    "To select the best statitical model with this data, we are going to perform a 5-fold cross validation with `x_train_1_all` testing against `InfoTheory Label`, and afterwards we pick the best one. The models that are going to be tested are:\n",
    "   - Logistic Regression\n",
    "   - Naive Bayes Bernoulli\n",
    "   - Linear Support Vector Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovGazFYksJV1"
   },
   "source": [
    "**Cross validation**\n",
    "As this process takes time, we are going to perform it once. With just one configuration out of 24 possible configurations shown as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q42LH4GEAYok"
   },
   "outputs": [],
   "source": [
    "models = [LogisticRegression(), BernoulliNB(), LinearSVC()] # Models chosen\n",
    "CV = 5 # 5_fold cross validation\n",
    "\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models))) # Dataframe to store the results\n",
    "entries = []\n",
    "\n",
    "for model in models:\n",
    "     model_name = model.__class__.__name__\n",
    "     accuracies = cross_val_score(model, x_train_1_all, trainLabelInfo, scoring='accuracy', cv=CV)\n",
    "     print(accuracies)\n",
    "     for fold_idx, accuracy in enumerate(accuracies):\n",
    "          entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "id": "UwVpZyi12aRB",
    "outputId": "5f9eeb5d-5ac9-4416-f828-f65380e8b5d9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x='model_name', y='accuracy', data=cv_df)\n",
    "sns.stripplot(x='model_name', y='accuracy', data=cv_df, \n",
    "              size=8, jitter=True, edgecolor=\"gray\", linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4OLA7FViHFjJ"
   },
   "source": [
    "One fold of LogisticRegression, was the model that performed the best with this data. Even though in general LinearSVC is the one with the highest accuracy, approximately 95.5%. That is why we are going to choose it.\n",
    "\n",
    "The Random Forest model was the model that besides to take the longest to run, it also is the one with worst performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXmntIvrsJV2"
   },
   "source": [
    "### 5.4 Prediction of Label\n",
    "Now that we selected Linear SVC as our statistical model, we are going to predict every label required and store the results of each measurement in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QRe5rqPZv4Uu"
   },
   "outputs": [],
   "source": [
    "LinearSVC_results = pd.DataFrame(columns=['Label', 'Prep', 'Size', 'Accuracy', \"Precision\", \"Recall\", \"F1score\"])\n",
    "\n",
    "models = [LinearSVC()] # Model chosen\n",
    "\n",
    "# Stores the abstracts of the eight different combinations of parameters\n",
    "combinations = [(\"InfoTheory\", \"Prep #1\", \"All Rows\", x_train_1_all, x_test_1_all, trainLabelInfo, testLabelInfo),\n",
    "                (\"InfoTheory\", \"Prep #1\", \"1000 Rows\", x_train_1_1000, x_test_1_1000, trainLabelInfo[:1000], testLabelInfo),\n",
    "                (\"InfoTheory\", \"Prep #2\", \"All Rows\", x_train_2_all, x_test_2_all, trainLabelInfo, testLabelInfo),\n",
    "                (\"InfoTheory\", \"Prep #2\", \"1000 Rows\", x_train_2_1000, x_test_2_1000, trainLabelInfo[:1000], testLabelInfo),\n",
    "                (\"CompVis\", \"Prep #1\", \"All Rows\", x_train_1_all, x_test_1_all, trainLabelComp, testLabelComp),\n",
    "                (\"CompVis\", \"Prep #1\", \"1000 Rows\", x_train_1_1000, x_test_1_1000, trainLabelComp[:1000], testLabelComp),\n",
    "                (\"CompVis\", \"Prep #2\", \"All Rows\", x_train_2_all, x_test_2_all, trainLabelComp, testLabelComp),\n",
    "                (\"CompVis\", \"Prep #2\", \"1000 Rows\", x_train_2_1000, x_test_2_1000, trainLabelComp[:1000], testLabelComp),\n",
    "                (\"Math\", \"Prep #1\", \"All Rows\", x_train_1_all, x_test_1_all, trainLabelMath, testLabelMath),\n",
    "                (\"Math\", \"Prep #1\", \"1000 Rows\", x_train_1_1000, x_test_1_1000, trainLabelMath[:1000], testLabelMath),\n",
    "                (\"Math\", \"Prep #2\", \"All Rows\", x_train_2_all, x_test_2_all, trainLabelMath, testLabelMath),\n",
    "                (\"Math\", \"Prep #2\", \"1000 Rows\", x_train_2_1000, x_test_2_1000, trainLabelMath[:1000], testLabelMath)]\n",
    "\n",
    "\n",
    "cont = 0\n",
    "for clf in models:\n",
    "    for comb in combinations:\n",
    "        print('\\n')\n",
    "        model_name = clf.__class__.__name__\n",
    "        clf.fit(comb[3], comb[5]) # train the model\n",
    "        y_predict=clf.predict(comb[4]) # Do the prediction\n",
    "        \n",
    "        # Store metric of the prediction with all rows\n",
    "        LinearSVC_results.loc[cont, 'Label'] = comb[0]\n",
    "        LinearSVC_results.loc[cont, 'Prep'] = comb[1]\n",
    "        LinearSVC_results.loc[cont, 'Size'] = comb[2]\n",
    "        LinearSVC_results.loc[cont, 'Accuracy'] = accuracy_score(comb[6],y_predict)\n",
    "        LinearSVC_results.loc[cont, 'Precision'] = precision_score(comb[6],y_predict,average='macro')\n",
    "        LinearSVC_results.loc[cont, 'Recall'] = recall_score(comb[6],y_predict,average='macro')\n",
    "        LinearSVC_results.loc[cont, 'F1score'] = f1_score(comb[6],y_predict,average='macro')\n",
    "\n",
    "        cont += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "On6TMsL8pZMd"
   },
   "source": [
    "### 5.5 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "wxckXpxz8rdD",
    "outputId": "40ca1b9b-8ad6-4e3d-a271-8ff39f8f5d1d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Prep</th>\n",
       "      <th>Size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.95091</td>\n",
       "      <td>0.934559</td>\n",
       "      <td>0.897499</td>\n",
       "      <td>0.914591</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.816445</td>\n",
       "      <td>0.908204</td>\n",
       "      <td>0.500553</td>\n",
       "      <td>0.450568</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.954314</td>\n",
       "      <td>0.939599</td>\n",
       "      <td>0.904406</td>\n",
       "      <td>0.920725</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.817156</td>\n",
       "      <td>0.908494</td>\n",
       "      <td>0.502489</td>\n",
       "      <td>0.454592</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.968645</td>\n",
       "      <td>0.952971</td>\n",
       "      <td>0.880491</td>\n",
       "      <td>0.912615</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.890639</td>\n",
       "      <td>0.44532</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.471078</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.970881</td>\n",
       "      <td>0.96003</td>\n",
       "      <td>0.886026</td>\n",
       "      <td>0.91881</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.890639</td>\n",
       "      <td>0.44532</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.471078</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.869804</td>\n",
       "      <td>0.850728</td>\n",
       "      <td>0.834421</td>\n",
       "      <td>0.841826</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.704086</td>\n",
       "      <td>0.678302</td>\n",
       "      <td>0.51492</td>\n",
       "      <td>0.448574</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.872802</td>\n",
       "      <td>0.853898</td>\n",
       "      <td>0.838916</td>\n",
       "      <td>0.84578</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.706373</td>\n",
       "      <td>0.754558</td>\n",
       "      <td>0.515166</td>\n",
       "      <td>0.445443</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label     Prep       Size  ...    Recall   F1score      Model\n",
       "0   InfoTheory  Prep #1   All Rows  ...  0.897499  0.914591  LinearSVC\n",
       "1   InfoTheory  Prep #1  1000 Rows  ...  0.500553  0.450568  LinearSVC\n",
       "2   InfoTheory  Prep #2   All Rows  ...  0.904406  0.920725  LinearSVC\n",
       "3   InfoTheory  Prep #2  1000 Rows  ...  0.502489  0.454592  LinearSVC\n",
       "4      CompVis  Prep #1   All Rows  ...  0.880491  0.912615  LinearSVC\n",
       "5      CompVis  Prep #1  1000 Rows  ...       0.5  0.471078  LinearSVC\n",
       "6      CompVis  Prep #2   All Rows  ...  0.886026   0.91881  LinearSVC\n",
       "7      CompVis  Prep #2  1000 Rows  ...       0.5  0.471078  LinearSVC\n",
       "8         Math  Prep #1   All Rows  ...  0.834421  0.841826  LinearSVC\n",
       "9         Math  Prep #1  1000 Rows  ...   0.51492  0.448574  LinearSVC\n",
       "10        Math  Prep #2   All Rows  ...  0.838916   0.84578  LinearSVC\n",
       "11        Math  Prep #2  1000 Rows  ...  0.515166  0.445443  LinearSVC\n",
       "\n",
       "[12 rows x 8 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearSVC_results['Model'] = \"LinearSVC\"\n",
    "\n",
    "LinearSVC_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6cUaFWTsJV5"
   },
   "source": [
    "## 6. RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxJ6PFVVffKD"
   },
   "source": [
    "### 6.1 Import Data\n",
    "As we already preprocessed the data before, in this task we only have to tokenize the documents with a simple text split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "w4tbuCwMsJV5"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchtext.legacy import data\n",
    "from torchtext.legacy.data import TabularDataset\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "tokenize = lambda x: x.split() # As we already tokenize it before we just split \n",
    "TEXT = data.Field(sequential=True, tokenize = tokenize, lower=True)\n",
    "\n",
    "LABEL = data.LabelField(dtype = torch.float, use_vocab=False, preprocessing=int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75oThygnevnK"
   },
   "source": [
    "Then we define the train fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7uy598JTe1fR"
   },
   "outputs": [],
   "source": [
    "train_fields = [(\"InfoTheory\", LABEL),\t(\"CompVis\", LABEL),\t(\"Math\", LABEL), (\"Abstract\", TEXT)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8X9K5qV7e3Ns"
   },
   "source": [
    "And finally, we import the data with all the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "qW_e6HCUsJV6"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_data_1_all, test_data_1_all = TabularDataset.splits(path=\"/content/drive/\", train='train_prep_1.csv', test='test_prep_1.csv',\n",
    "                                   format='csv',skip_header=True, fields=train_fields)\n",
    "\n",
    "train_data_2_all, test_data_2_all = TabularDataset.splits(path=\"/content/drive/\", train='train_prep_2.csv', test='test_prep_2.csv',\n",
    "                                   format='csv',skip_header=True, fields=train_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z3LJte6De-BC"
   },
   "source": [
    "And the same data but just the first 1000 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "f5G5KpsN9qwU"
   },
   "outputs": [],
   "source": [
    "train_data_1_1000, test_data_1_1000 = TabularDataset.splits(path=\"/content/drive/\", train='train_prep_1_1000.csv', test='test_prep_1.csv',\n",
    "                                   format='csv',skip_header=True, fields=train_fields)\n",
    "\n",
    "train_data_2_1000, test_data_2_1000 = TabularDataset.splits(path=\"/content/drive/\", train='train_prep_2_1000.csv', test='test_prep_2.csv',\n",
    "                                   format='csv',skip_header=True, fields=train_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhvlOrLVKiXB"
   },
   "source": [
    "We can see how many examples are in each split by checking their length.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0gTKOsz-ZVU",
    "outputId": "90255cee-9c7c-47e4-d96f-054f345cb357"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples with preprocessing #1: 54731\n",
      "Number of training examples with preprocessing #2: 54731\n",
      "Number of testing examples with preprocessing #1: 19678\n",
      "Number of testing examples with preprocessing #2: 19678\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples with preprocessing #1: {len(train_data_1_all)}')\n",
    "print(f'Number of training examples with preprocessing #2: {len(train_data_2_all)}')\n",
    "print(f'Number of testing examples with preprocessing #1: {len(test_data_1_all)}')\n",
    "print(f'Number of testing examples with preprocessing #2: {len(test_data_2_all)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L8EdLejoKqnM"
   },
   "source": [
    "We can also check an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUYkS9Qk8X7e",
    "outputId": "5c757885-97ef-49c9-ddf8-90c465ea422c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.legacy.data.dataset.TabularDataset at 0x7f8497f93310>"
      ]
     },
     "execution_count": 93,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_1_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ws3K3-0TsJV6",
    "outputId": "b774b112-aec4-4e00-8c7c-ad69990f5e7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'InfoTheory': 0, 'CompVis': 0, 'Math': 0, 'Abstract': ['nest', 'satisfi', 'special', 'case', 'satisfi', 'problem', 'claus', 'hierarch', 'structur', 'shown', 'solvabl', 'linear', 'time', 'assum', 'claus', 'repres', 'conveni', 'way']}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data_1_all.examples[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nn70BgEK8Mm"
   },
   "source": [
    "After that we create a vocabulary made out of Abstracts from all the rows of the traning dataset, and preprocessed with the method #1. But just with 10.000 tokens because it would take to much time to run with 52.234 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "0envfvLYKt37"
   },
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 10000 # All the vocabulary has 52.234 words but it will take to much time to run therefore we ch\n",
    "\n",
    "TEXT.build_vocab(train_data_1_all, max_size = MAX_VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_1_An9oLMwW"
   },
   "source": [
    "We build this vocabulary with this dataset, as it is the one with more words without looking at the test dataset. Because it is the one with more abstracs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "To3RGO5wKt1l",
    "outputId": "aaf3cf9e-78c8-4fea-eca2-2b860ba0714a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.legacy.data.field.Field at 0x7f8498183690>"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37e-DeSRKtyf",
    "outputId": "d9c3d7dc-43ea-401f-a0d6-a31c9051b19a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 10002\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjtDrEhAu7z6"
   },
   "source": [
    "After creating the vocabulary we can check what are the top 5 words after we perform the preprocessing method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y74gm_E_Ktv9",
    "outputId": "c8d55307-aeb3-4355-da4c-e1b6cd398eff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('use', 51026), ('network', 39237), ('algorithm', 39117), ('model', 36333), ('system', 34822)]\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.freqs.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gcAwVOn5KttH",
    "outputId": "10c8cca7-b6e4-4731-ee95-dfa657f280d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', '<pad>', 'use', 'network', 'algorithm']\n",
      "<torchtext.legacy.data.field.LabelField object at 0x7f8497fe18d0>\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.itos[:5])\n",
    "print(LABEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKS8htMHOf7X"
   },
   "source": [
    "From the steps shown before, we can see that we built a vocabularu with 52.234 diferent words. And the most used word is `use`. Remember that we removed the stopswords\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The final step of preparing the data is creating the iterators for each type of preprocessing and the size of the data set. That is why we build 4 different iterators:\n",
    "  - 2 Different preprocessing methods\n",
    "  - 2 Different sizes of datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIRYP0NLRrFm"
   },
   "source": [
    "### 6.2 Create Iterators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "Erom5zg9Qy1-"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Iterator for preprocessing method #1 and all the rows of the dataset\n",
    "train_iterator_1_all, test_iterator_1_all = data.BucketIterator.splits(\n",
    "    (train_data_1_all, test_data_1_all), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    sort_key = lambda x: len(x.Abstract),\n",
    "    sort_within_batch = False)\n",
    "\n",
    "batch_1_all = next(train_iterator_1_all.__iter__())\n",
    "\n",
    "# Iterator for preprocessing method #2 and all the rows of the dataset\n",
    "train_iterator_2_all, test_iterator_2_all = data.BucketIterator.splits(\n",
    "    (train_data_2_all, test_data_2_all), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    sort_key = lambda x: len(x.Abstract),\n",
    "    sort_within_batch = False)\n",
    "\n",
    "batch_2_all = next(train_iterator_2_all.__iter__())\n",
    "\n",
    "# Iterator for preprocessing method #1 and the first 1000 rows of the dataset\n",
    "train_iterator_1_1000, test_iterator_1_1000 = data.BucketIterator.splits(\n",
    "    (train_data_1_1000, test_data_1_1000), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    sort_key = lambda x: len(x.Abstract),\n",
    "    sort_within_batch = False)\n",
    "\n",
    "batch_1_1000 = next(train_iterator_1_1000.__iter__())\n",
    "\n",
    "# Iterator for preprocessing method #2 and the first 1000 rows of the dataset\n",
    "train_iterator_2_1000, test_iterator_2_1000 = data.BucketIterator.splits(\n",
    "    (train_data_2_1000, test_data_2_1000), \n",
    "    batch_size = BATCH_SIZE,\n",
    "    device = device,\n",
    "    sort_key = lambda x: len(x.Abstract),\n",
    "    sort_within_batch = False)\n",
    "\n",
    "batch_2_1000 = next(train_iterator_2_1000.__iter__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmMPzsxvUXAU"
   },
   "source": [
    "### 6.3 Train RNN Model\n",
    "The next stage is building the model that we'll eventually train and evaluate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "E0BSIOp-RG8X"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, hidden = self.rnn(embedded)\n",
    "        \n",
    "        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n",
    "        \n",
    "        return self.fc(hidden.squeeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "GbXLM3VYRRL0"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 1\n",
    "\n",
    "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LgV4O6GzRU5I",
    "outputId": "adb837de-8bc6-4157-9be6-29d7bf1a96ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(10002, 100)\n",
       "  (rnn): RNN(100, 256)\n",
       "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z7fIXlzDRac6",
    "outputId": "57469977-6ca2-4739-9363-a8e95a06e2b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 1,092,105 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "43ZlQv1YRgW3"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "41GUqzSwRizE",
    "outputId": "60ef6cb1-6c71-4f06-cb03-6ab689243a65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    lr: 0.001\n",
       "    momentum: 0\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 118,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "LEvm2j8NRnJp"
   },
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "dJwTHszbRnHb"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "9FWQIunERnEi"
   },
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
    "    \"\"\"\n",
    "\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = (rounded_preds == y).float() #convert into float for division \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrIz-KzBLkWb"
   },
   "source": [
    "#### 6.3.1 Auxiliary Infotheory Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2yHLJ4fVuRb"
   },
   "source": [
    "**Preprocessing Method #1 and All the Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "id": "-xlFtEfGRnCK"
   },
   "outputs": [],
   "source": [
    "def train_InfoTheory_1_all(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()    \n",
    "        predictions = model(batch_1_all.Abstract).squeeze(1)\n",
    "        loss = criterion(predictions, batch_1_all.InfoTheory)\n",
    "        acc = binary_accuracy(predictions, batch_1_all.InfoTheory)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnM6CFUtV9uM"
   },
   "source": [
    "**Preprocessing Method #2 and All the Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "id": "cyYPkr1gCMN-"
   },
   "outputs": [],
   "source": [
    "def train_InfoTheory_2_all(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()    \n",
    "        predictions = model(batch_2_all.Abstract).squeeze(1)\n",
    "        loss = criterion(predictions, batch_2_all.InfoTheory)\n",
    "        acc = binary_accuracy(predictions, batch_2_all.InfoTheory)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KIlOu-ThWAbA"
   },
   "source": [
    "**Preprocessing Method #1 and First 1000 Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "1oYYUVJaCM6G"
   },
   "outputs": [],
   "source": [
    "def train_InfoTheory_1_1000(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()    \n",
    "        predictions = model(batch_1_1000.Abstract).squeeze(1)\n",
    "        loss = criterion(predictions, batch_1_1000.InfoTheory)\n",
    "        acc = binary_accuracy(predictions, batch_1_1000.InfoTheory)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdqyRuh5WE2O"
   },
   "source": [
    "**Preprocessing Method #2 and First 1000 Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "id": "qV4Dg1J7CNgE"
   },
   "outputs": [],
   "source": [
    "def train_InfoTheory_2_1000(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()    \n",
    "        predictions = model(batch_2_1000.Abstract).squeeze(1)\n",
    "        loss = criterion(predictions, batch_2_1000.InfoTheory)\n",
    "        acc = binary_accuracy(predictions, batch_2_1000.InfoTheory)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RT9dYEzLzSh"
   },
   "source": [
    "#### 6.3.2 Auxiliary CompVis Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKQehp6WWML7"
   },
   "source": [
    "**Preprocessing Method #1 and All the Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "rv6WnTN5LQCB"
   },
   "outputs": [],
   "source": [
    "def train_CompVis_1_all(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()    \n",
    "        predictions = model(batch_1_all.Abstract).squeeze(1)\n",
    "        loss = criterion(predictions, batch_1_all.CompVis)\n",
    "        acc = binary_accuracy(predictions, batch_1_all.CompVis)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "io9nCEmJWYnJ"
   },
   "source": [
    "**Preprocessing Method #2 and All the Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "j0gE12uvLP0G"
   },
   "outputs": [],
   "source": [
    "def train_CompVis_2_all(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()    \n",
    "        predictions = model(batch_2_all.Abstract).squeeze(1)\n",
    "        loss = criterion(predictions, batch_2_all.CompVis)\n",
    "        acc = binary_accuracy(predictions, batch_2_all.CompVis)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2epzTG01WcYI"
   },
   "source": [
    "**Preprocessing Method #1 and First 1000 Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "sdaHYTV5LPiR"
   },
   "outputs": [],
   "source": [
    "def train_CompVis_1_1000(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()    \n",
    "        predictions = model(batch_1_1000.Abstract).squeeze(1)\n",
    "        loss = criterion(predictions, batch_1_1000.CompVis)\n",
    "        acc = binary_accuracy(predictions, batch_1_1000.CompVis)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khl9Pt8CWibH"
   },
   "source": [
    "**Preprocessing Method #2 and First 1000 Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "32jLNVUMYsbA"
   },
   "outputs": [],
   "source": [
    "def train_CompVis_2_1000(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()    \n",
    "        predictions = model(batch_2_1000.Abstract).squeeze(1)\n",
    "        loss = criterion(predictions, batch_2_1000.CompVis)\n",
    "        acc = binary_accuracy(predictions, batch_2_1000.CompVis)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hq-3T3FoMXAe"
   },
   "source": [
    "#### 6.3.3 Auxiliary Math Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAACJKmCWrT3"
   },
   "source": [
    "**Preprocessing Method #1 and All the Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "v0h6FqHxYsDG"
   },
   "outputs": [],
   "source": [
    "def train_Math_1_all(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()    \n",
    "        predictions = model(batch_1_all.Abstract).squeeze(1)\n",
    "        loss = criterion(predictions, batch_1_all.Math)\n",
    "        acc = binary_accuracy(predictions, batch_1_all.Math)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QpQyl9MWy73"
   },
   "source": [
    "**Preprocessing Method #2 and All the Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "id": "iWbiRUHMNtXH"
   },
   "outputs": [],
   "source": [
    "def train_Math_2_all(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()    \n",
    "        predictions = model(batch_2_all.Abstract).squeeze(1)\n",
    "        loss = criterion(predictions, batch_2_all.Math)\n",
    "        acc = binary_accuracy(predictions, batch_2_all.Math)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9iSi5XrZW3CL"
   },
   "source": [
    "**Preprocessing Method #1 and First 1000 Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "trOMyM8aNtOv"
   },
   "outputs": [],
   "source": [
    "def train_Math_1_1000(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()    \n",
    "        predictions = model(batch_1_1000.Abstract).squeeze(1)\n",
    "        loss = criterion(predictions, batch_1_1000.Math)\n",
    "        acc = binary_accuracy(predictions, batch_1_1000.Math)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G-6m_EMzW8Sq"
   },
   "source": [
    "**Preprocessing Method #2 and First 1000 Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "id": "XWN0QufqNtFx"
   },
   "outputs": [],
   "source": [
    "def train_Math_2_1000(model, iterator, optimizer, criterion):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:\n",
    "        \n",
    "        optimizer.zero_grad()    \n",
    "        predictions = model(batch_2_1000.Abstract).squeeze(1)\n",
    "        loss = criterion(predictions, batch_2_1000.Math)\n",
    "        acc = binary_accuracy(predictions, batch_2_1000.Math)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZKOAzS5XDDF"
   },
   "source": [
    "### 6.4 Train Accuracy\n",
    "\n",
    "First create a function to tell us how long an epoch takes to compare training times between models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "id": "jsyZDVvkR4e8"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dU7hWrWTX9j0"
   },
   "source": [
    "We then train the model through multiple epochs, an epoch being a complete pass through all examples in the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oglwEYvjR8v-",
    "outputId": "5da204c0-8662-45ed-9998-91e497108984"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 12m 0s\n",
      "\tTrain InfoTheory:\n",
      "\t\tPrep #1 and All Rows Loss: 0.377 | Prep #1 and All Rows Acc: 87.50%\n",
      "\t\tPrep #2 and All Rows Loss: 0.379 | Prep #2 and All Rows Acc: 87.25%\n",
      "\t\tPrep #1 and 1000 Rows Loss: 0.120 | Prep #1 and 1000 Rows Acc: 100.00%\n",
      "\t\tPrep #2 and 1000 Rows Loss: 0.057 | Prep #2 and 1000 Rows Acc: 100.00%\n",
      "\tTrain CompVis:\n",
      "\t\tPrep #1 and All Rows Loss: 0.008 | Prep #1 and All Rows Acc: 100.00%\n",
      "\t\tPrep #2 and All Rows Loss: 0.002 | Prep #2 and All Rows Acc: 100.00%\n",
      "\t\tPrep #1 and 1000 Rows Loss: 0.014 | Prep #1 and 1000 Rows Acc: 100.00%\n",
      "\t\tPrep #2 and 1000 Rows Loss: 0.001 | Prep #2 and 1000 Rows Acc: 100.00%\n",
      "\tTrain Math:\n",
      "\t\tPrep #1 and All Rows Loss: 0.664 | Prep #1 and All Rows Acc: 62.50%\n",
      "\t\tPrep #2 and All Rows Loss: 0.632 | Prep #2 and All Rows Acc: 62.50%\n",
      "\t\tPrep #1 and 1000 Rows Loss: 0.217 | Prep #1 and 1000 Rows Acc: 100.00%\n",
      "\t\tPrep #2 and 1000 Rows Loss: 0.066 | Prep #2 and 1000 Rows Acc: 100.00%\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss_Info_1_all, train_acc_Info_1_all = train_InfoTheory_1_all(model, train_iterator_1_all, optimizer, criterion)\n",
    "    train_loss_Info_2_all, train_acc_Info_2_all = train_InfoTheory_2_all(model, train_iterator_2_all, optimizer, criterion)\n",
    "    train_loss_Info_1_1000, train_acc_Info_1_1000 = train_InfoTheory_1_1000(model, train_iterator_1_1000, optimizer, criterion)\n",
    "    train_loss_Info_2_1000, train_acc_Info_2_1000 = train_InfoTheory_2_1000(model, train_iterator_2_1000, optimizer, criterion)\n",
    "    train_loss_Comp_1_all, train_acc_Comp_1_all = train_CompVis_1_all(model, train_iterator_1_all, optimizer, criterion)\n",
    "    train_loss_Comp_2_all, train_acc_Comp_2_all = train_CompVis_2_all(model, train_iterator_2_all, optimizer, criterion)\n",
    "    train_loss_Comp_1_1000, train_acc_Comp_1_1000 = train_CompVis_1_1000(model, train_iterator_1_1000, optimizer, criterion)\n",
    "    train_loss_Comp_2_1000, train_acc_Comp_2_1000 = train_CompVis_2_1000(model, train_iterator_2_1000, optimizer, criterion)\n",
    "    train_loss_Math_1_all, train_acc_Math_1_all = train_Math_1_all(model, train_iterator_1_all, optimizer, criterion)\n",
    "    train_loss_Math_2_all, train_acc_Math_2_all = train_Math_2_all(model, train_iterator_2_all, optimizer, criterion)\n",
    "    train_loss_Math_1_1000, train_acc_Math_1_1000 = train_Math_1_1000(model, train_iterator_1_1000, optimizer, criterion)\n",
    "    train_loss_Math_2_1000, train_acc_Math_2_1000 = train_Math_2_1000(model, train_iterator_2_1000, optimizer, criterion)\n",
    "  \n",
    "    torch.save(model.state_dict(), 'RNN_model.pt')\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain InfoTheory:')\n",
    "    print(f'\\t\\tPrep #1 and All Rows Loss: {train_loss_Info_1_all:.3f} | Prep #1 and All Rows Acc: {train_acc_Info_1_all*100:.2f}%')\n",
    "    print(f'\\t\\tPrep #2 and All Rows Loss: {train_loss_Info_2_all:.3f} | Prep #2 and All Rows Acc: {train_acc_Info_2_all*100:.2f}%')\n",
    "    print(f'\\t\\tPrep #1 and 1000 Rows Loss: {train_loss_Info_1_1000:.3f} | Prep #1 and 1000 Rows Acc: {train_acc_Info_1_1000*100:.2f}%')\n",
    "    print(f'\\t\\tPrep #2 and 1000 Rows Loss: {train_loss_Info_2_1000:.3f} | Prep #2 and 1000 Rows Acc: {train_acc_Info_2_1000*100:.2f}%')\n",
    "    print(f'\\tTrain CompVis:')\n",
    "    print(f'\\t\\tPrep #1 and All Rows Loss: {train_loss_Comp_1_all:.3f} | Prep #1 and All Rows Acc: {train_acc_Comp_1_all*100:.2f}%')\n",
    "    print(f'\\t\\tPrep #2 and All Rows Loss: {train_loss_Comp_2_all:.3f} | Prep #2 and All Rows Acc: {train_acc_Comp_2_all*100:.2f}%')\n",
    "    print(f'\\t\\tPrep #1 and 1000 Rows Loss: {train_loss_Comp_1_1000:.3f} | Prep #1 and 1000 Rows Acc: {train_acc_Comp_1_1000*100:.2f}%')\n",
    "    print(f'\\t\\tPrep #2 and 1000 Rows Loss: {train_loss_Comp_2_1000:.3f} | Prep #2 and 1000 Rows Acc: {train_acc_Comp_2_1000*100:.2f}%')\n",
    "    print(f'\\tTrain Math:')\n",
    "    print(f'\\t\\tPrep #1 and All Rows Loss: {train_loss_Math_1_all:.3f} | Prep #1 and All Rows Acc: {train_acc_Math_1_all*100:.2f}%')\n",
    "    print(f'\\t\\tPrep #2 and All Rows Loss: {train_loss_Math_2_all:.3f} | Prep #2 and All Rows Acc: {train_acc_Math_2_all*100:.2f}%')\n",
    "    print(f'\\t\\tPrep #1 and 1000 Rows Loss: {train_loss_Math_1_1000:.3f} | Prep #1 and 1000 Rows Acc: {train_acc_Math_1_1000*100:.2f}%')\n",
    "    print(f'\\t\\tPrep #2 and 1000 Rows Loss: {train_loss_Math_2_1000:.3f} | Prep #2 and 1000 Rows Acc: {train_acc_Math_2_1000*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dL1SmjUjeGDT"
   },
   "source": [
    "### 6.5 Prediction of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qtv76rUumzoP",
    "outputId": "d55b90f7-76c7-4a1e-aeea-7efaf885f4d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 136,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('RNN_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "id": "_YwlyyWHm2U2"
   },
   "outputs": [],
   "source": [
    "y_predict_1_all = []\n",
    "y_predict_2_all = []\n",
    "y_predict_1_1000 = []\n",
    "y_predict_2_1000 = []\n",
    "y_Info_1_all = []\n",
    "y_Comp_1_all = []\n",
    "y_Math_1_all = []\n",
    "y_Info_2_all = []\n",
    "y_Comp_2_all = []\n",
    "y_Math_2_all = []\n",
    "y_Info_1_1000 = []\n",
    "y_Comp_1_1000 = []\n",
    "y_Math_1_1000 = []\n",
    "y_Info_2_1000 = []\n",
    "y_Comp_2_1000 = []\n",
    "y_Math_2_1000 = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in test_iterator_1_all:\n",
    "        predictions_1_all = model(batch.Abstract).squeeze(1)\n",
    "        rounded_preds_1_all = torch.round(torch.sigmoid(predictions_1_all))\n",
    "        y_predict_1_all += rounded_preds_1_all.tolist()\n",
    "        y_Info_1_all += batch.InfoTheory.tolist()\n",
    "        y_Comp_1_all += batch.CompVis.tolist()\n",
    "        y_Math_1_all += batch.Math.tolist()\n",
    "    \n",
    "    for batch in test_iterator_2_all:\n",
    "        predictions_2_all = model(batch.Abstract).squeeze(1)\n",
    "        rounded_preds_2_all = torch.round(torch.sigmoid(predictions_2_all))\n",
    "        y_predict_2_all += rounded_preds_2_all.tolist()\n",
    "        y_Info_2_all += batch.InfoTheory.tolist()\n",
    "        y_Comp_2_all += batch.CompVis.tolist()\n",
    "        y_Math_2_all += batch.Math.tolist()\n",
    "\n",
    "    for batch in test_iterator_1_1000:\n",
    "        predictions_1_1000 = model(batch.Abstract).squeeze(1)\n",
    "        rounded_preds_1_1000 = torch.round(torch.sigmoid(predictions_1_1000))\n",
    "        y_predict_1_1000 += rounded_preds_1_1000.tolist()\n",
    "        y_Info_1_1000 += batch.InfoTheory.tolist()\n",
    "        y_Comp_1_1000 += batch.CompVis.tolist()\n",
    "        y_Math_1_1000 += batch.Math.tolist()\n",
    "    \n",
    "    for batch in test_iterator_2_1000:\n",
    "        predictions_2_1000 = model(batch.Abstract).squeeze(1)\n",
    "        rounded_preds_2_1000 = torch.round(torch.sigmoid(predictions_2_1000))\n",
    "        y_predict_2_1000 += rounded_preds_2_1000.tolist()\n",
    "        y_Info_2_1000 += batch.InfoTheory.tolist()\n",
    "        y_Comp_2_1000 += batch.CompVis.tolist()\n",
    "        y_Math_2_1000 += batch.Math.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z3QBgt1dgRFq"
   },
   "outputs": [],
   "source": [
    "combinations = [(\"InfoTheory\", \"Prep #1\", \"All Rows\", np.asarray(y_Info_1_all), np.asarray(y_predict_1_all)),\n",
    "                (\"InfoTheory\", \"Prep #2\", \"All Rows\", np.asarray(y_Info_2_all), np.asarray(y_predict_2_all)),\n",
    "                (\"InfoTheory\", \"Prep #1\", \"1000 Rows\", np.asarray(y_Info_1_1000), np.asarray(y_predict_1_1000)),\n",
    "                (\"InfoTheory\", \"Prep #2\", \"1000 Rows\", np.asarray(y_Info_2_1000), np.asarray(y_predict_2_1000)),\n",
    "                (\"CompVis\", \"Prep #1\", \"All Rows\", np.asarray(y_Comp_1_all), np.asarray(y_predict_1_all)),\n",
    "                (\"CompVis\", \"Prep #2\", \"All Rows\", np.asarray(y_Comp_2_all), np.asarray(y_predict_2_all)),\n",
    "                (\"CompVis\", \"Prep #1\", \"1000 Rows\", np.asarray(y_Comp_1_1000), np.asarray(y_predict_1_1000)),\n",
    "                (\"CompVis\", \"Prep #2\", \"1000 Rows\", np.asarray(y_Comp_2_1000), np.asarray(y_predict_2_1000)),\n",
    "                (\"Math\", \"Prep #1\", \"All Rows\", np.asarray(y_Math_1_all), np.asarray(y_predict_1_all)),\n",
    "                (\"Math\", \"Prep #2\", \"All Rows\", np.asarray(y_Math_2_all), np.asarray(y_predict_2_all)),\n",
    "                (\"Math\", \"Prep #1\", \"1000 Rows\", np.asarray(y_Math_1_1000), np.asarray(y_predict_1_1000)),\n",
    "                (\"Math\", \"Prep #2\", \"1000 Rows\", np.asarray(y_Math_2_1000), np.asarray(y_predict_2_1000))]\n",
    "\n",
    "cont = 0\n",
    "RNN_results = pd.DataFrame(columns=['Label', 'Prep', 'Size', 'Accuracy', \"Precision\", \"Recall\", \"F1score\"])\n",
    "for i in combinations:\n",
    "  # Store metric of the prediction with all rows\n",
    "  RNN_results.loc[cont, 'Label'] = i[0]\n",
    "  RNN_results.loc[cont, 'Prep'] = i[1]\n",
    "  RNN_results.loc[cont, 'Size'] = i[2]\n",
    "  RNN_results.loc[cont, 'Accuracy'] = accuracy_score(i[3],i[4])\n",
    "  RNN_results.loc[cont, 'Precision'] = precision_score(i[3],i[4],average='macro')\n",
    "  RNN_results.loc[cont, 'Recall'] = recall_score(i[3],i[4],average='macro')\n",
    "  RNN_results.loc[cont, 'F1score'] = f1_score(i[3],i[4],average='macro')\n",
    "\n",
    "  cont += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z16vjI3zqOEs"
   },
   "source": [
    "### 6.6 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "v-f7K0LJzjbO",
    "outputId": "80b87908-7526-45cd-f774-92021d9f722b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Prep</th>\n",
       "      <th>Size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.689349</td>\n",
       "      <td>0.501647</td>\n",
       "      <td>0.501772</td>\n",
       "      <td>0.50143</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.815987</td>\n",
       "      <td>0.408097</td>\n",
       "      <td>0.499844</td>\n",
       "      <td>0.449335</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.476594</td>\n",
       "      <td>0.491514</td>\n",
       "      <td>0.465236</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.3935</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.440403</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.724616</td>\n",
       "      <td>0.487661</td>\n",
       "      <td>0.479557</td>\n",
       "      <td>0.476655</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.890385</td>\n",
       "      <td>0.445306</td>\n",
       "      <td>0.499857</td>\n",
       "      <td>0.471007</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.506253</td>\n",
       "      <td>0.504379</td>\n",
       "      <td>0.503511</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.47479</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.618406</td>\n",
       "      <td>0.500208</td>\n",
       "      <td>0.500159</td>\n",
       "      <td>0.49367</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.698394</td>\n",
       "      <td>0.349286</td>\n",
       "      <td>0.499818</td>\n",
       "      <td>0.411209</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.454422</td>\n",
       "      <td>0.487184</td>\n",
       "      <td>0.43097</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.406176</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label     Prep       Size  ...    Recall   F1score Model\n",
       "0   InfoTheory  Prep #1   All Rows  ...  0.501772   0.50143   RNN\n",
       "1   InfoTheory  Prep #2   All Rows  ...  0.499844  0.449335   RNN\n",
       "2   InfoTheory  Prep #1  1000 Rows  ...  0.491514  0.465236   RNN\n",
       "3   InfoTheory  Prep #2  1000 Rows  ...       0.5  0.440403   RNN\n",
       "4      CompVis  Prep #1   All Rows  ...  0.479557  0.476655   RNN\n",
       "5      CompVis  Prep #2   All Rows  ...  0.499857  0.471007   RNN\n",
       "6      CompVis  Prep #1  1000 Rows  ...  0.504379  0.503511   RNN\n",
       "7      CompVis  Prep #2  1000 Rows  ...       0.5   0.47479   RNN\n",
       "8         Math  Prep #1   All Rows  ...  0.500159   0.49367   RNN\n",
       "9         Math  Prep #2   All Rows  ...  0.499818  0.411209   RNN\n",
       "10        Math  Prep #1  1000 Rows  ...  0.487184   0.43097   RNN\n",
       "11        Math  Prep #2  1000 Rows  ...       0.5  0.406176   RNN\n",
       "\n",
       "[12 rows x 8 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RNN_results[\"Model\"] = \"RNN\"\n",
    "\n",
    "RNN_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9RnFzmyqY2i"
   },
   "source": [
    "## 7. Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "id": "T2txCjrhtMCX",
    "outputId": "2028dd25-d744-4c25-b8f3-fb7e4eca79e2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Prep</th>\n",
       "      <th>Size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1score</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.95091</td>\n",
       "      <td>0.934559</td>\n",
       "      <td>0.897499</td>\n",
       "      <td>0.914591</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.816445</td>\n",
       "      <td>0.908204</td>\n",
       "      <td>0.500553</td>\n",
       "      <td>0.450568</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.954314</td>\n",
       "      <td>0.939599</td>\n",
       "      <td>0.904406</td>\n",
       "      <td>0.920725</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.817156</td>\n",
       "      <td>0.908494</td>\n",
       "      <td>0.502489</td>\n",
       "      <td>0.454592</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.968645</td>\n",
       "      <td>0.952971</td>\n",
       "      <td>0.880491</td>\n",
       "      <td>0.912615</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.890639</td>\n",
       "      <td>0.44532</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.471078</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.970881</td>\n",
       "      <td>0.96003</td>\n",
       "      <td>0.886026</td>\n",
       "      <td>0.91881</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.890639</td>\n",
       "      <td>0.44532</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.471078</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.869804</td>\n",
       "      <td>0.850728</td>\n",
       "      <td>0.834421</td>\n",
       "      <td>0.841826</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.704086</td>\n",
       "      <td>0.678302</td>\n",
       "      <td>0.51492</td>\n",
       "      <td>0.448574</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.872802</td>\n",
       "      <td>0.853898</td>\n",
       "      <td>0.838916</td>\n",
       "      <td>0.84578</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.706373</td>\n",
       "      <td>0.754558</td>\n",
       "      <td>0.515166</td>\n",
       "      <td>0.445443</td>\n",
       "      <td>LinearSVC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.689349</td>\n",
       "      <td>0.501647</td>\n",
       "      <td>0.501772</td>\n",
       "      <td>0.50143</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.815987</td>\n",
       "      <td>0.408097</td>\n",
       "      <td>0.499844</td>\n",
       "      <td>0.449335</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.476594</td>\n",
       "      <td>0.491514</td>\n",
       "      <td>0.465236</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>InfoTheory</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.3935</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.440403</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.724616</td>\n",
       "      <td>0.487661</td>\n",
       "      <td>0.479557</td>\n",
       "      <td>0.476655</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.890385</td>\n",
       "      <td>0.445306</td>\n",
       "      <td>0.499857</td>\n",
       "      <td>0.471007</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.506253</td>\n",
       "      <td>0.504379</td>\n",
       "      <td>0.503511</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CompVis</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.452</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.47479</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.618406</td>\n",
       "      <td>0.500208</td>\n",
       "      <td>0.500159</td>\n",
       "      <td>0.49367</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>All Rows</td>\n",
       "      <td>0.698394</td>\n",
       "      <td>0.349286</td>\n",
       "      <td>0.499818</td>\n",
       "      <td>0.411209</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #1</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.454422</td>\n",
       "      <td>0.487184</td>\n",
       "      <td>0.43097</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Math</td>\n",
       "      <td>Prep #2</td>\n",
       "      <td>1000 Rows</td>\n",
       "      <td>0.684</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.406176</td>\n",
       "      <td>RNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Label     Prep       Size  ...    Recall   F1score      Model\n",
       "0   InfoTheory  Prep #1   All Rows  ...  0.897499  0.914591  LinearSVC\n",
       "1   InfoTheory  Prep #1  1000 Rows  ...  0.500553  0.450568  LinearSVC\n",
       "2   InfoTheory  Prep #2   All Rows  ...  0.904406  0.920725  LinearSVC\n",
       "3   InfoTheory  Prep #2  1000 Rows  ...  0.502489  0.454592  LinearSVC\n",
       "4      CompVis  Prep #1   All Rows  ...  0.880491  0.912615  LinearSVC\n",
       "5      CompVis  Prep #1  1000 Rows  ...       0.5  0.471078  LinearSVC\n",
       "6      CompVis  Prep #2   All Rows  ...  0.886026   0.91881  LinearSVC\n",
       "7      CompVis  Prep #2  1000 Rows  ...       0.5  0.471078  LinearSVC\n",
       "8         Math  Prep #1   All Rows  ...  0.834421  0.841826  LinearSVC\n",
       "9         Math  Prep #1  1000 Rows  ...   0.51492  0.448574  LinearSVC\n",
       "10        Math  Prep #2   All Rows  ...  0.838916   0.84578  LinearSVC\n",
       "11        Math  Prep #2  1000 Rows  ...  0.515166  0.445443  LinearSVC\n",
       "12  InfoTheory  Prep #1   All Rows  ...  0.501772   0.50143        RNN\n",
       "13  InfoTheory  Prep #2   All Rows  ...  0.499844  0.449335        RNN\n",
       "14  InfoTheory  Prep #1  1000 Rows  ...  0.491514  0.465236        RNN\n",
       "15  InfoTheory  Prep #2  1000 Rows  ...       0.5  0.440403        RNN\n",
       "16     CompVis  Prep #1   All Rows  ...  0.479557  0.476655        RNN\n",
       "17     CompVis  Prep #2   All Rows  ...  0.499857  0.471007        RNN\n",
       "18     CompVis  Prep #1  1000 Rows  ...  0.504379  0.503511        RNN\n",
       "19     CompVis  Prep #2  1000 Rows  ...       0.5   0.47479        RNN\n",
       "20        Math  Prep #1   All Rows  ...  0.500159   0.49367        RNN\n",
       "21        Math  Prep #2   All Rows  ...  0.499818  0.411209        RNN\n",
       "22        Math  Prep #1  1000 Rows  ...  0.487184   0.43097        RNN\n",
       "23        Math  Prep #2  1000 Rows  ...       0.5  0.406176        RNN\n",
       "\n",
       "[24 rows x 8 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results = pd.concat([LinearSVC_results, RNN_results], ignore_index=True)\n",
    "final_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHjE05URoUiD"
   },
   "source": [
    "## 7. Visualization of Performance of Models\n",
    "The visualization and analysis of performance of each model is in the PDF File submitted with this Jupiter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svVb6oiuLHJY"
   },
   "source": [
    "# Part 2: Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kSivj5DwsJV7"
   },
   "source": [
    "## 1. Import the library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwCsI5KJKj87"
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHcq68j_sJV7"
   },
   "source": [
    "## 2. Documents\n",
    "With the two preprocessing methods used in Task 1, we create our documents, by just splitting the words in lists `train_abstracts1` and `train_abstracts2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "F_O6RsB67XWy"
   },
   "outputs": [],
   "source": [
    "train_abstracts1 = df_train_prep_1.Abstract.to_list()\n",
    "train_abstracts2 = df_train_prep_2.Abstract.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "NV50o8UvYm8H"
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+') # Tokenizer that matches every element of the corpus\n",
    "\n",
    "for idx in range(len(train_abstracts1)):\n",
    "    train_abstracts1[idx] = tokenizer.tokenize(train_abstracts1[idx])  # Split into words.\n",
    "\n",
    "for idx in range(len(train_abstracts2)):\n",
    "    train_abstracts2[idx] = tokenizer.tokenize(train_abstracts2[idx])  # Split into words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boa5kCB0sJV-"
   },
   "source": [
    "## 3. Remove Common and Rare tokens\n",
    "The main porpuse of this task is to remove `rare` tokens, those which does not apper in at least 20 documents, because they are not relevant in the corpus. \n",
    "\n",
    "Besides, we filter out the `common` words that occur in more than 50% of the documents, as we assume that are context words, and there are not relevant either.\n",
    "\n",
    "The reason to remove those tokens is to better predict the topics of the corpus. Because pretty common words are going to be in all topics and rare tokens are just going to add some noise to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xp-Z79EesJV-"
   },
   "source": [
    "#### 3.1 train_abstracts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "id": "iNsfdNy1ccWx"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary representation of the documents.\n",
    "dictionary_1 = Dictionary(train_abstracts1)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary_1.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKfI9TY8sJV-"
   },
   "source": [
    "Finally, with that dictionary we build our corpus_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "mfWL7l3scwg5"
   },
   "outputs": [],
   "source": [
    "# Bag-of-words representation of the documents.\n",
    "corpus_1 = [dictionary_1.doc2bow(doc) for doc in train_abstracts1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CwF1D85Lc2d-",
    "outputId": "dc46760a-6774-4f48-9576-f75385e7878a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 5938\n",
      "Number of documents: 54731\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary_1))\n",
    "print('Number of documents: %d' % len(corpus_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHLbC5KLsJV_"
   },
   "source": [
    "#### 3.2 train_abstracts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "id": "Q-_z8zKwsJV_"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary representation of the documents.\n",
    "dictionary_2 = Dictionary(train_abstracts2)\n",
    "\n",
    "# Filter out words that occur less than 20 documents, or more than 50% of the documents.\n",
    "dictionary_2.filter_extremes(no_below=20, no_above=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3z8eD1hsJV_"
   },
   "source": [
    "Finally, with that dictionary we build our corpus_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "6Xf5S1LFsJWA"
   },
   "outputs": [],
   "source": [
    "# Bag-of-words representation of the documents.\n",
    "corpus_2 = [dictionary_2.doc2bow(doc) for doc in train_abstracts2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "44fbLkE1sJWA",
    "outputId": "7573d737-459c-428a-ea25-257383fa3f41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique tokens: 9642\n",
      "Number of documents: 54731\n"
     ]
    }
   ],
   "source": [
    "print('Number of unique tokens: %d' % len(dictionary_2))\n",
    "print('Number of documents: %d' % len(corpus_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-HyWq8T4sJWA"
   },
   "source": [
    "Again, by using two different preprocessing methods we find out that the number of tokens in each corpus is different. Even though the number of documents is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a0H89bj8sJWA",
    "outputId": "27a323a0-f4c7-416e-e984-ee3969d80286",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary_2 has 3704 tokens more than dictionary_1\n",
      "corpus_2 has 0 documents more than corpus_1\n"
     ]
    }
   ],
   "source": [
    "print('dictionary_2 has ' + str(len(dictionary_2)-len(dictionary_1)) + ' tokens more than dictionary_1')\n",
    "print('corpus_2 has ' + str(len(corpus_2)-len(corpus_1)) + ' documents more than corpus_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBx8BgOdsJWA"
   },
   "source": [
    "## 4. LDA Model\n",
    "We are going to build 4 different models, changing 2 different parameters: `Preprocessing Method` and `Number of topics`, but the main parameters of the model will remain the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hv2VcxwTEcCr"
   },
   "source": [
    "### 4.1 Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "id": "hdqc_TGrsJWB"
   },
   "outputs": [],
   "source": [
    "# Set training parameters.\n",
    "chunksize = 2000\n",
    "passes = 20\n",
    "iterations = 400\n",
    "eval_every = None  # Don't evaluate model perplexity, takes too much time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pRBAYbHwsJWB"
   },
   "source": [
    "After that we are going to train each model:\n",
    "\n",
    "**Model 1:**\n",
    "   - *Preprocessing:* Method #1 \n",
    "   - *Number of topics:* 3 (Known three categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xui8WbMqc-4a"
   },
   "outputs": [],
   "source": [
    "NUM_TOPICS = 3\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary_1[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary_1.id2token\n",
    "\n",
    "model_1 = LdaModel(\n",
    "    corpus=corpus_1,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=NUM_TOPICS,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "outputfile = f'model_1{NUM_TOPICS}.gensim'\n",
    "print(\"Saving model in \" + outputfile)\n",
    "print(\"\")\n",
    "model_1.save(outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWMOeLD6sJWC"
   },
   "source": [
    "**Model 2:**\n",
    "   - *Preprocessing:* Method #1 \n",
    "   - *Number of topics:* 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwYstT0zsJWC"
   },
   "outputs": [],
   "source": [
    "NUM_TOPICS = 20\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary_1[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary_1.id2token\n",
    "\n",
    "model_2 = LdaModel(\n",
    "    corpus=corpus_1,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=NUM_TOPICS,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "outputfile = f'model_2{NUM_TOPICS}.gensim'\n",
    "print(\"Saving model in \" + outputfile)\n",
    "print(\"\")\n",
    "model_2.save(outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2XUDqJ4sJWC"
   },
   "source": [
    "**Model 3:**\n",
    "   - *Preprocessing:* Method #2\n",
    "   - *Number of topics:* 3 (Known three categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CZmXLkQ5sJWC"
   },
   "outputs": [],
   "source": [
    "NUM_TOPICS = 3\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary_2[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary_2.id2token\n",
    "\n",
    "model_3 = LdaModel(\n",
    "    corpus=corpus_2,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=NUM_TOPICS,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "outputfile = f'model_3{NUM_TOPICS}.gensim'\n",
    "print(\"Saving model in \" + outputfile)\n",
    "print(\"\")\n",
    "model_3.save(outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDQCbjSrsJWD"
   },
   "source": [
    "**Model 4:**\n",
    "   - *Preprocessing:* Method #2\n",
    "   - *Number of topics:* 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SBS6-trlsJWD"
   },
   "outputs": [],
   "source": [
    "NUM_TOPICS = 20\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary_2[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary_2.id2token\n",
    "\n",
    "model_4 = LdaModel(\n",
    "    corpus=corpus_2,\n",
    "    id2word=id2word,\n",
    "    chunksize=chunksize,\n",
    "    alpha='auto',\n",
    "    eta='auto',\n",
    "    iterations=iterations,\n",
    "    num_topics=NUM_TOPICS,\n",
    "    passes=passes,\n",
    "    eval_every=eval_every\n",
    ")\n",
    "outputfile = f'model_4{NUM_TOPICS}.gensim'\n",
    "print(\"Saving model in \" + outputfile)\n",
    "print(\"\")\n",
    "model_4.save(outputfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtLRkE6csJWD"
   },
   "source": [
    "### 4.2 Exploration of the topics\n",
    "Even though this part is going to be in a PDF, it is worth it to describe some insights found in the model as the visualizations are interactive. With them we can identify the most relevant words of each topic and the relevance of each word to each topic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-ruXvL6DKxn"
   },
   "source": [
    "**Model 1:**\n",
    "   - *Preprocessing:* Method #1 \n",
    "   - *Number of topics:* 3 (Known three categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "MWnP3PcUdGl3",
    "outputId": "607a5e72-d304-4d61-b415-003699be56cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -0.2152.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el58140202945639376902338622\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el58140202945639376902338622_data = {\"mdsDat\": {\"x\": [0.1212040231543729, -0.17834078307958098, 0.05713675992520808], \"y\": [0.12807711504801111, 0.034846423734113716, -0.16292353878212487], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [34.84844999951362, 38.49924042514549, 26.652309575340887]}, \"tinfo\": {\"Term\": [\"code\", \"channel\", \"graph\", \"network\", \"problem\", \"data\", \"rate\", \"signal\", \"imag\", \"optim\", \"scheme\", \"estim\", \"set\", \"perform\", \"bound\", \"algorithm\", \"matrix\", \"error\", \"nois\", \"achiev\", \"decod\", \"interfer\", \"languag\", \"spars\", \"capac\", \"relay\", \"quantum\", \"propos\", \"user\", \"logic\", \"graph\", \"languag\", \"quantum\", \"logic\", \"game\", \"tree\", \"polynomi\", \"semant\", \"word\", \"formal\", \"algebra\", \"player\", \"np\", \"answer\", \"automata\", \"boolean\", \"tensor\", \"calculu\", \"diagram\", \"citat\", \"string\", \"solver\", \"student\", \"latent\", \"subgraph\", \"ontolog\", \"ration\", \"sort\", \"journal\", \"arithmet\", \"color\", \"proof\", \"label\", \"probabilist\", \"notion\", \"edg\", \"combinatori\", \"theori\", \"conjectur\", \"kernel\", \"decid\", \"set\", \"program\", \"represent\", \"definit\", \"class\", \"complet\", \"problem\", \"theorem\", \"properti\", \"function\", \"prove\", \"give\", \"algorithm\", \"gener\", \"given\", \"construct\", \"comput\", \"relat\", \"complex\", \"show\", \"approxim\", \"structur\", \"number\", \"space\", \"time\", \"result\", \"model\", \"one\", \"two\", \"order\", \"paper\", \"method\", \"also\", \"present\", \"bound\", \"new\", \"base\", \"imag\", \"social\", \"softwar\", \"servic\", \"mobil\", \"architectur\", \"human\", \"dataset\", \"manag\", \"technolog\", \"devic\", \"web\", \"cloud\", \"attack\", \"visual\", \"content\", \"traffic\", \"engin\", \"video\", \"robot\", \"heterogen\", \"organ\", \"platform\", \"neural\", \"privaci\", \"deploy\", \"internet\", \"server\", \"monitor\", \"scalabl\", \"document\", \"research\", \"rout\", \"data\", \"featur\", \"challeng\", \"environ\", \"predict\", \"cluster\", \"network\", \"recognit\", \"qualiti\", \"secur\", \"develop\", \"system\", \"process\", \"model\", \"detect\", \"dynam\", \"base\", \"control\", \"level\", \"applic\", \"propos\", \"approach\", \"inform\", \"perform\", \"differ\", \"design\", \"paper\", \"method\", \"commun\", \"user\", \"analysi\", \"provid\", \"present\", \"effect\", \"comput\", \"time\", \"studi\", \"result\", \"learn\", \"channel\", \"matrix\", \"nois\", \"interfer\", \"decod\", \"spars\", \"relay\", \"compress\", \"gaussian\", \"convex\", \"mimo\", \"matric\", \"sum\", \"transmit\", \"antenna\", \"asymptot\", \"vertic\", \"squar\", \"vertex\", \"spectral\", \"transmitt\", \"fade\", \"subspac\", \"sparsiti\", \"precod\", \"distort\", \"quantiz\", \"hop\", \"snr\", \"beamform\", \"transmiss\", \"capac\", \"code\", \"signal\", \"ratio\", \"receiv\", \"rate\", \"error\", \"scheme\", \"estim\", \"optim\", \"achiev\", \"power\", \"multipl\", \"bound\", \"propos\", \"perform\", \"sampl\", \"distribut\", \"deriv\", \"algorithm\", \"linear\", \"network\", \"result\", \"two\", \"show\", \"problem\", \"base\", \"system\", \"paper\", \"inform\", \"consid\", \"user\", \"time\"], \"Freq\": [18352.0, 15869.0, 18306.0, 38368.0, 36412.0, 24998.0, 11006.0, 9210.0, 11210.0, 21249.0, 11080.0, 11247.0, 21776.0, 20290.0, 15532.0, 40990.0, 6267.0, 8331.0, 5595.0, 9913.0, 5476.0, 5455.0, 6801.0, 5181.0, 5308.0, 5013.0, 6220.0, 28681.0, 13967.0, 6001.0, 18306.194650907302, 6801.295519826417, 6220.522305699502, 6001.397342473962, 5829.422401476231, 5491.077117996687, 5828.659758906062, 4683.486564956585, 3688.9607767205202, 2903.2612095715062, 3373.7677726134966, 2223.7650841981754, 2039.1662806268096, 1886.087544326448, 1798.154357526767, 1451.0963907279913, 1360.5795557139102, 1392.7189585361791, 1299.7108819740686, 1225.3974217074845, 1210.6472472319535, 1058.1927352172809, 1042.0432324059873, 978.4339916624841, 979.3712866663947, 927.5357479944106, 899.2733991431139, 882.2191928907375, 834.8875206289333, 822.8787758749035, 3541.0606480384104, 3768.345004875411, 2585.9836874490356, 2877.8643300955314, 2748.6021659041503, 4811.2029304945545, 1340.0936496108488, 6492.669523914106, 1711.7531658950645, 2467.7108230979406, 1748.7259933422242, 17819.730683559625, 6808.2026305649915, 4626.480087269368, 2167.4898078087517, 7396.074670505937, 4950.825952508872, 26491.704456807536, 2550.1544404269785, 6739.585504477931, 12701.096908933161, 6238.871739001668, 4944.110940275906, 24653.980491136543, 15181.047205878443, 6958.441299737528, 6041.950065525136, 13491.210715694579, 5859.523585473777, 9508.59689045496, 13397.85774371172, 7111.923787986803, 8349.493679122757, 9938.961192422332, 6301.169936201657, 11556.462050915568, 11631.497030868635, 12892.394045525927, 8401.300460533423, 8605.43943974062, 7010.643014203636, 8965.71501070172, 8525.327844589443, 7692.836570688651, 7582.781381331956, 7188.810735568788, 7079.800009943184, 7323.075704654226, 11209.813769891376, 6000.836001352874, 5653.175147051038, 4770.429506670727, 4562.547012612152, 3786.372533829889, 3687.5384084883285, 3427.215625492203, 3495.627504001761, 3431.7957899884127, 3027.970787689034, 3091.747857427699, 2765.9377236151327, 2561.7212673491535, 2480.401479241584, 2497.876209966406, 2470.410472554176, 2431.1648697569667, 1953.0344556637974, 1960.7390865946006, 1841.4059452638771, 1812.890741258412, 1705.6071919940982, 1648.9179930006658, 1612.258991771547, 1581.482192552647, 1593.7100139103195, 1481.8164364182833, 1471.510060254119, 1463.0084277510969, 1806.2232925490164, 5883.180100375698, 2944.076788284959, 22086.33304653423, 6987.160076194517, 4064.114556078096, 3292.112315927548, 4833.303039681493, 5064.778305234255, 28088.112826522716, 2764.5866545135686, 3977.3271635095025, 3960.6610833301847, 8616.80484289489, 20220.88764460056, 10099.551396880115, 21617.231010336087, 5925.488747748362, 6487.090409415111, 17987.931114288116, 7080.6780337277605, 5440.403896603953, 8768.353325745473, 13993.942106589582, 10654.022192500235, 10149.40561374836, 10898.692144193337, 8580.447338274344, 7480.752066629319, 12821.162447350567, 11551.70393462726, 7218.206235931357, 7979.283221737027, 7124.073212608658, 7590.7107496586905, 7942.810498180714, 6025.422959767069, 8001.410340592426, 7843.397736566152, 6904.592153549323, 7478.178278931842, 6436.587238835126, 15869.37418092261, 6266.954089073233, 5595.220387250189, 5454.9678316172085, 5476.564502351619, 5181.366405852559, 5013.349550844291, 4432.846138000224, 3900.190233330919, 3801.530462057502, 3332.3217790081944, 3181.2758732536777, 3179.688805632699, 3054.0506443011077, 3016.7178989899494, 2715.8433671732078, 2600.9742162343027, 2419.4401608462813, 2100.0841503383044, 1921.1311325825905, 1906.3859488948463, 1885.6989388700215, 1488.5071147444567, 1484.9914901742222, 1390.3858966280848, 1265.8402372222065, 1257.5170763292942, 1181.9123800855637, 1176.0890266455408, 1079.6879382220288, 4668.407206818566, 5261.804810958726, 17907.714450785865, 8915.222744462866, 3111.5751008174616, 5187.877136695312, 9929.75894692097, 7328.160988478645, 9435.26187209503, 9427.431517398914, 14390.0054613627, 7461.91571625766, 7359.811433477217, 6144.622611868427, 8342.630329994845, 11947.203412940824, 9373.677666106238, 4801.37338603276, 6987.679266327035, 4834.178355278154, 11200.750262542348, 5969.6604298950315, 10275.764321273016, 8539.329356080852, 6998.4092745036105, 7361.459497045196, 8084.837997993496, 7699.099042666405, 7384.291335706355, 7172.6277751232, 6323.582960867771, 5929.97787437565, 5987.22139763611, 5929.755591068794], \"Total\": [18352.0, 15869.0, 18306.0, 38368.0, 36412.0, 24998.0, 11006.0, 9210.0, 11210.0, 21249.0, 11080.0, 11247.0, 21776.0, 20290.0, 15532.0, 40990.0, 6267.0, 8331.0, 5595.0, 9913.0, 5476.0, 5455.0, 6801.0, 5181.0, 5308.0, 5013.0, 6220.0, 28681.0, 13967.0, 6001.0, 18306.393146423074, 6801.469236961155, 6220.694004694073, 6001.569617806866, 5829.591901046871, 5491.247392612207, 5828.849236748325, 4683.653056917065, 3689.1253319416446, 2903.4233957399747, 3373.971797867046, 2223.9200230087536, 2039.3224382713277, 1886.2429953042497, 1798.3087540955614, 1451.2479034084613, 1360.7243519463536, 1392.8711051215378, 1299.859851852105, 1225.547026727952, 1210.7980268279114, 1058.3395158815347, 1042.1897020565923, 978.5774480083966, 979.5165191231451, 927.6829475484392, 899.4200968456128, 882.3653760186279, 835.0342506498666, 823.0239555215193, 3546.156428039465, 3786.209629573943, 2600.5452369825766, 2903.8744900693546, 2776.6057841687993, 4941.197977004621, 1346.1168400778568, 6932.572571624073, 1752.005178901625, 2574.954227404879, 1793.3791730915057, 21776.642821478912, 7771.000278901793, 5127.923280940883, 2260.0235761021213, 8676.311195567496, 5625.962830628479, 36412.43991829763, 2709.774350465935, 8261.890065904625, 17233.09254438956, 7582.035949681702, 5822.486382095182, 40990.808823799845, 23478.396909062252, 9125.703931698996, 7634.533570644384, 23030.240025482617, 7635.825123792633, 15048.335889404307, 25003.65962831462, 10201.38922730354, 13277.850195165447, 17940.608429437732, 8735.810580635014, 25329.615378550516, 27649.00466588133, 37203.937146993994, 16450.934744025035, 19123.65334460006, 11571.78246388637, 28959.50523317549, 25459.519417312767, 17273.917746674888, 18050.93669321221, 15532.356916447668, 15361.865286397131, 33010.10586160875, 11210.050929551924, 6001.013746173608, 5653.35304758183, 4770.608324013027, 4562.723486788475, 3786.545266739497, 3687.709517562803, 3427.382346521065, 3495.8010149580928, 3431.96798407544, 3028.1390235230615, 3091.92073581716, 2766.1022350528847, 2561.8897422909563, 2480.56534868964, 2498.042803051293, 2470.5773174726314, 2431.3324629566036, 1953.1957616497266, 1960.901843361009, 1841.5678840577614, 1813.0555987674857, 1705.7672728147184, 1649.078300113742, 1612.418190616034, 1581.6428425703543, 1593.8736192341091, 1481.9765816660076, 1471.6703248641047, 1463.1677930905687, 1806.633728328319, 6138.532715432065, 3007.958752647304, 24998.90309596804, 7465.062387071641, 4228.535275748244, 3405.8918096802017, 5216.578975269683, 5589.334763851515, 38368.830447888206, 2910.7100100006237, 4406.087372507992, 4498.683298278339, 11575.933177916359, 33006.78842403996, 14203.465337227379, 37203.937146993994, 7488.677008269551, 8542.942325974487, 33010.10586160875, 9684.94397911381, 6836.823965704005, 13297.551950179739, 28681.889284491564, 19263.130869868797, 17993.539694595856, 20290.010198875127, 14089.304115584633, 11520.495007992422, 28959.50523317549, 25459.519417312767, 11327.110342901986, 13967.496108334668, 12744.208322845012, 15831.73660266768, 18050.93669321221, 8941.807951756131, 23030.240025482617, 25329.615378550516, 16372.245184117837, 27649.00466588133, 11318.080771101477, 15869.566861914773, 6267.126179305298, 5595.390699005974, 5455.140466415452, 5476.738955006789, 5181.535192799489, 5013.521386961216, 4433.013954845263, 3900.3581113749606, 3801.694131049317, 3332.485141296786, 3181.4378633216506, 3179.853508843057, 3054.2144640891247, 3016.881144106196, 2716.0062334485747, 2601.1347165532, 2419.6001936644902, 2100.2415584895566, 1921.2871307048495, 1906.5447646132934, 1885.8584056319485, 1488.65813888084, 1485.1429762118037, 1390.536420262992, 1265.994188397149, 1257.6704566023104, 1182.0641022268278, 1176.2431576417964, 1079.838828617555, 4693.563321394462, 5308.501104744563, 18352.95396317572, 9210.29461390859, 3157.5442739827845, 5530.810071710712, 11006.452835970676, 8331.47585215574, 11080.355131308635, 11247.175008591195, 21249.259283947973, 9913.290183365087, 11193.240450846024, 8810.078943362634, 15532.356916447668, 28681.889284491564, 20290.010198875127, 6922.111265639383, 14256.770260757326, 7187.031753823634, 40990.808823799845, 11214.096879471288, 38368.830447888206, 27649.00466588133, 19123.65334460006, 25003.65962831462, 36412.43991829763, 33010.10586160875, 33006.78842403996, 28959.50523317549, 17993.539694595856, 12171.726725210247, 13967.496108334668, 25329.615378550516], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.4994001388549805, -5.489500045776367, -5.578700065612793, -5.61460018157959, -5.643700122833252, -5.703499794006348, -5.643799781799316, -5.862599849700928, -6.10129976272583, -6.340799808502197, -6.1905999183654785, -6.607399940490723, -6.6940999031066895, -6.77209997177124, -6.819799900054932, -7.034299850463867, -7.098700046539307, -7.075300216674805, -7.144499778747559, -7.2032999992370605, -7.215400218963623, -7.349999904632568, -7.3653998374938965, -7.428400039672852, -7.4274001121521, -7.481800079345703, -7.512800216674805, -7.531899929046631, -7.587100028991699, -7.601500034332275, -6.142199993133545, -6.079999923706055, -6.456500053405762, -6.349599838256836, -6.395500183105469, -5.835700035095215, -7.113900184631348, -5.535900115966797, -6.869100093841553, -6.503300189971924, -6.847700119018555, -4.526299953460693, -5.488500118255615, -5.874800205230713, -6.632999897003174, -5.405700206756592, -5.807000160217285, -4.129799842834473, -6.470399856567383, -5.498600006103516, -4.8649001121521, -5.575799942016602, -5.8084001541137695, -4.201700210571289, -4.686600208282471, -5.466599941253662, -5.607900142669678, -4.804599761962891, -5.638500213623047, -5.154399871826172, -4.811500072479248, -5.444799900054932, -5.28439998626709, -5.110099792480469, -5.565899848937988, -4.959400177001953, -4.952899932861328, -4.849999904632568, -5.278200149536133, -5.254199981689453, -5.459199905395508, -5.213200092315674, -5.263599872589111, -5.366300106048584, -5.38070011138916, -5.434100151062012, -5.449399948120117, -5.415599822998047, -5.089399814605713, -5.714300155639648, -5.77400016784668, -5.94379997253418, -5.988399982452393, -6.174799919128418, -6.201300144195557, -6.274499893188477, -6.254700183868408, -6.273099899291992, -6.3983001708984375, -6.377500057220459, -6.488900184631348, -6.5655999183654785, -6.597799777984619, -6.590799808502197, -6.601799964904785, -6.6178998947143555, -6.8368000984191895, -6.832900047302246, -6.895699977874756, -6.911300182342529, -6.972300052642822, -7.006100177764893, -7.028600215911865, -7.047900199890137, -7.040200233459473, -7.11299991607666, -7.119900226593018, -7.125699996948242, -6.914999961853027, -5.734099864959717, -6.426400184631348, -4.411300182342529, -5.56220006942749, -6.104000091552734, -6.314700126647949, -5.930699825286865, -5.883900165557861, -4.170899868011475, -6.489299774169922, -6.1255998611450195, -6.129799842834473, -5.352499961853027, -4.499499797821045, -5.193699836730957, -4.432700157165527, -5.7270002365112305, -5.63640022277832, -4.616499900817871, -5.548900127410889, -5.812399864196777, -5.335100173950195, -4.867599964141846, -5.1402997970581055, -5.188799858093262, -5.117599964141846, -5.3566999435424805, -5.493899822235107, -4.955100059509277, -5.0594000816345215, -5.529600143432617, -5.4293999671936035, -5.542799949645996, -5.479300022125244, -5.434000015258789, -5.71019983291626, -5.426599979400635, -5.446599960327148, -5.573999881744385, -5.494200229644775, -5.644199848175049, -4.374100208282471, -5.303199768066406, -5.416600227355957, -5.44189977645874, -5.438000202178955, -5.4934000968933105, -5.526400089263916, -5.649400234222412, -5.777400016784668, -5.803100109100342, -5.934800148010254, -5.981200218200684, -5.9816999435424805, -6.021999835968018, -6.034299850463867, -6.139400005340576, -6.182600021362305, -6.254899978637695, -6.396500110626221, -6.485599994659424, -6.493299961090088, -6.504199981689453, -6.740699768066406, -6.743100166320801, -6.808899879455566, -6.902699947357178, -6.909299850463867, -6.97130012512207, -6.97629976272583, -7.061800003051758, -5.597700119018555, -5.478000164031982, -4.253200054168701, -4.950699806213379, -6.003300189971924, -5.492099761962891, -4.842899799346924, -5.146699905395508, -4.894000053405762, -4.894800186157227, -4.47189998626709, -5.128699779510498, -5.142399787902832, -5.32289981842041, -5.017099857330322, -4.6579999923706055, -4.900599956512451, -5.5696001052856445, -5.194300174713135, -5.56279993057251, -4.722499847412109, -5.351799964904785, -4.808700084686279, -4.993800163269043, -5.192800045013428, -5.142199993133545, -5.048500061035156, -5.097400188446045, -5.139100074768066, -5.1682000160217285, -5.2941999435424805, -5.358399868011475, -5.348800182342529, -5.358500003814697], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.0542, 1.0541, 1.0541, 1.0541, 1.0541, 1.0541, 1.0541, 1.0541, 1.0541, 1.0541, 1.0541, 1.0541, 1.0541, 1.0541, 1.0541, 1.0541, 1.0541, 1.0541, 1.054, 1.054, 1.054, 1.054, 1.054, 1.054, 1.054, 1.054, 1.054, 1.054, 1.054, 1.054, 1.0527, 1.0494, 1.0485, 1.0452, 1.044, 1.0275, 1.0497, 0.9886, 1.0309, 1.0116, 1.0289, 0.8536, 0.9219, 0.9513, 1.0124, 0.8945, 0.9263, 0.7361, 0.9935, 0.8505, 0.749, 0.8592, 0.8906, 0.5458, 0.6181, 0.783, 0.8202, 0.5194, 0.7894, 0.5951, 0.4302, 0.6934, 0.5903, 0.4636, 0.7275, 0.2694, 0.1883, -0.0056, 0.3822, 0.2556, 0.553, -0.1183, -0.0399, 0.2453, 0.1868, 0.2838, 0.2795, -0.4516, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9545, 0.9544, 0.9544, 0.9544, 0.9544, 0.9544, 0.9544, 0.9544, 0.9544, 0.9544, 0.9544, 0.9544, 0.9544, 0.9543, 0.912, 0.9331, 0.8307, 0.8884, 0.9149, 0.9206, 0.8782, 0.856, 0.6426, 0.903, 0.8522, 0.8272, 0.6593, 0.4645, 0.6135, 0.4116, 0.7204, 0.6792, 0.3474, 0.6413, 0.7261, 0.5381, 0.2369, 0.3623, 0.3819, 0.333, 0.4586, 0.5227, 0.1397, 0.1643, 0.5039, 0.3946, 0.3729, 0.2194, 0.1336, 0.5598, -0.1027, -0.2178, 0.0911, -0.3531, 0.3901, 1.3223, 1.3223, 1.3223, 1.3223, 1.3223, 1.3223, 1.3223, 1.3223, 1.3223, 1.3223, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3222, 1.3169, 1.3135, 1.2977, 1.2897, 1.3076, 1.2583, 1.2193, 1.194, 1.1616, 1.1458, 0.9325, 1.0382, 0.903, 0.962, 0.7007, 0.4465, 0.5501, 0.9565, 0.6092, 0.9257, 0.0249, 0.6918, 0.0048, 0.1474, 0.3171, 0.0995, -0.1826, -0.1334, -0.1751, -0.0733, 0.2766, 0.6032, 0.4752, -0.1297]}, \"token.table\": {\"Topic\": [1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 3, 2, 1, 1, 2, 3, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 1, 1, 2, 3, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 2, 1, 2, 3, 3, 2, 1, 1, 2, 3, 1, 2, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 3, 2, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 3, 1, 3, 1, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 2, 1, 1, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 3, 1, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 3, 1, 2, 3, 1, 2, 1, 2, 3, 2, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 2, 1, 2, 3, 1, 2, 3, 2, 3, 3, 2, 2, 1, 1, 1, 2, 3, 3, 3, 3, 3, 1, 1, 2, 3, 1, 1, 2, 3, 1, 3, 3, 1, 2, 3, 2, 1, 1, 3, 1, 2, 3, 1, 2, 3, 2, 2, 3, 3, 3, 1, 1, 2, 3, 1, 2, 3, 3, 3, 2, 2, 2, 1], \"Freq\": [0.011096215077470906, 0.23614763178508538, 0.7527268809826173, 1.000008358734051, 0.6014519036688424, 0.12529638100280582, 0.27325637920802726, 0.4453535157929561, 0.28910638994800764, 0.2655448559654608, 0.20001242410881764, 0.5589990228918073, 0.2409722065273358, 0.999871174973291, 1.0000393969427785, 0.25719019657251824, 0.659369486417497, 0.08347401116827345, 0.2980304727607918, 0.5530772786611176, 0.14888545477755633, 0.6971599496434334, 9.802586468552213e-05, 0.3028018960135779, 0.9998559988852407, 0.9999708932876636, 0.9999977049211088, 1.0000430376480391, 0.9998283086289502, 0.22184115466641868, 0.5449240325193964, 0.2332316058687365, 1.0001492550352642, 0.9998291791444597, 0.4628402526848554, 6.438172940393037e-05, 0.537136768416991, 1.0000925389851139, 0.008665346223416383, 0.991240257122109, 0.013479844977742034, 0.9610892980621689, 0.025304270396813995, 0.9999642799378392, 0.9995536468890855, 0.8524359988123094, 0.0003457690638773564, 0.14718236485712805, 0.9999630400309905, 0.04114979862854214, 0.9061901306676781, 0.05277908954530405, 0.00010897428305072303, 0.02413780369573515, 0.9757557304361739, 0.9985459107221856, 0.0002819954562898011, 0.0011279818251592043, 0.9954559367391147, 0.004457265388384096, 0.0003531350784895071, 0.6372322491343155, 0.3624048742998566, 0.8800271436288393, 0.05296871112934642, 0.06701075199920671, 0.6318971127362586, 0.14008193434094365, 0.22806508475242818, 0.9999968520637641, 0.5857950236329457, 0.34741279253481566, 0.06678176164461273, 0.9771660612745989, 0.022830982740060724, 0.3645333238389279, 0.1482944894138528, 0.487194638351328, 0.7914039468281534, 0.0051083670847894705, 0.20354878076314967, 0.9999828653651408, 0.007021207365437143, 0.7311348434508884, 0.2619529865605005, 1.0000804559599323, 0.04720207104568188, 0.8834787636567203, 0.06932304162895482, 0.9998884435751813, 0.9752538817460432, 0.024534688848957063, 1.0000476643118021, 0.9588395550003245, 0.03362796778035287, 0.007522045424552615, 0.9995935602191266, 0.3027675505736186, 0.024488551884630918, 0.6726003398312833, 0.013627886639513335, 0.649364458281524, 0.33705148930719925, 0.0001335349353291277, 0.7911944918250816, 0.20858156898409747, 0.16361531903218152, 0.7443892313095608, 0.09200122215906723, 0.9999540894516462, 1.0001078178910559, 0.2538095544438189, 0.6089725886823172, 0.13719627201898826, 1.000004590544652, 0.1618178562047931, 0.34804516796193474, 0.490153090229343, 0.9996492214673168, 0.20531567849487062, 0.7593402545018391, 0.03535081807608376, 0.9736505241015363, 0.0028333210013347554, 0.023476088296773688, 0.12167561704188935, 0.6738010962108303, 0.2044329301034685, 0.9998632589488813, 0.9665603559818021, 0.03317780079767425, 0.06529455400860844, 0.05509227994476337, 0.8795560510571373, 0.0005334672924905034, 0.1612849447629622, 0.838166027717996, 1.0000750821841282, 0.06389765755020238, 0.9359600278894423, 0.00013395735335472195, 0.9998541736142941, 0.7370122319766084, 0.06945938443240691, 0.1935230134353192, 0.99989846612646, 0.999908185001291, 0.6465944016024535, 0.15639909378066064, 0.19698959932885496, 0.8491217798642468, 0.07196238385176364, 0.07883230116458116, 0.7624617292076208, 0.04339391272868896, 0.19417680140211324, 0.9999785240915603, 0.9996916301252441, 0.9999457709385582, 1.0000787704226197, 0.9999954567956699, 0.08453033843345532, 0.5640357690737265, 0.35145947419669393, 0.9999742506327167, 1.0000792915852084, 0.999958982940113, 0.9584636393662536, 0.038835641789556466, 0.003106851343164517, 0.994406851003502, 0.005383486432346879, 0.9999310094709236, 0.9994099107744903, 0.43081509123436545, 0.5687360012870407, 0.00044177101234040754, 0.10472699071845587, 0.795691102665363, 0.09960765457998387, 0.467536535162089, 8.917347609423784e-05, 0.5323656522825999, 0.9999050885279785, 1.0000569211579995, 0.9998623693623884, 0.9999798664807938, 0.3348452836153263, 0.45373990807322573, 0.2113944066179104, 0.9998544205671696, 1.0000606026668777, 0.3465224647881561, 0.5810406547723838, 0.07241169098194947, 1.000224014258034, 0.10011261030350745, 0.20249534782478149, 0.6974965876587905, 0.0001303141102200366, 0.7320525455720777, 0.26782155932421925, 0.9999525188623629, 0.46088153150706973, 0.36610137474516385, 0.17302586309968804, 0.9999301748480149, 0.9900577228765431, 0.010084254725552277, 0.9998418895093407, 0.553994589374776, 0.13037461963453073, 0.31565261692618535, 0.5106700701643252, 0.26952875742276133, 0.2198051391160814, 1.0003417681142017, 0.17562965137421105, 0.147205131162522, 0.6772000759043132, 0.6058703593746407, 0.1801796746963523, 0.21405518188146985, 0.9999693342181434, 0.3096047369527816, 0.4427216520713376, 0.2476906957575622, 0.0008871360745298154, 0.5371608931278032, 0.46200075348013836, 1.0001364354850693, 1.0000359621705903, 1.0000258650113516, 0.06682604588767353, 0.2756127694698835, 0.6575397028519748, 0.9996142350137867, 0.018977954799367716, 0.9264692479327694, 0.054441809727479105, 0.4200890030738115, 0.4400325664532882, 0.13988193759216325, 0.9997406438239981, 0.9910896665273103, 0.008609187513267115, 0.0003443675005306846, 0.7275535520125225, 0.05042232830646955, 0.2220395012842082, 0.1874894567468869, 0.7110940717775283, 0.10145411459717012, 0.8760776934320371, 0.11684467474093563, 0.007077595936950946, 0.9951905384657764, 0.004754094928976639, 0.815793958311646, 0.06439204537415366, 0.11982730248197768, 0.09556553171279661, 0.4879037033158978, 0.41653462509039807, 0.8228660535778543, 0.00013189069619776473, 0.1769973142974003, 0.291060931320923, 0.47947993265128613, 0.22947577332658706, 0.9026148743247117, 0.09713833699043917, 1.0002620268258346, 1.0000491898983774, 9.085579295191777e-05, 0.09776083321626353, 0.9021980240125436, 0.014568283453386916, 0.9855760458030453, 0.9995329247733221, 0.06183542655881102, 0.938018108149449, 0.050159582884716405, 0.9499400457276771, 0.7674350715210461, 0.21071724062753636, 0.02187058992218681, 0.9998960038422151, 0.9021195806874885, 0.09692032676214479, 0.000780042871325109, 0.04154087170683942, 0.9583723460836717, 0.4206661375536809, 0.2704618155469371, 0.3088357104781086, 1.00005005688547, 0.978736825233719, 0.021276887505080846, 0.1817364604126745, 0.12467294541823377, 0.6935745202235694, 0.9998853220448393, 0.0003609992597346998, 0.1480999463061606, 0.8515070038992232, 0.00022228726356058524, 0.8804798509634781, 0.11936826053203427, 0.9998605667607892, 1.0000158020945014, 0.9998724850225148, 0.8183079525198271, 0.07723871919968289, 0.10446973018982081, 0.5358415607620833, 0.1697351532970803, 0.2943969046700773, 0.03202937716612415, 0.9679386353762601, 0.9997932760414233, 0.999997709358087, 0.9999375507634393, 0.9996791994662961, 0.9995859130145421, 0.7212839543439339, 0.06753809443944152, 0.21119963430638913, 0.9998967115382652, 0.9999037289916906, 0.9998505529442941, 0.9997519451080961, 1.0001668099613754, 0.6287915496320274, 0.2912369053092646, 0.07990751397288072, 0.9998179774217516, 0.3791782941304942, 0.42175034165126646, 0.19911746760074275, 0.9994726795178426, 1.000229643804868, 1.0000460685237655, 0.16366330254856123, 0.6126315514317765, 0.22371155609377566, 1.0000093287363718, 1.0002025744988337, 0.9410377655842589, 0.05867647244231261, 0.9365931525299424, 0.0001442465967241556, 0.0633242559619043, 0.4562248509223629, 0.3096375480948505, 0.23411330615867187, 0.9997663228474785, 0.005326443533006917, 0.9945535364830516, 0.9999297809333149, 0.9997142660254275, 0.9999549478297883, 0.44996632416105736, 0.18406524823322742, 0.36593426339094476, 7.159479352947743e-05, 0.5712548575717004, 0.42863802886098135, 0.9998849853777152, 0.999948208544393, 0.9998997736665365, 0.9997720887740618, 1.0000256359038968, 0.9999660266512066], \"Term\": [\"achiev\", \"achiev\", \"achiev\", \"algebra\", \"algorithm\", \"algorithm\", \"algorithm\", \"also\", \"also\", \"also\", \"analysi\", \"analysi\", \"analysi\", \"answer\", \"antenna\", \"applic\", \"applic\", \"applic\", \"approach\", \"approach\", \"approach\", \"approxim\", \"approxim\", \"approxim\", \"architectur\", \"arithmet\", \"asymptot\", \"attack\", \"automata\", \"base\", \"base\", \"base\", \"beamform\", \"boolean\", \"bound\", \"bound\", \"bound\", \"calculu\", \"capac\", \"capac\", \"challeng\", \"challeng\", \"challeng\", \"channel\", \"citat\", \"class\", \"class\", \"class\", \"cloud\", \"cluster\", \"cluster\", \"cluster\", \"code\", \"code\", \"code\", \"color\", \"color\", \"color\", \"combinatori\", \"combinatori\", \"commun\", \"commun\", \"commun\", \"complet\", \"complet\", \"complet\", \"complex\", \"complex\", \"complex\", \"compress\", \"comput\", \"comput\", \"comput\", \"conjectur\", \"conjectur\", \"consid\", \"consid\", \"consid\", \"construct\", \"construct\", \"construct\", \"content\", \"control\", \"control\", \"control\", \"convex\", \"data\", \"data\", \"data\", \"dataset\", \"decid\", \"decid\", \"decod\", \"definit\", \"definit\", \"definit\", \"deploy\", \"deriv\", \"deriv\", \"deriv\", \"design\", \"design\", \"design\", \"detect\", \"detect\", \"detect\", \"develop\", \"develop\", \"develop\", \"devic\", \"diagram\", \"differ\", \"differ\", \"differ\", \"distort\", \"distribut\", \"distribut\", \"distribut\", \"document\", \"dynam\", \"dynam\", \"dynam\", \"edg\", \"edg\", \"edg\", \"effect\", \"effect\", \"effect\", \"engin\", \"environ\", \"environ\", \"error\", \"error\", \"error\", \"estim\", \"estim\", \"estim\", \"fade\", \"featur\", \"featur\", \"featur\", \"formal\", \"function\", \"function\", \"function\", \"game\", \"gaussian\", \"gener\", \"gener\", \"gener\", \"give\", \"give\", \"give\", \"given\", \"given\", \"given\", \"graph\", \"heterogen\", \"hop\", \"human\", \"imag\", \"inform\", \"inform\", \"inform\", \"interfer\", \"internet\", \"journal\", \"kernel\", \"kernel\", \"kernel\", \"label\", \"label\", \"languag\", \"latent\", \"learn\", \"learn\", \"learn\", \"level\", \"level\", \"level\", \"linear\", \"linear\", \"linear\", \"logic\", \"manag\", \"matric\", \"matrix\", \"method\", \"method\", \"method\", \"mimo\", \"mobil\", \"model\", \"model\", \"model\", \"monitor\", \"multipl\", \"multipl\", \"multipl\", \"network\", \"network\", \"network\", \"neural\", \"new\", \"new\", \"new\", \"nois\", \"notion\", \"notion\", \"np\", \"number\", \"number\", \"number\", \"one\", \"one\", \"one\", \"ontolog\", \"optim\", \"optim\", \"optim\", \"order\", \"order\", \"order\", \"organ\", \"paper\", \"paper\", \"paper\", \"perform\", \"perform\", \"perform\", \"platform\", \"player\", \"polynomi\", \"power\", \"power\", \"power\", \"precod\", \"predict\", \"predict\", \"predict\", \"present\", \"present\", \"present\", \"privaci\", \"probabilist\", \"probabilist\", \"probabilist\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"program\", \"program\", \"program\", \"proof\", \"proof\", \"properti\", \"properti\", \"properti\", \"propos\", \"propos\", \"propos\", \"prove\", \"prove\", \"prove\", \"provid\", \"provid\", \"provid\", \"qualiti\", \"qualiti\", \"quantiz\", \"quantum\", \"rate\", \"rate\", \"rate\", \"ratio\", \"ratio\", \"ration\", \"receiv\", \"receiv\", \"recognit\", \"recognit\", \"relat\", \"relat\", \"relat\", \"relay\", \"represent\", \"represent\", \"represent\", \"research\", \"research\", \"result\", \"result\", \"result\", \"robot\", \"rout\", \"rout\", \"sampl\", \"sampl\", \"sampl\", \"scalabl\", \"scheme\", \"scheme\", \"scheme\", \"secur\", \"secur\", \"secur\", \"semant\", \"server\", \"servic\", \"set\", \"set\", \"set\", \"show\", \"show\", \"show\", \"signal\", \"signal\", \"snr\", \"social\", \"softwar\", \"solver\", \"sort\", \"space\", \"space\", \"space\", \"spars\", \"sparsiti\", \"spectral\", \"squar\", \"string\", \"structur\", \"structur\", \"structur\", \"student\", \"studi\", \"studi\", \"studi\", \"subgraph\", \"subspac\", \"sum\", \"system\", \"system\", \"system\", \"technolog\", \"tensor\", \"theorem\", \"theorem\", \"theori\", \"theori\", \"theori\", \"time\", \"time\", \"time\", \"traffic\", \"transmiss\", \"transmiss\", \"transmit\", \"transmitt\", \"tree\", \"two\", \"two\", \"two\", \"user\", \"user\", \"user\", \"vertex\", \"vertic\", \"video\", \"visual\", \"web\", \"word\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el58140202945639376902338622\", ldavis_el58140202945639376902338622_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el58140202945639376902338622\", ldavis_el58140202945639376902338622_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el58140202945639376902338622\", ldavis_el58140202945639376902338622_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 200,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics = model_1.top_topics(corpus_1) #, num_words=20)\n",
    "model_1.num_topics\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / NUM_TOPICS\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "lda_display = pyLDAvis.gensim.prepare(model_1, corpus_1, dictionary_1, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RsQ7feQKQtgP"
   },
   "source": [
    "In model 1 we used Preprocessing Method #1, therefore we could get rid of stopwords, that could appear in every document regardless of its topic. That is why it could be a better approach for these LDA models. \n",
    "By pointing the cursor over each circle we can identify the most relevant words per topic and try to guess what it is about.\n",
    "\n",
    "It can be seen that each topic is pretty far from the other and they are not overlapping. It means that they are completly different. They also have almost the same size what means that there are almost the same amount of documents per topic, a pretty balanced dataset. \n",
    "\n",
    "From the beginning, we know that each abstract could be classified into three different categories: InfoTheory, CompVis, and Math. Now with a LDA model, we can check if they talk about these topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Du79de0SAZ7",
    "outputId": "2839aa2b-74b3-4ea7-9d78-d2d04b5d53ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.016*\"problem\" + 0.015*\"algorithm\" + 0.011*\"graph\" + 0.011*\"set\" + 0.009*\"gener\"\n",
      "1: 0.015*\"network\" + 0.012*\"data\" + 0.012*\"model\" + 0.011*\"system\" + 0.010*\"base\"\n",
      "2: 0.014*\"code\" + 0.013*\"channel\" + 0.011*\"optim\" + 0.009*\"propos\" + 0.009*\"algorithm\"\n"
     ]
    }
   ],
   "source": [
    "for i,topic in model_1.show_topics(formatted=True, num_topics=3, num_words=5):\n",
    "    print(str(i)+\": \"+ topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuiPM4OkDaVA"
   },
   "source": [
    "**Model 2:**\n",
    "   - *Preprocessing:* Method #1 \n",
    "   - *Number of topics:* 10\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "NU-cGBw3DlYi",
    "outputId": "33a97430-c7dd-466e-df36-2cf8b329f810"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -2.7750.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el581402085494934563659634911\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el581402085494934563659634911_data = {\"mdsDat\": {\"x\": [-0.17266267410811578, -0.08517708912247589, -0.1484328919670373, 0.07828696481164593, 0.07633176789804369, 0.023351321343349246, 0.04130920535893314, 0.027898703238149563, 0.03635672342934807, 0.13575419474124142, 0.042471164037525086, -0.03394524009572259, 0.1155342510465808, 0.11695247570535894, 0.05943832315715442, 0.07454843667663946, -0.06828232311935184, 0.015512950729968101, -0.4300272596442362, 0.09478099588300092], \"y\": [0.09952675913976594, -0.26789953270125666, 0.11530101462532745, -0.24021310055024328, 0.13848753779250067, -0.0983219681432057, -0.0410785099751174, 0.05340784152625822, 0.0847356711805632, -0.06760477204712544, 0.18820641469088303, -0.00013557549725499903, 0.11433550538674075, 0.05072888603555335, -0.15424375673912677, 0.03738119144160006, 0.029090866032578308, 0.12263471303304484, -0.04423605473070263, -0.12010313050078261], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [1.4991987781706415, 1.8639519501990713, 1.7405304034802738, 8.965379962861988, 4.370824239266004, 4.984291938238865, 2.025318466446655, 4.552744003254895, 3.7267020905015222, 11.671200605485195, 6.2632896566883005, 2.6345794544863774, 11.660908811293123, 12.977041600423261, 6.17689106088777, 3.889205366762368, 1.9675094674642752, 3.457120688221498, 1.17357696542813, 4.399734490439776]}, \"tinfo\": {\"Term\": [\"network\", \"code\", \"problem\", \"graph\", \"model\", \"algorithm\", \"data\", \"user\", \"channel\", \"system\", \"method\", \"node\", \"propos\", \"scheme\", \"imag\", \"signal\", \"comput\", \"optim\", \"learn\", \"bound\", \"quantum\", \"time\", \"control\", \"base\", \"constraint\", \"rate\", \"commun\", \"decod\", \"languag\", \"inform\", \"quantum\", \"circuit\", \"fault\", \"de\", \"optic\", \"convolut\", \"gpu\", \"secreci\", \"gate\", \"adversari\", \"perturb\", \"entangl\", \"bank\", \"assembl\", \"angl\", \"resist\", \"music\", \"amplitud\", \"instantan\", \"fingerprint\", \"dna\", \"illumin\", \"thermal\", \"drift\", \"pi\", \"kalman\", \"shed\", \"cmo\", \"se\", \"alic\", \"artifact\", \"filter\", \"encrypt\", \"toler\", \"light\", \"classic\", \"electr\", \"synthesi\", \"detector\", \"state\", \"comput\", \"input\", \"digit\", \"self\", \"output\", \"simul\", \"physic\", \"design\", \"graph\", \"edg\", \"tree\", \"vertic\", \"vertex\", \"plane\", \"walk\", \"bipartit\", \"cliqu\", \"regret\", \"infect\", \"undirect\", \"leader\", \"laplacian\", \"spin\", \"steiner\", \"straight\", \"er\", \"motif\", \"treewidth\", \"spanner\", \"erd\", \"bug\", \"forbidden\", \"fastest\", \"mrf\", \"liquid\", \"intel\", \"chordal\", \"fo\", \"coloni\", \"eigenvector\", \"path\", \"ant\", \"si\", \"connect\", \"degre\", \"maximum\", \"draw\", \"everi\", \"direct\", \"embed\", \"flow\", \"number\", \"cross\", \"minimum\", \"free\", \"contain\", \"pair\", \"complet\", \"set\", \"structur\", \"random\", \"two\", \"show\", \"interfer\", \"cell\", \"consumpt\", \"spread\", \"repair\", \"ofdm\", \"divis\", \"authent\", \"big\", \"signatur\", \"defect\", \"wave\", \"collis\", \"cnn\", \"chip\", \"femtocel\", \"sinr\", \"submodular\", \"arab\", \"phi\", \"offlin\", \"backhaul\", \"cp\", \"password\", \"tier\", \"ia\", \"beam\", \"reconfigur\", \"ep\", \"meter\", \"bs\", \"user\", \"align\", \"carrier\", \"scheme\", \"peak\", \"revers\", \"access\", \"propos\", \"share\", \"base\", \"multi\", \"multipl\", \"et\", \"al\", \"number\", \"paper\", \"two\", \"curv\", \"tensor\", \"permut\", \"emph\", \"planar\", \"intersect\", \"pack\", \"automaton\", \"polygon\", \"alpha\", \"memoryless\", \"triangl\", \"delta\", \"spike\", \"lemma\", \"isomorph\", \"super\", \"commut\", \"qubit\", \"ball\", \"join\", \"circl\", \"triangul\", \"invert\", \"monad\", \"homolog\", \"undecid\", \"unbound\", \"coalgebra\", \"bisimul\", \"multidimension\", \"let\", \"theorem\", \"matric\", \"interv\", \"expans\", \"bound\", \"symmetri\", \"vector\", \"invari\", \"boolean\", \"finit\", \"subspac\", \"famili\", \"algebra\", \"polynomi\", \"upper\", \"prove\", \"dimens\", \"lower\", \"point\", \"dual\", \"class\", \"function\", \"conjectur\", \"distanc\", \"space\", \"construct\", \"set\", \"matrix\", \"gener\", \"complex\", \"linear\", \"sequenc\", \"number\", \"properti\", \"result\", \"give\", \"show\", \"case\", \"also\", \"two\", \"given\", \"comput\", \"one\", \"random\", \"imag\", \"relay\", \"classif\", \"cloud\", \"segment\", \"classifi\", \"video\", \"mac\", \"descriptor\", \"brain\", \"supervis\", \"scene\", \"wavelet\", \"pca\", \"blind\", \"forest\", \"unsupervis\", \"registr\", \"contour\", \"rigid\", \"bag\", \"news\", \"ca\", \"dirichlet\", \"surveil\", \"slide\", \"hit\", \"handwritten\", \"blur\", \"skeleton\", \"learn\", \"train\", \"label\", \"discrimin\", \"featur\", \"dataset\", \"face\", \"recognit\", \"detect\", \"resolut\", \"visual\", \"extract\", \"object\", \"task\", \"accuraci\", \"method\", \"data\", \"propos\", \"machin\", \"base\", \"art\", \"approach\", \"perform\", \"select\", \"map\", \"multi\", \"techniqu\", \"result\", \"differ\", \"capac\", \"feedback\", \"polar\", \"multiplex\", \"secret\", \"destin\", \"dof\", \"csi\", \"imperfect\", \"csit\", \"eavesdropp\", \"voltag\", \"corrupt\", \"anonym\", \"piecewis\", \"impair\", \"shadow\", \"interleav\", \"harmon\", \"wiretap\", \"bc\", \"jam\", \"skew\", \"nonzero\", \"gamma\", \"miso\", \"blocklength\", \"sa\", \"poorli\", \"gender\", \"channel\", \"receiv\", \"distort\", \"broadcast\", \"transmit\", \"fade\", \"rate\", \"duplex\", \"forward\", \"sourc\", \"region\", \"transmiss\", \"gaussian\", \"expon\", \"achiev\", \"messag\", \"cooper\", \"sum\", \"inform\", \"scheme\", \"two\", \"multipl\", \"side\", \"bound\", \"ratio\", \"consid\", \"case\", \"deriv\", \"commun\", \"optim\", \"state\", \"result\", \"input\", \"word\", \"text\", \"charact\", \"tag\", \"speech\", \"grammar\", \"grain\", \"linguist\", \"pars\", \"diagnosi\", \"corpu\", \"english\", \"recurr\", \"histogram\", \"ordin\", \"floor\", \"arrang\", \"sentenc\", \"lexic\", \"biometr\", \"semigroup\", \"eh\", \"cartesian\", \"perceptu\", \"occup\", \"speaker\", \"rao\", \"corpora\", \"transduc\", \"verb\", \"templat\", \"string\", \"deep\", \"document\", \"sort\", \"percept\", \"layout\", \"pattern\", \"languag\", \"dictionari\", \"translat\", \"nest\", \"neural\", \"overlap\", \"semant\", \"identif\", \"extract\", \"automat\", \"recognit\", \"natur\", \"represent\", \"base\", \"similar\", \"context\", \"match\", \"gener\", \"present\", \"network\", \"node\", \"mobil\", \"rout\", \"antenna\", \"robot\", \"cognit\", \"vehicl\", \"beamform\", \"consensu\", \"hoc\", \"secondari\", \"contact\", \"urban\", \"lift\", \"dag\", \"trigger\", \"sink\", \"valuat\", \"guard\", \"actuat\", \"preferenti\", \"vehicular\", \"zone\", \"manet\", \"legitim\", \"ran\", \"maker\", \"overlay\", \"facebook\", \"link\", \"layer\", \"topolog\", \"resili\", \"commun\", \"multicast\", \"ad\", \"failur\", \"wireless\", \"connect\", \"locat\", \"central\", \"protocol\", \"scale\", \"path\", \"distribut\", \"local\", \"cluster\", \"degre\", \"detect\", \"structur\", \"larg\", \"complex\", \"differ\", \"kernel\", \"index\", \"fuzzi\", \"cach\", \"student\", \"journal\", \"page\", \"countri\", \"transact\", \"ergod\", \"svm\", \"disciplin\", \"d2d\", \"migrat\", \"academ\", \"replic\", \"dilemma\", \"book\", \"session\", \"rayleigh\", \"matlab\", \"schema\", \"publicli\", \"speci\", \"repositori\", \"api\", \"teach\", \"websit\", \"percol\", \"arxiv\", \"queri\", \"hash\", \"store\", \"file\", \"singular\", \"memori\", \"databas\", \"web\", \"data\", \"tabl\", \"publish\", \"storag\", \"content\", \"scientif\", \"survey\", \"core\", \"persist\", \"retriev\", \"record\", \"search\", \"public\", \"collect\", \"larg\", \"access\", \"parallel\", \"research\", \"number\", \"paper\", \"set\", \"avail\", \"result\", \"perform\", \"bayesian\", \"tempor\", \"uncertainti\", \"chain\", \"entropi\", \"manifold\", \"diverg\", \"latent\", \"mixtur\", \"hypothesi\", \"codeword\", \"ring\", \"prime\", \"slot\", \"posterior\", \"margin\", \"reward\", \"lasso\", \"molecular\", \"learner\", \"explan\", \"protein\", \"reinforc\", \"beta\", \"odd\", \"predictor\", \"empti\", \"null\", \"suboptim\", \"payment\", \"sure\", \"model\", \"probabilist\", \"markov\", \"infer\", \"observ\", \"agent\", \"stochast\", \"belief\", \"parameter\", \"decis\", \"probabl\", \"statist\", \"measur\", \"action\", \"distribut\", \"prior\", \"variabl\", \"hidden\", \"structur\", \"assumpt\", \"process\", \"state\", \"depend\", \"condit\", \"inform\", \"predict\", \"gener\", \"theori\", \"framework\", \"random\", \"paramet\", \"set\", \"valu\", \"show\", \"estim\", \"function\", \"provid\", \"result\", \"energi\", \"sensor\", \"load\", \"packet\", \"cellular\", \"throughput\", \"transmitt\", \"switch\", \"hop\", \"overhead\", \"downlink\", \"pixel\", \"queue\", \"transport\", \"latenc\", \"prioriti\", \"qo\", \"wsn\", \"congest\", \"client\", \"buffer\", \"uplink\", \"tcp\", \"rf\", \"scalar\", \"bss\", \"batteri\", \"oscil\", \"deform\", \"lte\", \"control\", \"traffic\", \"alloc\", \"schedul\", \"synchron\", \"station\", \"delay\", \"bandwidth\", \"power\", \"resourc\", \"polici\", \"wireless\", \"processor\", \"simul\", \"system\", \"time\", \"perform\", \"flow\", \"demand\", \"balanc\", \"stream\", \"effici\", \"design\", \"devic\", \"propos\", \"optim\", \"cost\", \"base\", \"dynam\", \"paper\", \"transmiss\", \"data\", \"multi\", \"code\", \"decod\", \"sparsiti\", \"ensembl\", \"cyclic\", \"soft\", \"erasur\", \"ldpc\", \"pariti\", \"epidem\", \"colour\", \"sphere\", \"ml\", \"opportunist\", \"gray\", \"md\", \"recept\", \"db\", \"restor\", \"magnet\", \"clinic\", \"subcarri\", \"reed\", \"rs\", \"cf\", \"heat\", \"slice\", \"radiat\", \"exce\", \"spheric\", \"block\", \"sc\", \"binari\", \"lattic\", \"error\", \"encod\", \"bit\", \"length\", \"correct\", \"symbol\", \"construct\", \"list\", \"minimum\", \"low\", \"check\", \"densiti\", \"complex\", \"linear\", \"rate\", \"perform\", \"weight\", \"propos\", \"paper\", \"new\", \"base\", \"softwar\", \"engin\", \"privaci\", \"intellig\", \"mine\", \"interfac\", \"busi\", \"platform\", \"industri\", \"recommend\", \"review\", \"ontolog\", \"team\", \"educ\", \"overview\", \"vulner\", \"programm\", \"workflow\", \"patient\", \"hull\", \"uml\", \"citi\", \"health\", \"malici\", \"refactor\", \"strateg\", \"commerci\", \"http\", \"environment\", \"enterpris\", \"creation\", \"prototyp\", \"thread\", \"technolog\", \"medic\", \"plan\", \"tool\", \"effort\", \"architectur\", \"manag\", \"research\", \"grid\", \"develop\", \"methodolog\", \"servic\", \"integr\", \"system\", \"environ\", \"applic\", \"challeng\", \"collabor\", \"implement\", \"design\", \"process\", \"project\", \"issu\", \"comput\", \"support\", \"provid\", \"paper\", \"present\", \"requir\", \"inform\", \"base\", \"approach\", \"work\", \"specif\", \"test\", \"framework\", \"new\", \"spars\", \"converg\", \"nonlinear\", \"differenti\", \"norm\", \"smooth\", \"cs\", \"harvest\", \"subgraph\", \"covari\", \"patch\", \"width\", \"bia\", \"denois\", \"pseudo\", \"calibr\", \"mdp\", \"fluid\", \"prune\", \"veloc\", \"newton\", \"sustain\", \"jump\", \"lyapunov\", \"diamet\", \"discontinu\", \"ap\", \"landscap\", \"dc\", \"spline\", \"reconstruct\", \"magnitud\", \"residu\", \"sampl\", \"interpol\", \"sequenti\", \"risk\", \"method\", \"iter\", \"span\", \"fast\", \"algorithm\", \"acceler\", \"equat\", \"robust\", \"numer\", \"regress\", \"cluster\", \"step\", \"propos\", \"local\", \"effici\", \"approach\", \"base\", \"adapt\", \"techniqu\", \"comput\", \"reduc\", \"compar\", \"perform\", \"matrix\", \"estim\", \"improv\", \"result\", \"analysi\", \"new\", \"paper\", \"function\", \"present\", \"optim\", \"problem\", \"larg\", \"show\", \"linear\", \"order\", \"hard\", \"relax\", \"np\", \"lp\", \"hypergraph\", \"outlier\", \"epsilon\", \"revenu\", \"penalti\", \"crowd\", \"su\", \"tile\", \"matroid\", \"solvabl\", \"intract\", \"radiu\", \"l1\", \"nonconvex\", \"sdp\", \"scholar\", \"gabor\", \"primal\", \"influenti\", \"equilibrium\", \"unconstrain\", \"phylogenet\", \"poli\", \"bidder\", \"shapley\", \"tx\", \"problem\", \"solv\", \"log\", \"approxim\", \"perfect\", \"convex\", \"oracl\", \"heurist\", \"optim\", \"solut\", \"run\", \"time\", \"algorithm\", \"match\", \"minim\", \"cost\", \"maxim\", \"instanc\", \"weight\", \"set\", \"item\", \"find\", \"domin\", \"polynomi\", \"given\", \"best\", \"show\", \"case\", \"known\", \"consid\", \"program\", \"number\", \"comput\", \"result\", \"size\", \"one\", \"social\", \"price\", \"popul\", \"market\", \"evolutionari\", \"auction\", \"twitter\", \"neuron\", \"particl\", \"textur\", \"outer\", \"equilibria\", \"road\", \"contract\", \"compani\", \"societi\", \"mu\", \"gene\", \"ga\", \"tie\", \"incent\", \"genom\", \"swarm\", \"green\", \"pedestrian\", \"profit\", \"cultur\", \"cancer\", \"anim\", \"polit\", \"onlin\", \"forecast\", \"cascad\", \"interact\", \"evolut\", \"econom\", \"bodi\", \"individu\", \"profil\", \"influenc\", \"mechan\", \"human\", \"impact\", \"behavior\", \"dynam\", \"period\", \"diffus\", \"peopl\", \"studi\", \"predict\", \"activ\", \"strategi\", \"cooper\", \"find\", \"differ\", \"chang\", \"neural\", \"effect\", \"time\", \"pattern\", \"result\", \"show\", \"two\", \"secur\", \"color\", \"attack\", \"peer\", \"opinion\", \"parti\", \"camera\", \"trust\", \"rewrit\", \"cours\", \"fractal\", \"cryptograph\", \"screen\", \"placement\", \"semidefinit\", \"elect\", \"chromat\", \"advertis\", \"blood\", \"gestur\", \"id\", \"bitcoin\", \"tv\", \"multilay\", \"safe\", \"intrus\", \"confidenti\", \"p2p\", \"asp\", \"cryptosystem\", \"cryptographi\", \"media\", \"vote\", \"group\", \"privat\", \"quasi\", \"key\", \"inequ\", \"protocol\", \"exchang\", \"share\", \"messag\", \"public\", \"commun\", \"inform\", \"one\", \"paper\", \"base\", \"signal\", \"compress\", \"mimo\", \"recoveri\", \"spectrum\", \"spectral\", \"precod\", \"outag\", \"freedom\", \"stationari\", \"cancel\", \"multius\", \"amplifi\", \"polytop\", \"radar\", \"df\", \"mmse\", \"ari\", \"cr\", \"pursuit\", \"multipath\", \"scatter\", \"af\", \"shot\", \"buyer\", \"vanish\", \"mismatch\", \"pu\", \"ic\", \"sender\", \"puls\", \"impuls\", \"band\", \"regim\", \"nois\", \"white\", \"sens\", \"transceiv\", \"frequenc\", \"arm\", \"decentr\", \"phase\", \"snr\", \"divers\", \"estim\", \"modul\", \"radio\", \"coher\", \"system\", \"perform\", \"joint\", \"error\", \"squar\", \"power\", \"detect\", \"multipl\", \"low\", \"design\", \"propos\", \"measur\", \"optim\", \"high\", \"linear\", \"time\", \"analysi\", \"shape\", \"gradient\", \"cycl\", \"3d\", \"array\", \"quantiz\", \"smart\", \"solver\", \"max\", \"surfac\", \"descent\", \"2d\", \"sat\", \"affin\", \"minor\", \"multipli\", \"delet\", \"satisfact\", \"reaction\", \"friend\", \"firstli\", \"logist\", \"csp\", \"arc\", \"handov\", \"pivot\", \"chemic\", \"hamiltonian\", \"admm\", \"applianc\", \"cut\", \"disjoint\", \"trace\", \"constraint\", \"moment\", \"min\", \"loop\", \"behaviour\", \"variabl\", \"satisfi\", \"logic\", \"game\", \"formal\", \"player\", \"automata\", \"calculu\", \"citat\", \"proposit\", \"induct\", \"lambda\", \"win\", \"ture\", \"reachabl\", \"revis\", \"predic\", \"syntax\", \"axiom\", \"calculi\", \"deduct\", \"axiomat\", \"disjunct\", \"paradox\", \"fuse\", \"intuitionist\", \"prolog\", \"negat\", \"epistem\", \"intension\", \"petri\", \"polymorph\", \"abstract\", \"concurr\", \"fragment\", \"semant\", \"arithmet\", \"sound\", \"program\", \"declar\", \"languag\", \"rule\", \"compil\", \"proof\", \"reason\", \"check\", \"express\", \"composit\", \"type\", \"theori\", \"notion\", \"termin\", \"categori\", \"defin\", \"complet\", \"system\", \"definit\", \"order\", \"oper\", \"relat\", \"extend\", \"set\", \"base\", \"properti\", \"call\", \"first\", \"paper\", \"show\"], \"Freq\": [40073.0, 21158.0, 34029.0, 17460.0, 38045.0, 38206.0, 25132.0, 14240.0, 18058.0, 33703.0, 23716.0, 10766.0, 27655.0, 11370.0, 9575.0, 8829.0, 22689.0, 20610.0, 9479.0, 15768.0, 6223.0, 24292.0, 9564.0, 32677.0, 6729.0, 12017.0, 12097.0, 6301.0, 7521.0, 19133.0, 6223.579962816652, 2572.399094896417, 1402.4326419436352, 1283.748467695622, 1014.0494614401348, 940.3085674084018, 908.4696695659228, 895.5273376893851, 882.7985218589165, 723.9711535613324, 716.4538183806511, 621.0270576006776, 603.7926968982003, 596.5549252178881, 557.2961468300937, 522.0054612273937, 428.94459811858684, 398.72231234184824, 359.27007627572436, 357.70997734146044, 351.5016156094626, 346.4339085889658, 337.9567739138029, 321.43326460883, 327.0878768301252, 312.5763075853371, 305.03498813928314, 265.8947289720547, 262.7386536776771, 262.50963198549374, 469.85317725295374, 2649.0215318094615, 912.2643960311635, 781.3758266987126, 818.5532855076442, 1699.201339204175, 532.5128788121873, 529.8831542219209, 505.9578762859236, 1344.2443728349588, 1479.395675219414, 762.1869628081464, 560.734705305013, 573.6198312446094, 583.144520773114, 602.2792798559617, 554.5442575428876, 530.2021086615678, 17460.805104865638, 4715.598310218488, 5237.446516949937, 2545.711571188909, 2055.451475021381, 1039.3399616777206, 812.4996279703279, 802.1761374891653, 706.4519179838557, 647.7318207797656, 548.4367546210126, 532.4981952467897, 401.5667821311264, 396.10015499506227, 389.4728601613691, 258.88279335731727, 253.91444487944295, 246.60367809304836, 232.35257212662341, 225.24381574454105, 215.05681046547969, 197.38100263151264, 182.61439072368748, 180.0883582882832, 170.114233008893, 167.59255866596754, 159.90649346396773, 157.92491495835824, 135.27515977947354, 134.18174001237645, 188.0778185071554, 274.1218429985167, 2742.338859671297, 215.36636833783388, 204.26330227406044, 1735.2627282327544, 1542.1665406004033, 1211.0891664066314, 446.1388499466669, 860.1931974689078, 1144.5333624863217, 575.4959764982881, 657.7450150764365, 1467.270024461764, 494.4657682072742, 682.0705132122702, 689.5631098712163, 628.0749163939456, 551.3048511714953, 636.6525447737589, 828.3446267897821, 716.1402959573289, 640.6381177618218, 669.3193293706959, 658.5705710982826, 5302.90428639042, 2559.1706404454394, 1805.7780835495184, 1510.4360011848455, 834.4596458464139, 830.5687620160985, 813.8658372889715, 809.7865106767259, 963.7218955086147, 784.4884502163934, 583.7365627897835, 570.6422407338612, 546.5349318278833, 464.3354243224013, 447.98268909836116, 430.3935853782429, 400.12733821618264, 389.09190675836055, 385.36376548504126, 385.6352073540532, 361.04112622946764, 372.12677079442597, 349.1672392961919, 343.80067995729854, 339.8057312817587, 305.23168978505186, 285.88842123371063, 278.50801371776384, 261.37666892208415, 238.92878638775522, 763.3941958482399, 12169.534354229354, 1382.723272088857, 400.38430216414383, 5016.25615731533, 472.3638911615712, 649.5747555624545, 1792.072777904704, 2409.403211615509, 895.5970721416329, 1904.8669668923785, 867.6727627643523, 779.8438718611144, 552.7639616065129, 519.9790157981672, 602.3133058543834, 528.2319287150018, 468.2818451514563, 1541.0190840809823, 1344.1758926580997, 1274.407621712689, 1416.9816153886104, 1075.0433808200805, 886.7666478254141, 757.8782033045815, 643.0117339362747, 633.986481397494, 622.9105148693512, 565.9360003126225, 555.4494821198222, 549.3863665298876, 528.194931915779, 517.8751223978558, 479.7488977755342, 464.6459796293371, 461.31170748760684, 495.5737433992986, 412.38396912452527, 406.4574510715944, 392.09954314256294, 386.6843225683641, 386.4774163875624, 379.98110485341294, 358.95470196301414, 343.1960712493156, 341.224667185753, 299.18766913581294, 299.68994067149697, 483.40307301349327, 929.9348234209077, 2377.5928078706484, 2770.502860970092, 1463.622362275052, 821.5353682634141, 11126.988457920374, 634.6137597782894, 3181.548055858958, 1327.512423484354, 1249.7952067170768, 4236.410315821197, 1240.7195469990877, 2041.7778125236139, 2439.5873250690934, 3675.0921458026733, 2265.6928157953857, 4647.679235724632, 2096.9378659172116, 3264.916006195268, 4680.841438280973, 1369.6317154467297, 4482.6846022288955, 7461.087977398799, 1331.3631965856446, 2783.400391042781, 3906.548102541701, 3568.0860890990125, 6597.646733870108, 2952.4025432518674, 6666.551670896864, 4990.365193225452, 4057.356518314693, 2532.9743681213367, 4918.167907836149, 3079.4546769222998, 5313.625742979811, 2577.835573886604, 4555.499794801292, 3168.5562219441495, 3299.250101685065, 3306.750216459185, 2743.231491932282, 3243.2231631821055, 2898.6753953087227, 2609.1894312193654, 9574.91560023417, 3955.2608952363853, 3079.535246209015, 2362.5009378762293, 2024.5271187432354, 2044.9466668786113, 1668.1510835643207, 698.8861584027367, 673.3161808122163, 651.9027787395685, 650.5131818404359, 619.7638719487292, 594.765410867961, 549.2110148442054, 471.52381961937294, 404.25713435466656, 425.5485289058367, 317.76418933867075, 294.5992555593848, 265.4031730720641, 262.8452471517332, 255.97442507948819, 248.48627957427158, 242.64131617147964, 228.62771596315184, 210.91623465549887, 200.4694668685195, 180.61898258873924, 180.96337610989906, 177.05920755949833, 8318.826573646, 2366.2591735043106, 1781.9603921128721, 883.9442526499404, 4858.63747867803, 2240.4666776590557, 1442.0760996656388, 1935.4571074862354, 3913.7604479859874, 980.6238398385392, 1541.8534371453165, 1500.0934894668958, 2977.4176919338506, 2070.5183276631606, 1289.6246958755787, 3959.4767672753387, 3898.2800644094805, 3500.1529303436123, 1341.803999323934, 2886.7046909394576, 1066.4188364275715, 2138.9696929767765, 2111.3839703083136, 1356.0988372088884, 1160.0091373864946, 1306.023814844404, 1398.2810261323127, 1459.9923054584833, 1343.3668690255436, 6046.12267321516, 3213.470341742795, 1348.5959643497463, 1165.8624118168595, 1135.4266904916046, 1133.3864913767857, 1072.3777265773722, 1103.7909359146302, 735.5042846661199, 675.5078868270729, 649.2450258492873, 553.655812868518, 536.4136570140676, 490.5135093786331, 467.9581270567857, 429.6629611924729, 405.4002104753335, 376.8214641037605, 369.59123908364995, 370.4320904606716, 359.4198577109968, 307.8343592306156, 278.33419988587906, 272.0754577758125, 271.93868403804686, 274.97592202193084, 217.2045926922527, 195.87362049719965, 186.10098886283603, 178.83923020230233, 18028.822236777894, 5614.049280548744, 1284.9537292666491, 1325.5734454207266, 2917.840323972632, 1824.535776788204, 8621.603963188534, 742.2161788993451, 1894.2541879135963, 4954.368155270591, 3055.5446057569, 3118.4721514452253, 2684.9485403660287, 762.1123156140326, 5010.455697883902, 2157.4395446785393, 1940.808151307508, 1814.0791119416706, 5372.908954700818, 3208.8595202606834, 3724.951473517136, 2481.251094633171, 1183.7986368073011, 2943.604898590619, 1429.2727268305252, 2331.269203660441, 2272.453425318835, 1889.2868991919192, 2164.0735645301975, 2397.061868497053, 1881.4974867551578, 1771.9931637695888, 1434.2913468346997, 4228.52592482075, 2454.8332658521194, 1357.9304558798226, 840.2143341927521, 704.9431121414013, 703.8431663858697, 601.4371023382606, 572.8859779387508, 561.0717672085204, 505.65451229845473, 454.7468567128506, 436.49573489753425, 424.1905151564169, 411.10610774739195, 342.69313635429427, 335.3923578227143, 323.6479187732087, 651.60701877916, 278.8161932902381, 269.608136450915, 256.5465480138039, 251.08964937678854, 250.04851149906986, 245.80282338981812, 243.34352206230133, 230.14459639481456, 229.10905183931303, 229.9313370576906, 232.47291147534966, 211.7110342249492, 503.2279463906072, 1214.4050946949237, 1199.8966853882087, 1707.3031777373096, 834.2970004017498, 423.6867596104374, 435.2775939984179, 2911.6738969429734, 3673.507914983365, 842.1981585635067, 1063.9769053694959, 457.0913278037739, 909.2019693043192, 586.6049042992142, 1178.971599006659, 686.1043572310004, 822.6761715448279, 799.625355310935, 801.6110515504794, 809.117423670806, 679.5758582801276, 943.3312181291363, 668.4578044664859, 643.007430717284, 615.4103354443102, 596.1359253572351, 592.4446001037443, 40073.7548155399, 10766.68851726605, 4865.374633416521, 3201.6473311815985, 2971.347907350034, 2090.8404603486465, 1652.6246155059202, 1203.7578215512603, 1063.4081836438402, 993.5115805611875, 856.5553347202352, 772.43155143697, 632.2763741005699, 578.1889846430402, 558.9510133761944, 416.54062940980987, 374.52171746161747, 345.0822554737383, 339.41038863322666, 324.71679360088666, 325.1094967555776, 316.8665375661605, 310.47528683579407, 286.88329228907315, 281.46406890295066, 274.2592847095116, 269.22196946183715, 267.934983117004, 249.19926813952736, 245.33189721602977, 3557.429426420881, 2409.959975411507, 2297.7268715037258, 485.22686321186814, 6805.829847718098, 426.61758922420876, 1236.6031236869824, 877.7163717576767, 2472.8718272884084, 2544.318304164816, 1439.79829049448, 1166.199580630419, 2039.765356305261, 1951.7647846365323, 1430.3075927339016, 2483.816721436598, 1674.130892691602, 1237.1821974121212, 1179.6402023853452, 1079.1104990570734, 1245.5410965787732, 1038.069901109916, 1045.7048579343787, 1027.0839307978324, 2456.619674695438, 2242.798782370789, 1714.4538369072634, 1098.0211394942753, 990.3250544365106, 793.4374685886023, 701.7446346095421, 690.9629298890394, 651.4763335655094, 624.859248624232, 572.9783376386611, 458.72364395220876, 450.1971657060907, 439.6538179218716, 435.8278877142546, 530.4646533288588, 387.17063845528685, 381.6283168841923, 366.7363594038293, 351.7012565485194, 348.52802988670703, 395.0319068996969, 321.86766509918033, 312.3179085933985, 307.9411905745602, 306.1064203232363, 306.2723434855744, 294.38483971850434, 291.6687064589321, 289.17407744326204, 4183.339155343349, 751.0055054854083, 1344.7974512685184, 939.4308255355419, 718.0831353546931, 2568.0150692453126, 2308.9651589315845, 2683.112643575537, 17075.19056502648, 734.2981316972833, 860.8444657350155, 1681.134054867644, 1726.6771643984282, 923.4019058791473, 1048.8058651973095, 1248.8405990881627, 595.8077492141506, 944.8359883328762, 732.1674757325202, 1741.67614262603, 1009.2397618895279, 1129.1362941407717, 1498.1313653689915, 1168.0428872192076, 1032.7134711666902, 1120.1416308785715, 1310.5804991332711, 1275.9094673984357, 1191.2242371370544, 890.5745012850626, 944.0743778504176, 891.4890571266021, 2328.3927078266142, 2255.130489073026, 2029.1648516590328, 1822.7498717189749, 2231.354054164726, 1088.8396741041843, 1001.9402152369499, 938.6846020051867, 934.5238671535709, 849.2911164432824, 615.5082980179693, 612.7072292396829, 574.7052816183865, 564.0762449048893, 556.7084548478213, 1000.6689634148, 530.2121741298203, 520.9106032376797, 524.8186800802971, 473.8157282312923, 463.246115911017, 413.28538637511593, 406.18354535826944, 400.2937886018723, 387.8966273844882, 374.9792218169365, 354.99936676710513, 357.1052568253341, 345.4494397939465, 343.2892298689799, 399.9160857459807, 35326.48948974435, 2696.020833635362, 2150.1491922017035, 3307.468625302871, 5569.224597128764, 3830.603100578839, 3282.7845477985857, 1478.8315330387709, 809.9476093709025, 3824.509002243373, 6294.773130907252, 3872.0274566361295, 7394.65001122003, 1846.5138502984958, 9054.701095135828, 1706.3463781887529, 3784.6847065632724, 959.6570787805864, 6689.583791258697, 1853.3842219068442, 6355.576452566544, 5183.864309432067, 3230.3600976875186, 3667.20175014937, 6300.627862264943, 2754.915383428959, 6496.283656118127, 2915.429433896893, 3118.419822333027, 3024.4952508659103, 2667.7531859155188, 3410.556431784012, 2596.807073820277, 3172.5270325711163, 2738.639713097838, 2908.799585008165, 2814.7869203292707, 2900.7394413777733, 7474.118785321149, 4426.533630899795, 2104.444985396573, 2078.9813894556446, 1933.829795989745, 1961.589457125693, 1771.8456285315654, 1520.189082131513, 1098.47795891727, 991.6350534134441, 791.3167688540778, 783.2297513069386, 787.4285225477746, 797.4189352772911, 756.1963022793141, 684.5377463094867, 670.3584859056173, 672.5376735398366, 689.6940728022824, 692.5287671336333, 600.0113568119898, 592.2292821932366, 530.6774996613052, 520.2880768627821, 478.6158167153691, 476.1485699985163, 470.2952163307691, 466.96227626558084, 461.64572552227713, 459.31041400008985, 9112.046986782208, 2247.9357597496814, 2688.587732438263, 2779.706195540419, 1312.807630214167, 1326.7626455809814, 2375.651922559455, 1218.9561893371122, 6173.142527246419, 2837.209955454304, 1681.985528790388, 2771.216584414154, 913.7409830957871, 3362.1197611224343, 7282.270333668737, 5352.3478041543885, 4542.685944383236, 1471.4567901974742, 1242.8247097931992, 1134.169995355996, 1162.0525295408281, 3114.7307617920383, 2744.4425263882117, 1515.2176509781204, 3362.0762076917586, 2950.281001544753, 1876.786241471512, 2857.53176568388, 1889.4485744765948, 2195.8665307583988, 1634.5550158206904, 1745.7498187092785, 1638.4089431262398, 21158.44569942429, 6301.741642243924, 1708.686173403882, 1097.3499473409233, 1081.8735182426867, 983.5043776037473, 944.9460106518158, 882.8121608827007, 882.0599294835158, 703.1767518377585, 594.662024270529, 562.4366050557816, 546.3686524919664, 507.99395174987046, 487.1521850918984, 407.61349798443985, 402.6375814889297, 355.10934064606994, 352.28355948016065, 350.57603768559466, 331.0892441409983, 322.8690797173965, 297.03997540124453, 289.3771869061024, 286.9052588688964, 284.1518020706544, 284.22948916698647, 281.7237034698865, 259.32909350467213, 264.72576679244315, 2674.4216568622583, 635.6529249447727, 2289.321850407112, 1322.7553469197633, 4678.958845240835, 2117.9642913535704, 1904.5780131844122, 1753.6089107842008, 1350.307133609355, 933.9020362274355, 1608.5465786248033, 710.0431316446075, 926.007983682093, 1095.9644501557425, 725.9816830151294, 779.600273345471, 1112.717614504295, 1022.3595208587561, 988.3713002626125, 1023.8999284330408, 799.9780045414719, 906.450315155955, 847.4701556698043, 798.8076542327747, 811.6450990489689, 6016.403952662281, 2587.3309562630816, 1715.8019459757284, 1467.270209547389, 1394.7629901029593, 1453.4964205827187, 1222.2784680081475, 1815.1530040154153, 1119.233708657807, 1086.0804652324864, 1797.6268794874613, 888.4734753310653, 856.4000259322985, 669.4876286148111, 664.4969171075758, 614.53463195069, 604.4621141454809, 493.3112976715479, 492.88417857525536, 477.99563314674066, 475.6773027980823, 463.72422284984714, 453.92316110591196, 414.14742262081086, 400.36773174012075, 455.2726149584295, 390.1012846726569, 358.6942385740233, 375.1472408065761, 349.2095066984898, 429.80979263614273, 678.2872570976057, 574.2039529815879, 3415.2791922410706, 622.6503438390756, 1862.9877767497348, 4029.4248750958127, 1180.806730558157, 3412.4583329887164, 3135.3857005044224, 5037.715392836182, 1818.7984635777343, 8407.780776265752, 1519.0369413760254, 3647.5609010269245, 2993.8177239660013, 17518.04865399882, 2586.375102472941, 7127.716776811612, 2875.5841271340155, 1119.4038378021999, 4296.10474667957, 5331.147366711848, 5843.731339069973, 2355.2755731263296, 1945.983727381282, 6257.07023127172, 2560.7890135024827, 4752.806298902999, 6425.200422369243, 4783.087746974665, 3473.6026961625075, 4804.187866560091, 5986.79378338659, 4358.484919746869, 3386.4398645185565, 2785.4277410428735, 2763.774124376821, 2904.4996665546964, 3340.1306087727976, 4826.429039519275, 3258.7516179862796, 1953.5695219269896, 1792.988171162308, 1670.4672311748948, 1192.3041215282403, 939.5449278450534, 884.7045106724141, 888.9716001685076, 796.6644666514175, 711.9062335229409, 702.5444090810598, 491.296635697505, 477.35841666932106, 497.7661630546405, 482.46742998049615, 397.3634105382445, 361.60831324463584, 354.69504998716627, 338.2443026976344, 326.29812981650576, 313.1911615252762, 313.8958345530693, 291.2457779713628, 284.68015721516855, 264.3735908965772, 260.7545785574716, 270.3046097031182, 247.2988433436924, 228.36405313176095, 2687.224347432889, 845.0073708707614, 585.589461489053, 6291.393326232501, 686.9427961811305, 1202.0800185663625, 1303.8978998763266, 19431.315513642083, 3280.267115654285, 886.5591275526135, 2251.818731033245, 25173.959845624082, 786.1925706924752, 2235.7671354481245, 3188.5160530772164, 3630.0302397569963, 1562.6355879309683, 3937.5154095142407, 2591.0909689510486, 12051.367595852773, 4089.8295867194843, 6514.928561125862, 8469.17245025011, 10938.051463040732, 2970.892918156257, 4843.875488619113, 8071.3709080699455, 3107.5819945505086, 3937.1090472353085, 6599.262298451365, 3125.043864284966, 4358.987340266711, 3999.353011036915, 6312.232886083056, 4384.113550973941, 4625.573560207626, 6027.80156508068, 4634.042058719029, 4719.416688881291, 4422.812490251344, 4922.981630808896, 3533.724664188581, 3905.176625315103, 3399.2438797851805, 3377.864883290281, 2839.8344176860337, 1456.7742399627891, 1888.3359501376633, 686.7421613195212, 622.8831462938463, 529.6730052098931, 531.5731156191546, 485.10787901261875, 477.8049795234999, 465.9850191507002, 412.85767248897236, 409.18654744705685, 398.59529070431074, 474.03214780630515, 369.488627667068, 361.1512628893245, 338.8437913399758, 272.9958552148147, 266.0248531855867, 251.14558796300886, 245.47777704536216, 262.4243587232129, 229.36048026678208, 1405.1786101030045, 221.70515848253396, 198.39281954438292, 181.5464833366538, 178.9030442710616, 166.3396702881429, 164.08207433797307, 26635.71862885037, 4972.247086993427, 1622.3725525224886, 6254.089107701218, 949.7172244796125, 2584.5223221511324, 528.882900997758, 1197.2950591702347, 9410.1470793111, 4427.490774552364, 1816.7498103859211, 9513.459585077244, 13001.974760097924, 2072.8599278260217, 2571.688999010706, 2643.92853533855, 1991.3449330091878, 1408.2615490966707, 2189.1362457513255, 5197.398276960559, 916.8025248753288, 2459.6818468150027, 893.8826724388404, 1952.9273347809863, 2502.3283766586947, 1512.4233208930787, 3700.6294246077364, 2638.327837913612, 2019.4969873187501, 2280.1637541078508, 1946.7901371925632, 2439.023260332336, 2292.947328309884, 2157.632390699079, 1743.4803622925024, 1701.3568759322382, 5816.844078112211, 1459.0631309586038, 1345.9247368769948, 1244.9402426148372, 862.4157782548449, 783.1250849822924, 732.9750463310362, 713.2892221711414, 715.4704642421673, 667.0790956051347, 573.7119387290282, 568.9285086302409, 535.6469046049248, 557.6951098248524, 484.37712488932993, 482.93592951707245, 440.25418334312366, 391.97146386580965, 385.9219436966824, 360.7779007024343, 361.6921112767658, 383.72367036706333, 351.95091603520007, 334.5093453239151, 331.46068584758194, 329.35353830985764, 314.9592363314278, 313.50308511776757, 308.267149883319, 316.0177846827308, 3245.9055855901424, 470.92675260355554, 555.7733162986763, 2845.158872714483, 1492.3125981115495, 688.3290996528565, 720.4065765787947, 2064.8838276438, 820.0640020181114, 1207.4018081596967, 2461.2505116135303, 1967.003900745795, 1666.6305252598627, 1926.1228892272684, 3146.518349514537, 1006.5160590324341, 937.3249021056156, 825.3753583411792, 3354.439720125048, 1752.1671544727549, 1400.6246890990412, 1697.0353443066833, 1199.3195773230027, 1531.5616898368394, 1822.1854828282303, 1115.0751841578385, 906.2769176903153, 1299.583538087192, 1328.8066103066049, 939.3814907688982, 1075.746242360853, 963.5399459543089, 946.774511929961, 5057.2419516189175, 3621.5997175854004, 2906.9851159596424, 1003.5106411241553, 832.2705097208245, 779.6894589970792, 737.1143295928287, 666.0304381329096, 588.5472840775185, 570.8025595241212, 547.1307172623549, 479.0634008339938, 531.3937666520695, 463.24388440071834, 401.06393978376497, 382.0741901617258, 382.33773403405934, 309.3644403982306, 306.13571406481066, 319.7472766480029, 290.259328093781, 284.51844892111814, 275.259516665098, 273.663749209439, 274.42143243037486, 278.7656416497486, 260.92813337392465, 257.1282654285632, 238.832272211705, 229.21655775099217, 470.16638138047665, 1115.9846887269653, 585.3282560893265, 4478.416306116399, 767.1365963544546, 711.0363451984745, 2601.183302066252, 1049.0233300240661, 2734.5093980557936, 806.1797096559906, 1174.9282868821053, 1006.2626331749624, 717.0382787128877, 1159.1805122258065, 1010.4271199343301, 707.5887133584802, 608.8566147971395, 599.6049563000404, 8829.3341204428, 4238.755140976352, 3186.4009132529936, 2245.0848463259335, 1951.199074921051, 1836.9780489169211, 1329.4649498957767, 986.1696047400657, 895.8284361481558, 821.2450293094053, 736.5372080518507, 641.7392065488161, 481.3693737649868, 415.6001634559946, 429.56295142584224, 372.0369116355662, 367.84942559255967, 339.25430529859005, 336.3836937894421, 326.751833048828, 338.20491377230206, 333.2287104138838, 298.5616269493392, 285.53075023432314, 283.34402339427515, 278.6726373113356, 282.2449542786972, 263.81464472805374, 253.6743114186542, 252.74782057459896, 318.858744990319, 274.0360369522902, 914.5244028837925, 1148.6516099420376, 4520.094924693381, 468.710489381105, 3499.3298619869574, 420.7562103382744, 2501.7525938600274, 562.1324673063714, 509.2027837025, 1792.4947727073986, 852.517870564828, 1207.944361303648, 3760.948631743092, 1146.591245239525, 1029.1280908697427, 646.91259874558, 4599.236421520353, 3039.6531623384985, 929.3478760089728, 1679.0080316830956, 937.3160700399575, 1780.6543132937798, 1449.5769924454796, 1513.7569383148661, 1293.1510125045018, 1538.9332058328912, 1506.6595095013597, 1262.9554065696705, 1239.606863527437, 1094.107747027975, 1096.9131994938966, 1153.2484225840867, 1029.7609666205901, 2581.9721711783804, 1759.970688764114, 1640.1061427070472, 1419.635758505192, 1456.307082870081, 1293.6924674453733, 1157.781356833332, 1060.8663586953976, 962.3320147054261, 1231.5503286258402, 653.2096761717395, 624.2844259576509, 598.6361404533897, 610.6691528018569, 512.5481676041107, 506.57411812451784, 504.8554483992517, 472.5310284394234, 436.86430591244346, 427.4876261049443, 388.2641482174452, 364.2761673959392, 366.04346604821774, 390.53274060431636, 354.4470810332603, 353.65659626059806, 301.7531579361624, 301.6867095935161, 285.43005671074246, 274.55378268931355, 1361.3474686077027, 597.5803529897032, 860.0531658597785, 3667.3402780208203, 577.6459018463005, 542.9791842645009, 644.2212530231382, 541.5763055745549, 498.7708152417687, 454.99904772730616, 6420.746822986078, 6236.75914395536, 3106.087856751591, 2379.1046825146555, 1923.7496706734305, 1489.9778713236246, 1310.9636722343744, 795.5761269354823, 736.67327410148, 660.5856340325538, 634.0905182946148, 607.0471182430132, 541.4095080365012, 486.49916804772266, 413.4505702393567, 403.0485866581812, 372.94750674574027, 292.6867385416136, 291.6033372578623, 289.2740729071483, 282.52822979317386, 277.519120569095, 252.8578478799079, 253.73258065456136, 224.21258239133888, 222.528929355225, 205.8742245178468, 201.06140311125188, 196.86471172427022, 193.92509016909432, 2019.977004785153, 902.8929784412705, 710.9235171466473, 3910.3625632167746, 777.4418870920589, 736.8355906566372, 4782.30947651737, 353.8757714036069, 3847.903656249537, 2009.1362146384474, 572.9665960102195, 1952.863635502003, 1651.2282589261656, 1170.8305087069261, 2031.015305085465, 1024.4853603924562, 2627.7713213666248, 2622.8726822823814, 1373.8641693048462, 1033.4909520285714, 950.0860932714028, 1765.283788961925, 1590.9608432956315, 3243.5671228180113, 1081.5989067809708, 2018.6596895155624, 1754.3390155284678, 1515.4752703297445, 1274.6241276197106, 1637.3481360627914, 1759.6619141681533, 1353.8311210631268, 1230.5272749034627, 1302.4328795165359, 1385.0546686058779, 1352.286669116889], \"Total\": [40073.0, 21158.0, 34029.0, 17460.0, 38045.0, 38206.0, 25132.0, 14240.0, 18058.0, 33703.0, 23716.0, 10766.0, 27655.0, 11370.0, 9575.0, 8829.0, 22689.0, 20610.0, 9479.0, 15768.0, 6223.0, 24292.0, 9564.0, 32677.0, 6729.0, 12017.0, 12097.0, 6301.0, 7521.0, 19133.0, 6223.725577498294, 2572.543359659872, 1402.576179303965, 1283.89205826457, 1014.1981583381995, 940.4508571721038, 908.6120197436052, 895.6692118228784, 882.9410629252563, 724.1136873146618, 716.5966803984837, 621.1700060975427, 603.934538357063, 596.6969300830258, 557.4386581541227, 522.1488271590915, 429.0857486168079, 398.86361776171094, 359.4109672180317, 357.8508744751947, 351.643556879878, 346.57498507777365, 338.09797542337066, 321.57380665244716, 327.2316097288624, 312.71734121213956, 305.19358068199364, 266.0357509819569, 262.8794330273201, 262.65036190286764, 494.73799716019835, 3325.6249704881234, 1081.9841979679568, 950.1854830228123, 1042.4774807637257, 4319.3534212973445, 857.3343573045541, 938.7515198288454, 859.2644113329771, 11834.568098383554, 22689.665747929223, 5950.518883519344, 2129.790040732173, 2421.0887388523734, 3971.018830276984, 8778.326624199919, 2905.3513926615283, 11797.877362075173, 17460.95189386083, 4715.743517842357, 5237.611766691104, 2545.855785972442, 2055.595498745979, 1039.4874350505752, 812.6422391571276, 802.3187610143327, 706.5945339769058, 647.8740678365949, 548.5801514606331, 532.6403201735595, 401.7082400839874, 396.2418342174414, 389.6158246125196, 259.0247739862415, 254.05548621924208, 246.74506995715913, 232.49319561371428, 225.38989700227728, 215.1982623233784, 197.5217528374229, 182.75501470193092, 180.22932064343786, 170.25457079807026, 167.7340757988167, 160.0473878466028, 158.06482247658275, 135.41558286642706, 134.3221405599039, 188.30374999548684, 292.5896327874169, 4172.969619299854, 227.100564258191, 217.60397210887376, 5883.185832596919, 5296.013152898153, 3966.4510884794868, 800.1343703185798, 2816.6371321466863, 4950.609303096822, 1878.7556703234068, 2545.0803453072804, 17473.430588453826, 1404.297723647732, 3585.1775325700773, 3691.1837678787647, 3115.3374710491544, 2757.03538504818, 5592.830279763229, 21046.41731729431, 13298.403005713531, 9110.115534679499, 19211.58808327248, 24492.24326687202, 5303.048876728159, 2559.3229692627137, 1805.9222424543302, 1510.581062705609, 834.6026105766139, 830.7114981434473, 814.0090496246287, 809.9292806889873, 963.9044929496258, 784.6416042089674, 583.878350261852, 570.7838996776001, 546.677795420651, 464.47575189090344, 448.12478900707714, 430.5350187994511, 400.2698040794939, 389.2337584227417, 385.50503146667654, 385.7776740904888, 361.18323412244257, 372.2781330972685, 349.31084341896565, 343.9422700502222, 339.94732097820605, 305.37321869782363, 286.0315582214637, 278.6516633162733, 261.5182460261206, 239.0695107000867, 794.257550701735, 14240.413517012856, 1606.2151839305216, 415.64370343912054, 11370.107244089708, 538.0197587449171, 934.2144595747938, 4888.135859643001, 27655.41326943416, 3480.6088633532545, 32677.685093201624, 6834.24376697141, 8841.970302605623, 2275.6158318146645, 2273.6000470035237, 17473.430588453826, 29086.547356166746, 19211.58808327248, 1541.1649839648169, 1344.3195505390765, 1274.5524237650995, 1417.1433446299493, 1075.1862842611192, 886.91155921873, 758.020605087149, 643.1540387631462, 634.1299237487493, 623.0537196534902, 566.0795189272432, 555.5924239112495, 549.5284244493582, 528.3361213163774, 518.020235123657, 479.8908283969456, 464.7874911105603, 461.453572540137, 495.7337471152904, 412.52645959668337, 406.5987126844762, 392.24107618206585, 386.8258578161458, 386.6191169646592, 380.1227033666063, 359.0962033652316, 343.33774337285774, 341.36961732598354, 299.3281366459148, 299.8311381674343, 494.2419673019452, 996.2230633225595, 2705.925212855777, 3203.942946205879, 1636.6023001703736, 882.5325677598053, 15768.111957661276, 670.5874027774529, 4027.0254671545836, 1530.4589249949324, 1436.6196473338346, 6079.251546628118, 1494.0956214285475, 2706.5084340935555, 3407.548997687597, 5628.3056120858255, 3147.6912719918296, 7560.758607077771, 2897.845246636681, 5092.194446430167, 8362.266982671392, 1745.6022902825748, 8465.217883411871, 16752.895461319902, 1717.7818307182729, 4780.988147389758, 8341.930773265509, 7803.876609789046, 21046.41731729431, 6077.7331695164985, 23451.584511062294, 14857.886903714723, 10957.064621513624, 5109.083059997206, 17473.430588453826, 8222.134480283214, 27001.262396623373, 5738.659754294443, 24492.24326687202, 12947.914171060023, 17312.92061440663, 19211.58808327248, 8936.82651679339, 22689.665747929223, 16434.2483871248, 9110.115534679499, 9575.06294775889, 3955.406522497578, 3079.683235425719, 2362.645679562237, 2024.6744510742917, 2045.0979617137334, 1668.296247623929, 699.0300017547496, 673.4594787858819, 652.0488556124552, 650.661271527984, 619.9076839451193, 594.9094221635028, 549.35416158828, 471.6667513228153, 404.40038884140137, 425.69969293756225, 317.90668005257345, 294.7421932437647, 265.5459752273855, 262.98832242500123, 256.11744824027187, 248.62869968199772, 242.78333293272456, 228.7706479981846, 211.0590926696207, 200.61292818216282, 180.76105232793623, 181.10594942022735, 177.20140091717167, 9479.547422618143, 2716.473222590335, 2072.743623534609, 993.411253808799, 6723.747411565668, 3089.878754934893, 1887.0173548506946, 2737.349987025277, 6867.09023487258, 1294.6876483910473, 2260.782078854385, 2703.109009540841, 6999.802132838204, 5084.423198076734, 3018.0260477617257, 23716.239768326555, 25132.538582066896, 27655.41326943416, 3777.0951138865344, 32677.685093201624, 2430.520471810408, 18774.71676976066, 19745.675797594227, 5902.899732870918, 3701.325384985229, 6834.24376697141, 10661.106691228777, 27001.262396623373, 13972.381194182295, 6046.275487929797, 3213.6166372067046, 1348.7376596303684, 1166.0037744230342, 1135.5685537670563, 1133.5352099154409, 1072.519579453354, 1103.9758181751813, 735.6451900694635, 675.649972233823, 649.3857937879923, 553.7961082260018, 536.5538660198096, 490.65412721675096, 468.0980339071074, 429.80255883982295, 405.53985876720463, 376.96285386966036, 369.7312040102197, 370.5728705640314, 359.56236258121584, 307.9751303418614, 278.47377192496805, 272.21519382194424, 272.07844733109647, 275.12739250313354, 217.3442256971529, 196.01256869691636, 186.2403128092184, 178.97805411504476, 18058.808027831095, 6213.166748266636, 1393.2922345917632, 1447.2436391686292, 3374.196704692561, 2095.238842285692, 12017.793866525813, 838.0882271444249, 2404.942832028011, 7186.085699596274, 4315.469838116415, 4941.6085444609935, 4202.035678238237, 896.1777740561992, 10356.917597645373, 3627.3354837551406, 3321.603633698934, 3375.3778807048607, 19133.00715721098, 11370.107244089708, 19211.58808327248, 8841.970302605623, 2115.7586453368576, 15768.111957661276, 3246.9775255024565, 12182.671683821794, 12947.914171060023, 7313.030402304907, 12097.297848100447, 20610.57111389147, 11834.568098383554, 27001.262396623373, 5950.518883519344, 4228.669556066391, 2454.976811134073, 1358.07307429147, 840.3574026501045, 705.0851129798033, 703.9870003549569, 601.578471703034, 573.0291967059976, 561.2132018111926, 505.79520054584026, 454.88803856394685, 436.63673811591815, 424.33183776307396, 411.24688199754377, 342.83352467016135, 335.5319681758454, 323.78826107511287, 651.9256598625462, 278.9570449298503, 269.74809385276274, 256.68604602646, 251.22836570477395, 250.18825801247752, 245.94177605104596, 243.48260121718332, 230.28457082958053, 229.248454469245, 230.0716346189173, 232.61698936096093, 211.85069894231532, 513.7747586200522, 1364.0564975802356, 1359.2906826510498, 2200.9204655510903, 981.2693785124188, 457.3186762025662, 478.4030832317932, 4813.401300395556, 7521.694668153186, 1190.0167571755678, 1730.5052409076316, 574.6277520884246, 1815.7572696429293, 1011.4647688992505, 5089.61758990614, 1649.3151275831776, 2703.109009540841, 2585.3542702712984, 2737.349987025277, 5214.014813797594, 4934.2611929706445, 32677.685093201624, 4620.077227230276, 3784.6675437606623, 3973.319073791375, 23451.584511062294, 18068.17700006658, 40073.908858808805, 10766.843379379587, 4865.519868621643, 3201.793217283638, 2971.4914013230527, 2090.984315112312, 1652.76890902576, 1203.904786012438, 1063.5505941964066, 993.6544738181364, 856.6984848113324, 772.5746066453426, 632.4196394087262, 578.3307996307951, 559.0932319854679, 416.6819899529179, 374.6634754932726, 345.22527144190724, 339.55181756025104, 324.85784226582734, 325.25170710290007, 317.0077688129681, 310.6168454066922, 287.024394056214, 281.60583808345103, 274.40087104817957, 269.36188843282054, 268.0763613107116, 249.34047553953891, 245.4732149764063, 4637.958259429908, 3252.587397527305, 3113.8277685190783, 538.3074618962988, 12097.297848100447, 483.3175238229682, 2050.7565817672994, 1298.1849740978341, 5441.168934790865, 5883.185832596919, 2956.828230054277, 2167.5666219652503, 5554.701558721264, 5986.035161959313, 4172.969619299854, 14429.033129666506, 7008.28320513234, 5677.4999267131925, 5296.013152898153, 6867.09023487258, 13298.403005713531, 9598.174690435293, 14857.886903714723, 13972.381194182295, 2456.7629499796913, 2242.9821342821942, 1714.5978375614077, 1098.164309334302, 990.4682572307107, 793.5805953309842, 701.8908134749471, 691.1112774081042, 651.6205113671318, 625.0011456322111, 573.1210375154789, 458.86580839754606, 450.33758400238554, 439.7954339460123, 435.9699104547364, 530.6382312012342, 387.31188051838836, 381.7705529889521, 366.8779514228955, 351.84286990028835, 348.66895542504653, 395.19776669954945, 322.01025936532386, 312.4593551127434, 308.08286819321467, 306.2477171593383, 306.4144114954574, 294.5268802890414, 291.8100820705648, 289.3152060796371, 4288.59335133129, 765.8471496152563, 1401.8445394693783, 977.8792366109699, 747.2330439006464, 3028.570171437743, 2762.85444367013, 3269.4243779086773, 25132.538582066896, 792.3082586984997, 954.7108776278513, 2026.191662216597, 2591.5649861946085, 1250.7886956674147, 1520.7372108363268, 2060.873428918184, 706.1494054910685, 1575.201082270032, 1018.5417721823111, 5310.332398482589, 2070.8301775993577, 3010.296771468203, 9598.174690435293, 4888.135859643001, 3240.0198891456785, 6466.516219044551, 17473.430588453826, 29086.547356166746, 21046.41731729431, 4466.53568387749, 27001.262396623373, 19745.675797594227, 2328.5367828242183, 2255.325238681739, 2029.3514689450858, 1822.921705196054, 2231.6407012028117, 1088.9816336951237, 1002.0832713700448, 938.827657601161, 934.6687354747032, 849.4514176951037, 615.6502379803501, 612.8511834864154, 574.8489354633716, 564.2183307462672, 556.8504534277214, 1000.9355933206812, 530.3548108640927, 521.0523845393484, 524.9631075001943, 473.95858229622223, 463.39378220153134, 413.4270694909345, 406.3271501377279, 400.43568269570864, 388.0381802498865, 375.12058032434624, 355.14107533693283, 357.24921422512455, 345.5905689053357, 343.4299903437965, 400.0960094357946, 38045.03110793383, 2798.7164326749667, 2223.344015737608, 3490.6499365102645, 6367.816835406111, 4337.2500995901255, 3710.02786424583, 1599.7277698315265, 845.0399780022473, 4548.197727773804, 8063.922482793784, 4796.62619940492, 10840.615696137122, 2253.9452959449814, 14429.033129666506, 2060.0830964842285, 5286.764526185289, 1067.7895457961029, 13298.403005713531, 2539.1800445041276, 14573.813800063226, 11834.568098383554, 6155.128112354718, 7587.339844421794, 19133.00715721098, 5182.37017239487, 23451.584511062294, 6974.443400028706, 8489.638550200198, 9110.115534679499, 7171.008605648935, 21046.41731729431, 7679.124847696028, 24492.24326687202, 10859.013713036917, 16752.895461319902, 16109.951168987285, 27001.262396623373, 7474.2682942141055, 4426.67844700295, 2104.5903520309876, 2079.1326513527565, 1933.9753255061537, 1961.743909254801, 1771.9891824433744, 1520.333963609861, 1098.6211428748372, 991.7889847626957, 791.4591275118752, 783.372231249946, 787.5720144143897, 797.5660389751838, 756.3390291498415, 684.6810102117597, 670.5012399839052, 672.681123843036, 689.8416959116112, 692.678421528867, 600.1544627552477, 592.3711758597683, 530.8202407030321, 520.4303110456738, 478.7576537695768, 476.29126061786087, 470.4372974163149, 467.10421656427013, 461.7872136572501, 459.45344785988124, 9564.045161312455, 2500.3669944265935, 3099.465226908899, 3226.640625706117, 1430.6979719609615, 1469.1166106066405, 3115.5318729993814, 1447.4468439035772, 10969.666893387579, 4398.29712740775, 2460.9593701491594, 5441.168934790865, 1081.3361177133036, 8778.326624199919, 33703.23771295595, 24292.33988854209, 19745.675797594227, 2545.0803453072804, 1909.9217518091505, 1619.1153623767782, 1701.4294505031537, 12842.032285994497, 11797.877362075173, 3163.4498840955644, 27655.41326943416, 20610.57111389147, 5832.049221720327, 32677.685093201624, 8466.349170274305, 29086.547356166746, 4941.6085444609935, 25132.538582066896, 6834.24376697141, 21158.59213682939, 6301.885449407641, 1708.8273902499905, 1097.4925268250358, 1082.015496724247, 983.6484772155934, 945.0951560597669, 882.9535353475367, 882.2013895467645, 703.3170747551039, 594.8025531267914, 562.5783843589073, 546.5098665975047, 508.1344389002169, 487.29436857188324, 407.75478959010684, 402.77743532056684, 355.249614179268, 352.4231607540936, 350.7159324096739, 331.22886913989925, 323.0093144470215, 297.17999419254295, 289.517233893886, 287.0451757083509, 284.29147050677733, 284.36984586544725, 281.86283408250125, 259.4683643863797, 264.87356850637593, 4024.1318730518497, 756.4958206539529, 3591.9531364834297, 1853.4193570337002, 8752.929386452259, 3515.4155663859556, 3400.1754669268194, 3985.6351896188544, 2814.581899539913, 2184.9751114318346, 7803.876609789046, 1749.7008148512866, 3585.1775325700773, 6086.522358947974, 1982.2089107679367, 2574.7916573135863, 14857.886903714723, 10957.064621513624, 12017.793866525813, 19745.675797594227, 5165.7747781397875, 27655.41326943416, 29086.547356166746, 15321.800342662185, 32677.685093201624, 6016.549104600091, 2587.4770103183864, 1715.9456083211237, 1467.4161178151714, 1394.9100782832159, 1453.650992035783, 1222.4217903500064, 1815.3720015084507, 1119.3792510000221, 1086.2235302910613, 1797.8834234338115, 888.616490506487, 856.5427471669616, 669.6301631528031, 664.6415913642377, 614.6769417415794, 604.6131855214317, 493.4525383381074, 493.0260825580072, 478.1374483314917, 475.8187317868276, 463.8686686683339, 454.06498316243085, 414.2906576951554, 400.50898934638667, 455.4374137736034, 390.24968791883737, 358.83653611551495, 375.2984774505539, 349.35143391654003, 430.01805198297734, 682.6155467778838, 577.1501188172551, 3640.3585883783608, 631.0731855046732, 1974.2044362940337, 4576.983412019044, 1259.0563506777808, 3996.3084928686885, 3688.642438945982, 6466.516219044551, 2114.319722080138, 11949.633951341524, 1790.9974249575994, 4999.353377154772, 4041.4992081146947, 33703.23771295595, 3563.945597160505, 13458.379641434758, 4273.327426896699, 1292.6873703076888, 8141.873988110916, 11797.877362075173, 14573.813800063226, 3773.6961944773398, 2862.8604353786163, 22689.665747929223, 4917.934543229761, 16109.951168987285, 29086.547356166746, 18068.17700006658, 9301.5115516636, 19133.00715721098, 32677.685093201624, 18774.71676976066, 11102.722924559592, 6718.376732943006, 7031.732487732631, 8489.638550200198, 15321.800342662185, 4826.576834020241, 3258.911491512937, 1953.7149432130927, 1793.1408849854386, 1670.6177236996318, 1192.4804406953717, 939.6886007514647, 884.8465563743044, 889.1155052438853, 796.8126394911288, 712.0481917925454, 702.687000331845, 491.44047266615087, 477.50117627273454, 497.9198790131233, 482.61667939009226, 397.50554393715703, 361.75055731351387, 354.8390337775335, 338.3895311032502, 326.43996838257016, 313.3330334422101, 314.03805249859073, 291.3878973372609, 284.8219294600209, 264.51636697361425, 260.89605446306365, 270.45177695996944, 247.4408756734449, 228.505856968651, 2708.691301582736, 850.6486645662549, 589.173856237789, 6488.905663223762, 698.8725979285076, 1264.107822016205, 1384.9932926078327, 23716.239768326555, 3650.3841269116, 934.7039106680213, 2568.7295850034643, 38206.768537839496, 851.4053441057466, 2741.7441589749287, 4091.2031667580623, 4812.5176778122395, 1864.6176819529342, 5677.4999267131925, 3585.749656047597, 27655.41326943416, 7008.28320513234, 12842.032285994497, 18774.71676976066, 32677.685093201624, 5150.881614749383, 10661.106691228777, 22689.665747929223, 5668.743799089937, 8070.098556512495, 19745.675797594227, 6077.7331695164985, 10859.013713036917, 10062.999971612824, 27001.262396623373, 12638.888431857624, 15321.800342662185, 29086.547356166746, 16752.895461319902, 18068.17700006658, 20610.57111389147, 34029.80171680522, 9598.174690435293, 24492.24326687202, 10957.064621513624, 11451.74962594714, 2839.9812277492574, 1456.927616331433, 1888.559730505218, 686.8850065645968, 623.0250928153081, 529.8150437635934, 531.7160817822726, 485.25001223379275, 477.9477122871521, 466.1263761574824, 412.999314251611, 409.32882208947575, 398.7372493835877, 474.20905417025097, 369.6353500855228, 361.29657981673483, 338.9858139621827, 273.1399387511747, 266.16619400754695, 251.28617020035693, 245.61854812027337, 262.58112358518446, 229.5011492121957, 1406.0871959734777, 221.86100623828153, 198.5346343159893, 181.68748393651612, 179.0439178298203, 166.48020988228345, 164.2226957732969, 34029.80171680522, 6708.9275437305, 2052.3228455193976, 9490.327243790167, 1147.7160685306094, 3650.310581698168, 597.8667538414697, 1599.8939564554132, 20610.57111389147, 9107.082597522236, 2965.533518464474, 24292.33988854209, 38206.768537839496, 3973.319073791375, 5607.78547784316, 5832.049221720327, 4105.005578571683, 2481.1874299669225, 5165.7747781397875, 21046.41731729431, 1404.506778353782, 7549.872317315457, 1402.4118321791861, 5628.3056120858255, 8936.82651679339, 3801.362842731377, 24492.24326687202, 12947.914171060023, 7405.339397919542, 12182.671683821794, 7972.232961778226, 17473.430588453826, 22689.665747929223, 27001.262396623373, 7224.757166635112, 16434.2483871248, 5816.991158838, 1459.2076564977308, 1346.0694773167409, 1245.0845617446917, 862.5605154458167, 783.2692279729132, 733.1178142098238, 713.4321897918306, 715.6148674976074, 667.2218291761972, 573.854606409721, 569.0713443552728, 535.7898954027551, 557.8529989209859, 484.5200050473276, 483.07912182607976, 440.3967011526284, 392.113776177316, 386.06577191550406, 360.9207422547039, 361.83547242185676, 383.87832139666193, 352.0944602134117, 334.651503319078, 331.60248559120834, 329.49614707845114, 315.1019550968647, 313.6451912963286, 308.4101798174716, 316.1677375832532, 3267.5759182059596, 471.1634893211177, 592.7196475667307, 4537.880184439731, 2101.329187332478, 811.1419968314724, 859.6774780505041, 3193.9778472424427, 1019.5071511750556, 1707.4775675907247, 4745.854685858075, 3567.012084163476, 2846.00820157102, 3820.3350400526992, 8466.349170274305, 1504.0862460178478, 1416.4392915273456, 1189.292260408674, 16312.320642851475, 5182.37017239487, 3751.968823019462, 6233.51305125101, 3321.603633698934, 7549.872317315457, 13972.381194182295, 4030.138986094174, 1815.7572696429293, 8790.053094637695, 24292.33988854209, 4813.401300395556, 27001.262396623373, 24492.24326687202, 19211.58808327248, 5057.387001698256, 3621.7437262793787, 2907.1291733047833, 1003.6532458842942, 832.4124684787206, 779.8320222300604, 737.2610194864255, 666.1721275420192, 588.6897155115115, 570.945164550086, 547.2718446561736, 479.20527029600305, 531.557932168222, 463.4033285298023, 401.2048465081477, 382.2158150239324, 382.4842080718547, 309.50522013925337, 306.27552160090653, 319.89750693786436, 290.40063112160726, 284.6583579068126, 275.399991533035, 273.803858852709, 274.56237061168423, 278.9107695658615, 261.0688623857495, 257.26975611546305, 238.97246260492088, 229.35723721451976, 477.92522183141665, 1227.143434038155, 621.791923006919, 5810.616868404131, 981.0968267368294, 896.2524924482414, 4589.51860961395, 1471.2016611182473, 5554.701558721264, 1382.921213570944, 3480.6088633532545, 3627.3354837551406, 2070.8301775993577, 12097.297848100447, 19133.00715721098, 16434.2483871248, 29086.547356166746, 32677.685093201624, 8829.487368733124, 4238.903417232623, 3186.546330203723, 2245.2326620866534, 1951.344115606676, 1837.1233878954088, 1329.608414435042, 986.3132085186252, 895.9761933751273, 821.3895065853451, 736.6800011563228, 641.8823773385307, 481.51292835138383, 415.74196517747293, 429.71677454063524, 372.17825511196196, 367.99186587270765, 339.3960685778017, 336.525153453099, 326.89403829320725, 338.35344693759316, 333.3850826395561, 298.7039815619407, 285.67167311518097, 283.48537029841356, 278.81374112128185, 282.3917680769617, 263.95639499953745, 253.81602921219377, 252.88979299140414, 319.0684945097525, 274.26214948423274, 930.6118065920474, 1215.9839037008478, 5355.860804225284, 486.55266405761074, 4768.023678466561, 441.5566821243325, 3426.025986337895, 619.9765121922838, 562.2169217564254, 3211.499467942251, 1176.6472237380349, 1919.4709904768044, 10859.013713036917, 2073.1853838757006, 1764.1774304982973, 869.9969639513789, 33703.23771295595, 19745.675797594227, 2147.9975271007743, 8752.929386452259, 2336.3703787711715, 10969.666893387579, 6867.09023487258, 8841.970302605623, 6086.522358947974, 11797.877362075173, 27655.41326943416, 10840.615696137122, 20610.57111389147, 7858.296020852177, 10957.064621513624, 24292.33988854209, 12638.888431857624, 2582.121137263401, 1760.1139171872603, 1640.2591244107314, 1419.7797461216533, 1456.4569012517627, 1293.8351790065308, 1157.923695269423, 1061.010764292262, 962.474507949958, 1231.7496860001024, 653.3511882763677, 624.4264698500626, 598.7783000426742, 610.814933799662, 512.6909932906211, 506.7160745379623, 504.99759710490963, 472.6731670121434, 437.00559228335584, 427.62807335726296, 388.40607006755016, 364.4169124174285, 366.1849179297065, 390.6866405519084, 354.5878324091058, 353.7972095316699, 301.89484913102643, 301.8333019617477, 285.5703809731202, 274.6943747731295, 1425.8965077681955, 637.1132939750091, 1007.5630784916906, 6729.07377092871, 730.6959568279971, 695.4739430471087, 1086.1160192565987, 1244.6362031505014, 5286.764526185289, 2805.447509957678, 6420.892099617049, 6236.983453115496, 3106.2419918504274, 2379.2474846491955, 1923.920761024022, 1490.1207038126756, 1311.1059102614947, 795.7181745023321, 736.8209288890758, 660.7272610849054, 634.2319256424323, 607.1917397111505, 541.5516808966739, 486.64069548798443, 413.5920307695262, 403.1906661787569, 373.0887156785673, 292.8271476206258, 291.743981634995, 289.41498534427944, 282.66903129521387, 277.6596440292239, 252.99751046916742, 253.8728217859507, 224.35333254113635, 222.66929238427423, 206.0144582521639, 201.2007717553539, 197.00464759476202, 194.06490277562108, 2312.66405452681, 997.7006501927586, 789.5310175109976, 5089.61758990614, 885.5614962146886, 888.521622638615, 7972.232961778226, 379.2374944921542, 7521.694668153186, 3817.4528035754224, 726.658844336084, 3893.68708777703, 3192.6885230257967, 1982.2089107679367, 4286.837128558502, 1649.826025502058, 6941.140716027072, 6974.443400028706, 2834.2931728383296, 1751.8130727759199, 1520.1176856558905, 6252.067099853813, 5592.830279763229, 33703.23771295595, 2306.0161229794767, 11451.74962594714, 8537.951097096418, 7742.895232318818, 5377.86932898068, 21046.41731729431, 32677.685093201624, 8222.134480283214, 6320.041574502739, 10310.601603781723, 29086.547356166746, 24492.24326687202], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.4321999549865723, -3.315700054168701, -3.922300100326538, -4.010700225830078, -4.246600151062012, -4.3221001625061035, -4.356500148773193, -4.3709001541137695, -4.385200023651123, -4.583499908447266, -4.593999862670898, -4.7368998527526855, -4.764999866485596, -4.777100086212158, -4.845200061798096, -4.910600185394287, -5.10699987411499, -5.179999828338623, -5.284200191497803, -5.288599967956543, -5.306099891662598, -5.3206000328063965, -5.345399856567383, -5.395500183105469, -5.377999782562256, -5.423399925231934, -5.44789981842041, -5.58519983291626, -5.597099781036377, -5.5980000495910645, -5.015900135040283, -3.28629994392395, -4.35230016708374, -4.507199764251709, -4.460700035095215, -3.7304000854492188, -4.890699863433838, -4.895599842071533, -4.941800117492676, -3.9646999835968018, -3.8689000606536865, -4.532100200653076, -4.839000225067139, -4.816299915313721, -4.799799919128418, -4.767600059509277, -4.850100040435791, -4.894999980926514, -1.618299961090088, -2.9274001121520996, -2.822499990463257, -3.5439000129699707, -3.7578001022338867, -4.439700126647949, -4.6859002113342285, -4.698699951171875, -4.825799942016602, -4.912600040435791, -5.078999996185303, -5.108500003814697, -5.390699863433838, -5.404399871826172, -5.421299934387207, -5.829699993133545, -5.848999977111816, -5.878300189971924, -5.93779993057251, -5.968900203704834, -6.015100002288818, -6.100900173187256, -6.178699970245361, -6.192599773406982, -6.249599933624268, -6.264500141143799, -6.311500072479248, -6.32390022277832, -6.478700160980225, -6.4868998527526855, -6.149199962615967, -5.772500038146973, -3.4695000648498535, -6.013700008392334, -6.0665998458862305, -3.9270999431610107, -4.045100212097168, -4.286799907684326, -5.285399913787842, -4.628900051116943, -4.343299865722656, -5.030799865722656, -4.897200107574463, -4.094900131225586, -5.182600021362305, -4.860899925231934, -4.849999904632568, -4.943399906158447, -5.073800086975098, -4.929800033569336, -4.666600227355957, -4.81220006942749, -4.923600196838379, -4.879799842834473, -4.895999908447266, -2.741499900817871, -3.470099925994873, -3.8187999725341797, -3.9974000453948975, -4.590799808502197, -4.595399856567383, -4.615699768066406, -4.620800018310547, -4.446700096130371, -4.652500152587891, -4.9481000900268555, -4.970799922943115, -5.013899803161621, -5.1768999099731445, -5.212800025939941, -5.252799987792969, -5.325799942016602, -5.353700160980225, -5.363399982452393, -5.362599849700928, -5.428500175476074, -5.3983001708984375, -5.461999893188477, -5.477499961853027, -5.489200115203857, -5.596499919891357, -5.661900043487549, -5.6880998611450195, -5.7515997886657715, -5.841400146484375, -4.679800033569336, -1.9107999801635742, -4.085700035095215, -5.325099945068359, -2.797100067138672, -5.159800052642822, -4.84119987487793, -3.8264000415802, -3.530400037765503, -4.519999980926514, -3.765399932861328, -4.551700115203857, -4.658400058746338, -5.002600193023682, -5.063700199127197, -4.916800022125244, -5.047999858856201, -5.168499946594238, -5.616499900817871, -5.753200054168701, -5.80649995803833, -5.700399875640869, -5.976600170135498, -6.169099807739258, -6.326200008392334, -6.490600109100342, -6.504700183868408, -6.522299766540527, -6.618199825286865, -6.636899948120117, -6.647900104522705, -6.687300205230713, -6.706999778747559, -6.7835001945495605, -6.815400123596191, -6.8225998878479, -6.750999927520752, -6.934800148010254, -6.94920015335083, -6.985199928283691, -6.999100208282471, -6.999599933624268, -7.016600131988525, -7.073500156402588, -7.1184000968933105, -7.124199867248535, -7.2555999755859375, -7.254000186920166, -6.775899887084961, -6.121600151062012, -5.1828999519348145, -5.029900074005127, -5.668000221252441, -6.245500087738037, -3.6396000385284424, -6.503699779510498, -4.891600131988525, -5.765699863433838, -5.826000213623047, -4.605199813842773, -5.8333001136779785, -5.335100173950195, -5.157100200653076, -4.747399806976318, -5.231100082397461, -4.512599945068359, -5.308499813079834, -4.865699768066406, -4.505499839782715, -5.734399795532227, -4.548699855804443, -4.039299964904785, -5.762800216674805, -5.025300025939941, -4.686299800872803, -4.776899814605713, -4.162199974060059, -4.966300010681152, -4.151899814605713, -4.441500186920166, -4.648399829864502, -5.11959981918335, -4.455999851226807, -4.924200057983398, -4.378699779510498, -5.1020002365112305, -4.532599925994873, -4.895699977874756, -4.855299949645996, -4.853000164031982, -5.03980016708374, -4.872399806976318, -4.9847002029418945, -5.089900016784668, -3.0713999271392822, -3.9554998874664307, -4.2058000564575195, -4.470799922943115, -4.625199794769287, -4.615200042724609, -4.81879997253418, -5.688799858093262, -5.726099967956543, -5.758399963378906, -5.760499954223633, -5.809000015258789, -5.850100040435791, -5.929800033569336, -6.082300186157227, -6.236199855804443, -6.184899806976318, -6.4770002365112305, -6.552700042724609, -6.6570000648498535, -6.6666998863220215, -6.69320011138916, -6.722899913787842, -6.746699810028076, -6.80620002746582, -6.8867998123168945, -6.937600135803223, -7.041900157928467, -7.039999961853027, -7.061800003051758, -3.2119998931884766, -4.469200134277344, -4.752799987792969, -5.45389986038208, -3.749799966812134, -4.523900032043457, -4.9644999504089355, -4.670199871063232, -3.9660000801086426, -5.350100040435791, -4.897600173950195, -4.925000190734863, -4.239500045776367, -4.602700233459473, -5.076200008392334, -3.954400062561035, -3.9700000286102295, -4.077700138092041, -5.036499977111816, -4.270400047302246, -5.266200065612793, -4.570199966430664, -4.583199977874756, -5.025899887084961, -5.18209981918335, -5.063600063323975, -4.995299816131592, -4.952099800109863, -5.035399913787842, -3.6624999046325684, -4.29449987411499, -5.162799835205078, -5.3084001541137695, -5.33489990234375, -5.336699962615967, -5.392000198364258, -5.363100051879883, -5.769100189208984, -5.8541998863220215, -5.893799781799316, -6.053100109100342, -6.084700107574463, -6.174200057983398, -6.22130012512207, -6.306600093841553, -6.364799976348877, -6.437900066375732, -6.457200050354004, -6.454999923706055, -6.485099792480469, -6.640100002288818, -6.740799903869629, -6.763599872589111, -6.764100074768066, -6.752999782562256, -6.988800048828125, -7.092199802398682, -7.143400192260742, -7.183199882507324, -2.5699000358581543, -3.736599922180176, -5.21120023727417, -5.179999828338623, -4.390999794006348, -4.860599994659424, -3.3076000213623047, -5.760000228881836, -4.8231000900268555, -3.861599922180176, -4.344900131225586, -4.32450008392334, -4.4741997718811035, -5.733500003814697, -3.850399971008301, -4.692999839782715, -4.798799991607666, -4.866300106048584, -3.7804999351501465, -4.296000003814697, -4.1468000411987305, -4.553100109100342, -5.2932000160217285, -4.382199764251709, -5.104700088500977, -4.615499973297119, -4.640999794006348, -4.825699806213379, -4.689899921417236, -4.587600231170654, -4.829800128936768, -4.889800071716309, -5.101200103759766, -3.119499921798706, -3.663300037384033, -4.25540018081665, -4.735400199890137, -4.910999774932861, -4.912499904632568, -5.069799900054932, -5.1184000968933105, -5.139200210571289, -5.243199825286865, -5.349299907684326, -5.3902997970581055, -5.418900012969971, -5.450200080871582, -5.632199764251709, -5.653800010681152, -5.6894001960754395, -4.98960018157959, -5.838500022888184, -5.872099876403809, -5.921800136566162, -5.943299770355225, -5.947400093078613, -5.9644999504089355, -5.974599838256836, -6.030399799346924, -6.034900188446045, -6.031300067901611, -6.020299911499023, -6.113900184631348, -5.248000144958496, -4.367099761962891, -4.3790998458862305, -4.026400089263916, -4.742499828338623, -5.420100212097168, -5.393099784851074, -3.4925999641418457, -3.260200023651123, -4.733099937438965, -4.499300003051758, -5.344200134277344, -4.656499862670898, -5.094699859619141, -4.396699905395508, -4.938000202178955, -4.756499767303467, -4.784900188446045, -4.78249979019165, -4.773099899291992, -4.9475998878479, -4.619699954986572, -4.964099884033203, -5.002900123596191, -5.046800136566162, -5.07859992980957, -5.084799766540527, -1.6806000471115112, -2.9948999881744385, -3.7892000675201416, -4.207699775695801, -4.282299995422363, -4.633800029754639, -4.86899995803833, -5.1859002113342285, -5.309800148010254, -5.377799987792969, -5.526199817657471, -5.629499912261963, -5.829800128936768, -5.9191999435424805, -5.953000068664551, -6.247099876403809, -6.353400230407715, -6.435299873352051, -6.451900005340576, -6.496099948883057, -6.494900226593018, -6.520599842071533, -6.540999889373779, -6.619999885559082, -6.639100074768066, -6.664999961853027, -6.683499813079834, -6.688300132751465, -6.760799884796143, -6.776500225067139, -4.10230016708374, -4.491700172424316, -4.539400100708008, -6.0945000648498535, -3.4535000324249268, -6.223199844360352, -5.158999919891357, -5.501800060272217, -4.46589994430542, -4.4375, -5.006800174713135, -5.217599868774414, -4.6585001945495605, -4.702600002288818, -5.013400077819824, -4.46150016784668, -4.855999946594238, -5.1585001945495605, -5.206099987030029, -5.295199871063232, -5.151800155639648, -5.334000110626221, -5.326600074768066, -5.344600200653076, -4.272299766540527, -4.363399982452393, -4.631999969482422, -5.077600002288818, -5.180799961090088, -5.402500152587891, -5.525300025939941, -5.540800094604492, -5.599599838256836, -5.641300201416016, -5.728000164031982, -5.950399875640869, -5.969200134277344, -5.9928998947143555, -6.0015997886657715, -5.805099964141846, -6.119999885559082, -6.134399890899658, -6.174200057983398, -6.216100215911865, -6.225200176239014, -6.099899768829346, -6.304699897766113, -6.33489990234375, -6.348999977111816, -6.354899883270264, -6.354400157928467, -6.394000053405762, -6.403299808502197, -6.411799907684326, -3.740000009536743, -5.457499980926514, -4.874899864196777, -5.23360013961792, -5.502299785614014, -4.228000164031982, -4.3343000411987305, -4.184100151062012, -2.3334999084472656, -5.480000019073486, -5.321000099182129, -4.651599884033203, -4.624899864196777, -5.250800132751465, -5.123499870300293, -4.94890022277832, -5.689000129699707, -5.22790002822876, -5.482900142669678, -4.616300106048584, -5.161900043487549, -5.049699783325195, -4.766900062561035, -5.0157999992370605, -5.138899803161621, -5.057700157165527, -4.900599956512451, -4.927499771118164, -4.996099948883057, -5.2870001792907715, -5.228700160980225, -5.285999774932861, -5.46750020980835, -5.499499797821045, -5.605100154876709, -5.712399959564209, -5.5100998878479, -6.22760009765625, -6.310800075531006, -6.375999927520752, -6.38040018081665, -6.476099967956543, -6.797999858856201, -6.802599906921387, -6.866600036621094, -6.885300159454346, -6.898399829864502, -6.311999797821045, -6.947199821472168, -6.964900016784668, -6.957399845123291, -7.059700012207031, -7.082200050354004, -7.196300029754639, -7.213699817657471, -7.228300094604492, -7.259699821472168, -7.293600082397461, -7.348400115966797, -7.342400074005127, -7.3755998611450195, -7.381899833679199, -7.2291998863220215, -2.7481000423431396, -5.320899963378906, -5.5472002029418945, -5.116499900817871, -4.5954999923706055, -4.969699859619141, -5.124000072479248, -5.921500205993652, -6.523499965667725, -4.97130012512207, -4.4730000495910645, -4.958899974822998, -4.311999797821045, -5.699399948120117, -4.109399795532227, -5.77839994430542, -4.981800079345703, -6.353899955749512, -4.412199974060059, -5.695700168609619, -4.463399887084961, -4.667200088500977, -5.140100002288818, -5.013299942016602, -4.472099781036377, -5.299300193786621, -4.441500186920166, -5.242700099945068, -5.1753997802734375, -5.205999851226807, -5.331500053405762, -5.0858001708984375, -5.358399868011475, -5.158199787139893, -5.305300235748291, -5.244999885559082, -5.2778000831604, -5.247799873352051, -3.6789000034332275, -4.202700138092041, -4.946199893951416, -4.958399772644043, -5.030799865722656, -5.016499996185303, -5.118299961090088, -5.271500110626221, -5.596399784088135, -5.698699951171875, -5.9243998527526855, -5.934599876403809, -5.929299831390381, -5.9166998863220215, -5.969799995422363, -6.069300174713135, -6.090199947357178, -6.086999893188477, -6.061800003051758, -6.057700157165527, -6.201099872589111, -6.214200019836426, -6.32390022277832, -6.343699932098389, -6.427199840545654, -6.432300090789795, -6.444699764251709, -6.4517998695373535, -6.4633002281188965, -6.468299865722656, -3.4807000160217285, -4.880300045013428, -4.701300144195557, -4.668000221252441, -5.418099880218506, -5.407599925994873, -4.824999809265137, -5.492300033569336, -3.8701000213623047, -4.647500038146973, -5.170300006866455, -4.671000003814697, -5.7804999351501465, -4.477700233459473, -3.704900026321411, -4.012800216674805, -4.176799774169922, -5.303999900817871, -5.472899913787842, -5.5644001960754395, -5.54010009765625, -4.554200172424316, -4.680699825286865, -5.274700164794922, -4.477700233459473, -4.608399868011475, -5.060699939727783, -4.6402997970581055, -5.053999900817871, -4.90369987487793, -5.19890022277832, -5.1331000328063965, -5.196599960327148, -1.7723000049591064, -2.9835000038146973, -4.288599967956543, -4.731400012969971, -4.74560022354126, -4.84089994430542, -4.880899906158447, -4.948999881744385, -4.94980001449585, -5.176499843597412, -5.344099998474121, -5.399799823760986, -5.428800106048584, -5.5015997886657715, -5.543499946594238, -5.721799850463867, -5.734000205993652, -5.859600067138672, -5.867599964141846, -5.872499942779541, -5.929699897766113, -5.954800128936768, -6.0381999015808105, -6.064300060272217, -6.07289981842041, -6.082600116729736, -6.082300186157227, -6.091100215911865, -6.173999786376953, -6.15339994430542, -3.84060001373291, -5.277400016784668, -3.9960999488830566, -4.544600009918213, -3.2811999320983887, -4.07390022277832, -4.180099964141846, -4.262599945068359, -4.52400016784668, -4.8927001953125, -4.348999977111816, -5.1666998863220215, -4.901199817657471, -4.732699871063232, -5.144499778747559, -5.073299884796143, -4.71750020980835, -4.802199840545654, -4.835999965667725, -4.8007001876831055, -5.047500133514404, -4.922500133514404, -4.989799976348877, -5.048999786376953, -5.0329999923706055, -4.517300128936768, -5.361199855804443, -5.771999835968018, -5.928400039672852, -5.979100227355957, -5.937900066375732, -6.111100196838379, -5.715700149536133, -6.19920015335083, -6.229300022125244, -5.725399971008301, -6.430099964141846, -6.466899871826172, -6.713099956512451, -6.720600128173828, -6.798699855804443, -6.815299987792969, -7.018400192260742, -7.0192999839782715, -7.050000190734863, -7.054900169372559, -7.0802998542785645, -7.1016998291015625, -7.193399906158447, -7.227200031280518, -7.098700046539307, -7.253200054168701, -7.337100028991699, -7.292300224304199, -7.363900184631348, -7.156199932098389, -6.699999809265137, -6.866600036621094, -5.083600044250488, -6.785600185394287, -5.689700126647949, -4.9182000160217285, -6.145599842071533, -5.084400177001953, -5.169099807739258, -4.694900035858154, -5.713699817657471, -4.182700157165527, -5.893799781799316, -5.0177998542785645, -5.2153000831604, -3.4486000537872314, -5.361599922180176, -4.347799777984619, -5.2555999755859375, -6.198999881744385, -4.854100227355957, -4.638299942016602, -4.546500205993652, -5.4552001953125, -5.646100044250488, -4.478099822998047, -5.371500015258789, -4.7530999183654785, -4.451600074768066, -4.746699810028076, -5.0665998458862305, -4.742300033569336, -4.522299766540527, -4.839700222015381, -5.092100143432617, -5.287399768829346, -5.295199871063232, -5.24560022354126, -5.105800151824951, -4.844699859619141, -5.237400054931641, -5.749100208282471, -5.83489990234375, -5.905700206756592, -6.2428998947143555, -6.481100082397461, -6.541299819946289, -6.536499977111816, -6.646100044250488, -6.758600234985352, -6.7718000411987305, -7.129499912261963, -7.158299922943115, -7.116399765014648, -7.147600173950195, -7.341700077056885, -7.435999870300293, -7.4552998542785645, -7.502799987792969, -7.538700103759766, -7.579699993133545, -7.577499866485596, -7.652400016784668, -7.67519998550415, -7.749199867248535, -7.763000011444092, -7.7270002365112305, -7.815899848937988, -7.895599842071533, -5.430300235748291, -6.587200164794922, -6.95389986038208, -4.579599857330322, -6.794300079345703, -6.2347002029418945, -6.15339994430542, -3.451900005340576, -5.230800151824951, -6.5391998291015625, -5.60699987411499, -3.193000078201294, -6.659299850463867, -5.614200115203857, -5.259200096130371, -5.129499912261963, -5.972400188446045, -5.0482001304626465, -5.466700077056885, -3.9296000003814697, -5.010300159454346, -4.5447001457214355, -4.282299995422363, -4.026500225067139, -5.329899787902832, -4.841100215911865, -4.33050012588501, -5.284900188446045, -5.048299789428711, -4.531799793243408, -5.279300212860107, -4.946499824523926, -5.032599925994873, -4.576300144195557, -4.940800189971924, -4.887199878692627, -4.622399806976318, -4.885300159454346, -4.867099761962891, -4.932000160217285, -4.824900150299072, -5.156400203704834, -5.05649995803833, -5.195199966430664, -5.201499938964844, -4.632699966430664, -5.30019998550415, -5.0406999588012695, -6.052199840545654, -6.149799823760986, -6.3119001388549805, -6.308300018310547, -6.399799823760986, -6.414999961853027, -6.440000057220459, -6.561100006103516, -6.570000171661377, -6.596199989318848, -6.422900199890137, -6.671999931335449, -6.694900035858154, -6.758600234985352, -6.974699974060059, -7.0005998611450195, -7.05810022354126, -7.080999851226807, -7.014200210571289, -7.148900032043457, -5.33620023727417, -7.182799816131592, -7.293900012969971, -7.382699966430664, -7.397299766540527, -7.470099925994873, -7.483799934387207, -2.394200086593628, -4.072500228881836, -5.192500114440918, -3.8431999683380127, -5.728000164031982, -4.726900100708008, -6.313399791717529, -5.496300220489502, -3.4346001148223877, -4.188600063323975, -5.079400062561035, -3.4237000942230225, -3.111299991607666, -4.947500228881836, -4.731800079345703, -4.704100131988525, -4.987599849700928, -5.334099769592285, -4.892899990081787, -4.028200149536133, -5.763299942016602, -4.776400089263916, -5.788599967956543, -5.0071001052856445, -4.759200096130371, -5.262700080871582, -4.3678998947143555, -4.706299781799316, -4.973599910736084, -4.852200031280518, -5.010200023651123, -4.784800052642822, -4.84660005569458, -4.907400131225586, -5.120500087738037, -5.144999980926514, -3.453000068664551, -4.835999965667725, -4.9166998863220215, -4.994699954986572, -5.361800193786621, -5.4583001136779785, -5.524400234222412, -5.551700115203857, -5.548600196838379, -5.618599891662598, -5.769400119781494, -5.7778000831604, -5.838099956512451, -5.797699928283691, -5.938700199127197, -5.941699981689453, -6.034200191497803, -6.150400161743164, -6.165900230407715, -6.23330020904541, -6.230800151824951, -6.171599864959717, -6.2581000328063965, -6.308899879455566, -6.317999839782715, -6.324399948120117, -6.369100093841553, -6.373700141906738, -6.390600204467773, -6.365799903869629, -4.036399841308594, -5.966899871826172, -5.801199913024902, -4.1682000160217285, -4.813499927520752, -5.587299823760986, -5.5416998863220215, -4.488699913024902, -5.412199974060059, -5.025300025939941, -4.3130998611450195, -4.537300109863281, -4.703000068664551, -4.558300018310547, -4.067500114440918, -5.207300186157227, -5.278500080108643, -5.405700206756592, -4.003499984741211, -4.652900218963623, -4.8769001960754395, -4.684899806976318, -5.0320000648498535, -4.787499904632568, -4.613800048828125, -5.104899883270264, -5.31220006942749, -4.9517998695373535, -4.929500102996826, -5.276299953460693, -5.1407999992370605, -5.250899791717529, -5.268499851226807, -2.9114999771118164, -3.2453999519348145, -3.4651999473571777, -4.528900146484375, -4.716000080108643, -4.781199932098389, -4.837399959564209, -4.938799858093262, -5.0625, -5.093100070953369, -5.13539981842041, -5.2683000564575195, -5.164599895477295, -5.3018999099731445, -5.446000099182129, -5.494500160217285, -5.493800163269043, -5.705599784851074, -5.716100215911865, -5.672599792480469, -5.7692999839782715, -5.789299964904785, -5.822400093078613, -5.828199863433838, -5.825500011444092, -5.809700012207031, -5.875899791717529, -5.890500068664551, -5.964399814605713, -6.00540018081665, -5.2870001792907715, -4.422599792480469, -5.06790018081665, -3.033099889755249, -4.797500133514404, -4.8734002113342285, -3.5764000415802, -4.484499931335449, -3.526400089263916, -4.747799873352051, -4.371200084686279, -4.526100158691406, -4.864999771118164, -4.3846001625061035, -4.521999835968018, -4.878300189971924, -5.028500080108643, -5.043799877166748, -2.9179000854492188, -3.6517999172210693, -3.9370999336242676, -4.287300109863281, -4.427599906921387, -4.4878997802734375, -4.811299800872803, -5.110000133514404, -5.205999851226807, -5.293000221252441, -5.401800155639648, -5.539599895477295, -5.827099800109863, -5.974100112915039, -5.940999984741211, -6.084799766540527, -6.096099853515625, -6.177000045776367, -6.185500144958496, -6.214600086212158, -6.180099964141846, -6.195000171661377, -6.304800033569336, -6.349400043487549, -6.357100009918213, -6.373700141906738, -6.361000061035156, -6.428500175476074, -6.467700004577637, -6.471399784088135, -6.238999843597412, -6.390500068664551, -5.185400009155273, -4.957399845123291, -3.5875000953674316, -5.853799819946289, -3.8434998989105225, -5.961699962615967, -4.178999900817871, -5.671999931335449, -5.770899772644043, -4.512400150299072, -5.2555999755859375, -4.907100200653076, -3.771399974822998, -4.959199905395508, -5.067299842834473, -5.531599998474121, -3.5701000690460205, -3.984299898147583, -5.169300079345703, -4.5777997970581055, -5.160799980163574, -4.519000053405762, -4.724800109863281, -4.681399822235107, -4.838900089263916, -4.664899826049805, -4.686100006103516, -4.862599849700928, -4.881199836730957, -5.006100177764893, -5.003499984741211, -4.953400135040283, -5.066699981689453, -3.0671000480651855, -3.4504001140594482, -3.520900011062622, -3.6651999950408936, -3.639699935913086, -3.7581000328063965, -3.8691000938415527, -3.9565999507904053, -4.053999900817871, -3.8073999881744385, -4.441500186920166, -4.486800193786621, -4.528800010681152, -4.508800029754639, -4.684000015258789, -4.695700168609619, -4.699100017547607, -4.7652997970581055, -4.843800067901611, -4.865499973297119, -4.961699962615967, -5.0254998207092285, -5.020699977874756, -4.955900192260742, -5.052800178527832, -5.055099964141846, -5.213799953460693, -5.214000225067139, -5.269400119781494, -5.308300018310547, -3.707200050354004, -4.5304999351501465, -4.166399955749512, -2.716200113296509, -4.5644001960754395, -4.626299858093262, -4.455399990081787, -4.628900051116943, -4.711299896240234, -4.803100109100342, -3.47760009765625, -3.506700038909912, -4.203800201416016, -4.470399856567383, -4.6828999519348145, -4.938399791717529, -5.066400051116943, -5.565800189971924, -5.6427001953125, -5.751800060272217, -5.792699813842773, -5.836299896240234, -5.950699806213379, -6.057700157165527, -6.220399856567383, -6.245800018310547, -6.323500156402588, -6.565800189971924, -6.569499969482422, -6.577499866485596, -6.601099967956543, -6.61899995803833, -6.712100028991699, -6.708600044250488, -6.832300186157227, -6.839799880981445, -6.917600154876709, -6.941299915313721, -6.962399959564209, -6.977399826049805, -4.634099960327148, -5.439300060272217, -5.678299903869629, -3.9735000133514404, -5.588900089263916, -5.642499923706055, -3.772200107574463, -6.375899791717529, -3.9895999431610107, -4.639400005340576, -5.894100189208984, -4.667799949645996, -4.835599899291992, -5.1793999671936035, -4.628600120544434, -5.312900066375732, -4.370999813079834, -4.372900009155273, -5.019499778747559, -5.304200172424316, -5.388299942016602, -4.768799781799316, -4.872799873352051, -4.1605000495910645, -5.258699893951416, -4.634699821472168, -4.775000095367432, -4.92140007019043, -5.0945000648498535, -4.844099998474121, -4.771999835968018, -5.034200191497803, -5.129700183868408, -5.07289981842041, -5.01140022277832, -5.035299777984619], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 4.2002, 4.2002, 4.2001, 4.2001, 4.2001, 4.2001, 4.2001, 4.2001, 4.2001, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.2, 4.1999, 4.1999, 4.1998, 4.1998, 4.1998, 4.1998, 4.1998, 4.1998, 4.1998, 4.1998, 4.1997, 4.1997, 4.1997, 4.1997, 4.1486, 3.9728, 4.0296, 4.0046, 3.9584, 3.2673, 3.724, 3.6283, 3.6706, 2.025, 1.47, 2.1452, 2.8657, 2.7602, 2.2819, 1.5209, 2.5441, 1.0978, 3.9825, 3.9824, 3.9824, 3.9824, 3.9824, 3.9823, 3.9823, 3.9823, 3.9823, 3.9823, 3.9822, 3.9822, 3.9821, 3.9821, 3.9821, 3.9819, 3.9819, 3.9819, 3.9819, 3.9818, 3.9818, 3.9818, 3.9817, 3.9817, 3.9816, 3.9816, 3.9816, 3.9816, 3.9814, 3.9814, 3.9813, 3.9173, 3.5627, 3.9294, 3.9192, 2.7615, 2.7487, 2.7961, 3.3983, 2.7963, 2.518, 2.7993, 2.6294, 1.5052, 2.9387, 2.323, 2.3048, 2.381, 2.3728, 1.8095, 0.7474, 1.0609, 1.3278, 0.6255, 0.3664, 4.051, 4.0509, 4.0509, 4.0509, 4.0508, 4.0508, 4.0508, 4.0508, 4.0508, 4.0508, 4.0507, 4.0507, 4.0507, 4.0507, 4.0507, 4.0507, 4.0506, 4.0506, 4.0506, 4.0506, 4.0506, 4.0506, 4.0506, 4.0506, 4.0506, 4.0505, 4.0505, 4.0505, 4.0504, 4.0504, 4.0113, 3.8938, 3.9012, 4.0136, 3.2327, 3.9208, 3.6876, 3.0475, 1.6105, 2.6935, 1.2087, 1.9871, 1.6228, 2.6359, 2.5756, 0.6833, 0.0425, 0.3368, 2.4117, 2.4117, 2.4117, 2.4117, 2.4117, 2.4116, 2.4116, 2.4116, 2.4116, 2.4116, 2.4115, 2.4115, 2.4115, 2.4115, 2.4115, 2.4115, 2.4115, 2.4115, 2.4115, 2.4115, 2.4115, 2.4114, 2.4114, 2.4114, 2.4114, 2.4114, 2.4114, 2.4114, 2.4113, 2.4113, 2.3896, 2.3429, 2.2824, 2.2664, 2.3001, 2.3402, 2.0632, 2.3567, 2.1761, 2.2695, 2.2725, 2.0506, 2.226, 2.13, 2.0776, 1.9856, 2.083, 1.9252, 2.0883, 1.9673, 1.8315, 2.1692, 1.7761, 1.6029, 2.157, 1.8708, 1.6532, 1.6292, 1.2518, 1.6898, 1.154, 1.3208, 1.4183, 1.7102, 1.1441, 1.4297, 0.7862, 1.6115, 0.7298, 1.0041, 0.754, 0.6523, 1.2308, 0.4665, 0.6767, 1.1615, 3.1302, 3.1302, 3.1302, 3.1302, 3.1301, 3.1301, 3.1301, 3.13, 3.13, 3.13, 3.13, 3.13, 3.13, 3.13, 3.1299, 3.1299, 3.1299, 3.1298, 3.1297, 3.1297, 3.1297, 3.1297, 3.1296, 3.1296, 3.1296, 3.1295, 3.1295, 3.1294, 3.1294, 3.1294, 2.9996, 2.9922, 2.9791, 3.0135, 2.8053, 2.8088, 2.8613, 2.7836, 2.568, 2.8524, 2.7475, 2.5413, 2.2754, 2.2318, 2.28, 1.3402, 1.2666, 1.0632, 2.0953, 0.7036, 2.3064, 0.958, 0.8946, 1.6594, 1.97, 1.4753, 1.0989, 0.2128, 0.7883, 2.9989, 2.9988, 2.9988, 2.9988, 2.9988, 2.9987, 2.9987, 2.9987, 2.9987, 2.9987, 2.9987, 2.9986, 2.9986, 2.9986, 2.9986, 2.9986, 2.9985, 2.9985, 2.9985, 2.9985, 2.9985, 2.9984, 2.9984, 2.9984, 2.9984, 2.9983, 2.9982, 2.9982, 2.9981, 2.9981, 2.9972, 2.8975, 2.9179, 2.9111, 2.8536, 2.8605, 2.6668, 2.8774, 2.7602, 2.627, 2.6536, 2.5385, 2.551, 2.8368, 2.2728, 2.4793, 2.4615, 2.3779, 1.7288, 1.7338, 1.3584, 1.7281, 2.4182, 1.3205, 2.1783, 1.3453, 1.2588, 1.6454, 1.2779, 0.8473, 1.1599, 0.2751, 1.5761, 3.8994, 3.8994, 3.8993, 3.8993, 3.8992, 3.8992, 3.8992, 3.8992, 3.8992, 3.8992, 3.8991, 3.8991, 3.8991, 3.8991, 3.899, 3.899, 3.899, 3.899, 3.8989, 3.8989, 3.8989, 3.8989, 3.8989, 3.8989, 3.8989, 3.8988, 3.8988, 3.8988, 3.8988, 3.8988, 3.8787, 3.7832, 3.7747, 3.6455, 3.7372, 3.8231, 3.805, 3.3968, 3.1828, 3.5537, 3.413, 3.6706, 3.2078, 3.3546, 2.4369, 3.0224, 2.7098, 2.726, 2.6713, 2.0363, 1.917, 0.3544, 1.9662, 2.1269, 2.0344, 0.2272, 0.4818, 3.0894, 3.0894, 3.0894, 3.0894, 3.0894, 3.0894, 3.0894, 3.0893, 3.0893, 3.0893, 3.0893, 3.0893, 3.0892, 3.0892, 3.0892, 3.0891, 3.0891, 3.089, 3.089, 3.089, 3.089, 3.089, 3.089, 3.0889, 3.0889, 3.0889, 3.0889, 3.0889, 3.0889, 3.0889, 2.8242, 2.7896, 2.7855, 2.9856, 2.5142, 2.9647, 2.5836, 2.698, 2.3008, 2.2512, 2.3698, 2.4696, 2.0876, 1.9687, 2.0187, 1.33, 1.6576, 1.5658, 1.5877, 1.2388, 0.7214, 0.8652, 0.4356, 0.4791, 3.2896, 3.2896, 3.2896, 3.2895, 3.2895, 3.2895, 3.2894, 3.2894, 3.2894, 3.2894, 3.2894, 3.2893, 3.2893, 3.2893, 3.2893, 3.2893, 3.2893, 3.2893, 3.2893, 3.2892, 3.2892, 3.2892, 3.2892, 3.2892, 3.2892, 3.2892, 3.2892, 3.2892, 3.2892, 3.2892, 3.2648, 3.2701, 3.2481, 3.2495, 3.2499, 3.1247, 3.1102, 3.092, 2.9031, 3.2136, 3.1862, 3.103, 2.8836, 2.9862, 2.9181, 2.7887, 3.1197, 2.7785, 2.9595, 2.1748, 2.5709, 2.3091, 1.4323, 1.8582, 2.1463, 1.5365, 0.6994, 0.163, 0.4179, 1.6771, -0.0638, 0.1918, 2.148, 2.148, 2.148, 2.148, 2.1479, 2.1479, 2.1479, 2.1479, 2.1479, 2.1479, 2.1478, 2.1478, 2.1478, 2.1478, 2.1478, 2.1478, 2.1478, 2.1478, 2.1478, 2.1477, 2.1477, 2.1477, 2.1477, 2.1477, 2.1477, 2.1477, 2.1476, 2.1476, 2.1476, 2.1476, 2.1476, 2.0739, 2.1107, 2.1146, 2.0941, 2.014, 2.0238, 2.0257, 2.0695, 2.1056, 1.9747, 1.9004, 1.9339, 1.7655, 1.9487, 1.6821, 1.9597, 1.8138, 2.0413, 1.461, 1.8332, 1.3182, 1.3226, 1.5034, 1.421, 1.0373, 1.5162, 0.8643, 1.2758, 1.1465, 1.0454, 1.1592, 0.3282, 1.0638, 0.1042, 0.7705, 0.3972, 0.4035, -0.0829, 2.7704, 2.7704, 2.7704, 2.7704, 2.7704, 2.7704, 2.7704, 2.7704, 2.7703, 2.7703, 2.7703, 2.7703, 2.7703, 2.7703, 2.7703, 2.7703, 2.7703, 2.7703, 2.7703, 2.7702, 2.7702, 2.7702, 2.7702, 2.7702, 2.7702, 2.7702, 2.7702, 2.7702, 2.7702, 2.7702, 2.7221, 2.664, 2.6283, 2.6214, 2.6845, 2.6685, 2.4993, 2.5987, 2.1955, 2.3321, 2.3899, 2.0958, 2.6021, 1.8108, 1.2383, 1.2578, 1.301, 2.2226, 2.3408, 2.4145, 2.3892, 1.3539, 1.3121, 2.0344, 0.6632, 0.8266, 1.6367, 0.3337, 1.2707, 0.1868, 1.6641, 0.1035, 1.3422, 3.6364, 3.6364, 3.6364, 3.6363, 3.6363, 3.6363, 3.6363, 3.6363, 3.6363, 3.6362, 3.6362, 3.6362, 3.6362, 3.6362, 3.6362, 3.6361, 3.6361, 3.6361, 3.6361, 3.636, 3.636, 3.636, 3.636, 3.636, 3.636, 3.636, 3.636, 3.636, 3.6359, 3.6359, 3.2279, 3.4624, 3.186, 3.2991, 3.0101, 3.1297, 3.0569, 2.8154, 2.902, 2.7865, 2.0572, 2.7346, 2.2828, 1.922, 2.632, 2.4417, 1.0447, 1.2646, 1.1384, 0.6771, 1.7712, 0.2184, 0.1007, 0.6825, -0.0589, 2.1489, 2.1489, 2.1488, 2.1488, 2.1488, 2.1488, 2.1488, 2.1488, 2.1488, 2.1488, 2.1488, 2.1488, 2.1488, 2.1487, 2.1487, 2.1487, 2.1487, 2.1486, 2.1486, 2.1486, 2.1486, 2.1486, 2.1486, 2.1486, 2.1486, 2.1486, 2.1485, 2.1485, 2.1485, 2.1485, 2.1484, 2.1426, 2.1438, 2.0851, 2.1355, 2.0909, 2.0215, 2.0848, 1.991, 1.9864, 1.8992, 1.9984, 1.7974, 1.9842, 1.8337, 1.8489, 1.4946, 1.8283, 1.5133, 1.7528, 2.005, 1.5096, 1.3546, 1.2351, 1.6775, 1.7629, 0.8607, 1.4964, 0.9282, 0.6389, 0.8199, 1.1639, 0.767, 0.4518, 0.6885, 0.9615, 1.2685, 1.2151, 1.0763, 0.6257, 2.042, 2.0419, 2.0419, 2.0419, 2.0419, 2.0418, 2.0418, 2.0418, 2.0418, 2.0418, 2.0418, 2.0418, 2.0417, 2.0417, 2.0417, 2.0417, 2.0416, 2.0416, 2.0416, 2.0416, 2.0416, 2.0415, 2.0415, 2.0415, 2.0415, 2.0414, 2.0414, 2.0414, 2.0414, 2.0414, 2.034, 2.0353, 2.0359, 2.0111, 2.0248, 1.9917, 1.9817, 1.8427, 1.9351, 1.9891, 1.9103, 1.6248, 1.9623, 1.838, 1.7927, 1.76, 1.8653, 1.676, 1.7171, 1.2113, 1.5034, 1.3634, 1.2459, 0.9475, 1.4917, 1.2531, 1.0084, 1.4409, 1.3243, 0.946, 1.3768, 1.1292, 1.1193, 0.5886, 0.9832, 0.8443, 0.4681, 0.7568, 0.6995, 0.503, 0.1087, 1.0428, 0.2059, 0.8716, 0.8211, 2.7843, 2.7842, 2.7842, 2.7841, 2.7841, 2.7841, 2.7841, 2.7841, 2.7841, 2.7841, 2.784, 2.784, 2.784, 2.784, 2.784, 2.784, 2.7839, 2.7838, 2.7838, 2.7838, 2.7838, 2.7838, 2.7837, 2.7837, 2.7837, 2.7836, 2.7836, 2.7836, 2.7835, 2.7835, 2.5394, 2.4848, 2.5493, 2.3673, 2.595, 2.4391, 2.6618, 2.4945, 2.0003, 2.0631, 2.2943, 1.8469, 1.7064, 2.1337, 2.0048, 1.9933, 2.061, 2.218, 1.9258, 1.3858, 2.3578, 1.6629, 2.334, 1.7259, 1.5114, 1.8627, 0.8945, 1.1936, 1.485, 1.1086, 1.3746, 0.8153, 0.4923, 0.2575, 1.3627, 0.5164, 3.2469, 3.2469, 3.2469, 3.2468, 3.2468, 3.2468, 3.2468, 3.2468, 3.2468, 3.2468, 3.2467, 3.2467, 3.2467, 3.2467, 3.2467, 3.2467, 3.2466, 3.2466, 3.2466, 3.2466, 3.2466, 3.2466, 3.2466, 3.2465, 3.2465, 3.2465, 3.2465, 3.2465, 3.2465, 3.2465, 3.2403, 3.2465, 3.1826, 2.7801, 2.9047, 3.0828, 3.0702, 2.8108, 3.0293, 2.9004, 2.5904, 2.6517, 2.7119, 2.5621, 2.2572, 2.8453, 2.8341, 2.8817, 1.6653, 2.1626, 2.2616, 1.9459, 2.2283, 1.6517, 1.2099, 1.9621, 2.5521, 1.3354, 0.3411, 1.613, 0.0241, 0.0115, 0.2368, 3.9284, 3.9284, 3.9284, 3.9283, 3.9282, 3.9282, 3.9282, 3.9282, 3.9282, 3.9282, 3.9281, 3.9281, 3.9281, 3.9281, 3.9281, 3.928, 3.928, 3.9279, 3.9279, 3.9279, 3.9279, 3.9279, 3.9279, 3.9279, 3.9279, 3.9279, 3.9279, 3.9279, 3.9278, 3.9278, 3.912, 3.8334, 3.868, 3.668, 3.6824, 3.6969, 3.3606, 3.5902, 3.2197, 3.3888, 2.8424, 2.6461, 2.8678, 1.5831, 0.9874, 0.7831, 0.062, -0.0698, 3.3647, 3.3647, 3.3647, 3.3647, 3.3647, 3.3647, 3.3646, 3.3646, 3.3646, 3.3646, 3.3645, 3.3645, 3.3644, 3.3644, 3.3644, 3.3644, 3.3643, 3.3643, 3.3643, 3.3643, 3.3643, 3.3643, 3.3643, 3.3642, 3.3642, 3.3642, 3.3642, 3.3642, 3.3642, 3.3642, 3.3641, 3.3639, 3.3473, 3.3078, 3.1951, 3.3274, 3.0554, 3.3165, 3.0503, 3.2668, 3.2657, 2.7816, 3.0425, 2.9016, 2.3044, 2.7724, 2.8258, 3.0685, 1.373, 1.4935, 2.5269, 1.7135, 2.4514, 1.5466, 1.8093, 1.5998, 1.8157, 1.3279, 0.4548, 1.2149, 0.5537, 1.3931, 1.0632, 0.3172, 0.8573, 4.4451, 4.445, 4.445, 4.445, 4.445, 4.445, 4.445, 4.445, 4.445, 4.445, 4.4449, 4.4449, 4.4449, 4.4449, 4.4448, 4.4448, 4.4448, 4.4448, 4.4448, 4.4448, 4.4447, 4.4447, 4.4447, 4.4447, 4.4447, 4.4447, 4.4446, 4.4446, 4.4446, 4.4446, 4.3988, 4.3811, 4.2868, 3.8381, 4.2101, 4.1976, 3.9228, 3.613, 2.0843, 2.6261, 3.1236, 3.1236, 3.1236, 3.1236, 3.1235, 3.1235, 3.1235, 3.1234, 3.1234, 3.1234, 3.1234, 3.1234, 3.1234, 3.1233, 3.1233, 3.1233, 3.1232, 3.1231, 3.1231, 3.1231, 3.1231, 3.1231, 3.1231, 3.1231, 3.123, 3.123, 3.1229, 3.1229, 3.1229, 3.1229, 2.9883, 3.0238, 3.0188, 2.8601, 2.9934, 2.9364, 2.6126, 3.0544, 2.4534, 2.4817, 2.886, 2.4336, 2.4643, 2.5971, 2.3766, 2.6471, 2.1523, 2.1456, 2.3995, 2.5959, 2.6536, 1.859, 1.8665, 0.7827, 2.3665, 1.3879, 1.5412, 1.4926, 1.684, 0.57, 0.2021, 1.3197, 1.4873, 1.0547, 0.0791, 0.2271]}, \"token.table\": {\"Topic\": [19, 19, 13, 20, 9, 11, 14, 3, 6, 9, 11, 13, 5, 7, 11, 14, 1, 3, 5, 6, 7, 9, 11, 12, 13, 14, 15, 18, 10, 13, 16, 20, 3, 5, 11, 13, 16, 8, 5, 8, 9, 13, 15, 17, 20, 5, 11, 13, 14, 18, 19, 1, 17, 18, 19, 8, 10, 13, 15, 1, 3, 4, 12, 15, 4, 20, 5, 14, 15, 1, 3, 5, 11, 15, 18, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 18, 1, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20, 1, 16, 6, 2, 8, 8, 14, 9, 19, 1, 4, 5, 9, 10, 11, 12, 13, 14, 15, 20, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 18, 20, 6, 10, 14, 15, 18, 3, 19, 11, 13, 18, 12, 20, 13, 18, 7, 19, 5, 9, 13, 14, 1, 9, 9, 17, 1, 4, 6, 10, 14, 15, 17, 18, 17, 16, 3, 5, 7, 11, 13, 14, 18, 20, 20, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 18, 20, 20, 3, 5, 11, 15, 16, 4, 5, 18, 11, 18, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 11, 10, 6, 3, 8, 6, 8, 10, 11, 13, 14, 16, 18, 20, 8, 14, 17, 19, 10, 12, 2, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 10, 14, 15, 3, 4, 5, 10, 12, 7, 2, 4, 6, 12, 15, 18, 17, 5, 2, 6, 9, 11, 12, 14, 6, 17, 5, 5, 8, 16, 20, 9, 4, 19, 4, 6, 15, 5, 6, 8, 3, 11, 11, 11, 2, 13, 18, 5, 9, 20, 20, 14, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 17, 18, 16, 6, 3, 11, 7, 1, 16, 4, 6, 10, 13, 14, 15, 16, 18, 20, 5, 7, 9, 13, 20, 3, 11, 4, 8, 9, 10, 11, 13, 15, 16, 17, 12, 10, 5, 8, 11, 13, 14, 15, 1, 3, 5, 8, 9, 10, 11, 13, 14, 15, 16, 17, 20, 6, 18, 7, 12, 17, 20, 19, 3, 2, 17, 4, 1, 20, 13, 2, 4, 5, 6, 10, 12, 15, 20, 1, 4, 6, 10, 14, 15, 20, 5, 5, 11, 12, 2, 5, 8, 9, 14, 1, 3, 4, 12, 10, 8, 1, 10, 13, 18, 8, 9, 13, 2, 4, 5, 7, 8, 9, 10, 13, 15, 16, 3, 2, 17, 12, 13, 1, 6, 8, 11, 13, 17, 18, 4, 16, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 18, 20, 13, 20, 2, 3, 4, 6, 8, 9, 10, 11, 13, 15, 17, 20, 1, 4, 8, 10, 12, 13, 14, 15, 16, 18, 20, 4, 7, 10, 13, 20, 18, 1, 4, 5, 9, 10, 13, 14, 15, 20, 8, 18, 20, 4, 6, 10, 11, 14, 18, 20, 17, 11, 2, 4, 2, 4, 6, 8, 10, 13, 16, 20, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 6, 11, 15, 18, 19, 1, 2, 4, 5, 7, 8, 10, 12, 13, 14, 15, 20, 3, 8, 2, 4, 5, 7, 9, 10, 13, 15, 17, 20, 5, 9, 11, 13, 17, 4, 7, 10, 13, 14, 15, 18, 20, 5, 16, 11, 13, 14, 4, 14, 15, 1, 6, 16, 18, 9, 11, 13, 15, 16, 20, 7, 7, 1, 5, 7, 10, 12, 14, 17, 20, 6, 11, 13, 14, 15, 16, 9, 17, 14, 3, 18, 13, 2, 5, 7, 9, 11, 13, 18, 15, 17, 1, 17, 17, 14, 6, 6, 19, 16, 4, 6, 19, 19, 12, 9, 8, 5, 9, 10, 11, 14, 5, 9, 5, 9, 12, 14, 1, 17, 18, 10, 13, 15, 20, 13, 20, 12, 20, 7, 10, 12, 3, 2, 4, 5, 6, 8, 10, 13, 20, 4, 7, 10, 13, 20, 11, 2, 3, 4, 6, 8, 10, 12, 16, 18, 6, 11, 19, 4, 8, 11, 13, 15, 16, 14, 8, 10, 12, 14, 2, 4, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 20, 4, 6, 7, 10, 12, 14, 18, 20, 19, 5, 1, 3, 11, 12, 13, 14, 15, 18, 19, 6, 5, 8, 17, 18, 1, 5, 4, 5, 6, 8, 10, 11, 13, 14, 15, 18, 20, 1, 8, 11, 13, 17, 18, 7, 14, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 14, 14, 16, 1, 3, 5, 9, 13, 17, 18, 9, 4, 5, 14, 16, 18, 1, 2, 4, 5, 6, 8, 10, 13, 14, 16, 17, 18, 19, 20, 5, 9, 14, 5, 10, 8, 19, 20, 4, 5, 7, 8, 12, 15, 5, 6, 6, 8, 9, 10, 11, 12, 13, 17, 18, 10, 5, 8, 13, 16, 18, 3, 1, 7, 9, 13, 6, 6, 11, 15, 16, 18, 11, 2, 10, 13, 16, 1, 3, 4, 6, 12, 6, 18, 8, 10, 11, 13, 14, 15, 16, 20, 6, 13, 16, 2, 13, 1, 3, 5, 7, 8, 9, 10, 11, 13, 14, 16, 18, 20, 1, 3, 5, 8, 9, 10, 11, 12, 13, 14, 15, 17, 18, 11, 13, 14, 16, 7, 2, 6, 17, 1, 19, 2, 4, 9, 10, 11, 13, 17, 20, 4, 10, 5, 6, 7, 10, 12, 20, 1, 3, 11, 13, 7, 12, 1, 13, 10, 8, 11, 13, 16, 18, 13, 3, 12, 20, 15, 4, 14, 20, 16, 8, 15, 2, 12, 2, 9, 1, 5, 6, 10, 12, 14, 18, 10, 14, 18, 1, 3, 4, 12, 15, 2, 4, 6, 7, 8, 9, 11, 13, 15, 17, 20, 13, 14, 16, 16, 12, 6, 8, 13, 17, 4, 13, 16, 10, 6, 14, 4, 5, 6, 7, 10, 18, 20, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 20, 5, 7, 9, 5, 11, 13, 8, 6, 18, 8, 11, 13, 14, 20, 2, 4, 10, 12, 5, 9, 11, 12, 14, 15, 2, 1, 5, 7, 8, 10, 13, 16, 20, 6, 3, 9, 17, 1, 5, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 1, 4, 6, 10, 12, 14, 18, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 19, 7, 2, 8, 11, 13, 14, 2, 2, 16, 5, 20, 5, 6, 11, 16, 17, 17, 9, 20, 5, 8, 10, 11, 13, 14, 15, 18, 20, 1, 2, 3, 4, 6, 7, 8, 10, 11, 14, 16, 20, 18, 3, 7, 11, 18, 19, 4, 6, 10, 11, 13, 14, 15, 20, 20, 9, 16, 15, 20, 6, 1, 6, 10, 14, 6, 16, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 16, 17, 1, 2, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 17, 20, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 18, 20, 1, 19, 7, 7, 2, 12, 16, 13, 14, 4, 5, 16, 17, 8, 19, 19, 5, 15, 6, 14, 3, 9, 13, 12, 14, 15, 5, 10, 1, 5, 6, 8, 9, 11, 12, 13, 14, 16, 18, 7, 5, 8, 4, 11, 13, 13, 5, 7, 13, 16, 15, 10, 3, 18, 17, 7, 10, 16, 17, 1, 5, 8, 11, 13, 16, 18, 6, 6, 1, 9, 11, 12, 13, 14, 20, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 18, 18, 16, 9, 5, 6, 7, 8, 9, 10, 13, 16, 17, 18, 20, 13, 15, 17, 2, 10, 20, 10, 16, 15, 5, 6, 7, 8, 9, 10, 13, 16, 17, 1, 4, 5, 6, 7, 9, 10, 14, 15, 18, 20, 4, 5, 9, 10, 12, 13, 15, 19, 20, 1, 1, 4, 10, 13, 14, 15, 19, 2, 13, 20, 10, 13, 16, 17, 20, 13, 3, 6, 4, 12, 14, 4, 4, 9, 14, 16, 15, 17, 20, 4, 5, 4, 4, 5, 8, 9, 10, 11, 13, 14, 17, 20, 7, 9, 15, 12, 14, 6, 4, 6, 10, 18, 9, 14, 1, 9, 3, 6, 8, 9, 10, 11, 12, 13, 14, 17, 18, 2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 15, 4, 5, 15, 20, 20, 14, 7, 20, 2, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 10, 11, 10, 4, 12, 7, 8, 11, 12, 7, 9, 12, 2, 5, 10, 10, 8, 4, 2, 4, 6, 7, 11, 12, 15, 4, 15, 17, 7, 8, 1, 5, 8, 9, 4, 6, 12, 14, 15, 18, 20, 7, 6, 8, 9, 2, 2, 7, 9, 12, 15, 20, 11, 1, 2, 4, 5, 8, 11, 14, 15, 19, 5, 8, 9, 11, 13, 14, 15, 16, 4, 6, 9, 15, 20, 19, 11, 19, 1, 5, 11, 12, 14, 16, 18, 4, 6, 11, 12, 15, 16, 18, 15, 11, 14, 5, 5, 7, 9, 13, 15, 20, 12, 12, 14, 8, 13, 11, 13, 8, 10, 4, 5, 9, 10, 12, 13, 14, 20, 10, 16, 6, 10, 2, 5, 6, 7, 15, 18, 9, 4, 6, 14, 4, 14, 15, 19, 4, 6, 8, 10, 15, 18, 2, 4, 6, 10, 11, 12, 15, 18, 12, 14, 1, 4, 7, 8, 9, 10, 11, 13, 14, 16, 18, 1, 8, 10, 11, 13, 16, 17, 20, 13, 17, 13, 14, 1, 9, 12, 4, 6, 8, 12, 17, 3, 5, 7, 13, 14, 5, 10, 13, 14, 9, 18, 6, 12, 15, 19, 13, 4, 10, 11, 14, 15, 18, 2, 6, 11, 12, 15, 18, 19, 18, 6, 10, 12, 18, 8, 8, 10, 11, 13, 16, 20, 7, 8, 11, 12, 13, 18, 10, 18, 19, 4, 2, 2, 16, 3, 5, 6, 8, 11, 13, 15, 18, 20, 6, 8, 1, 4, 17, 18, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 18, 20, 6, 19, 18, 1, 4, 5, 6, 7, 8, 10, 13, 14, 15, 16, 20, 20, 3, 7, 14, 8, 7, 16, 16, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 5, 14, 8, 5, 6, 18, 15, 14, 6, 14, 4, 8, 10, 20, 15, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 6, 10, 11, 14, 18, 5, 13, 15, 20, 6, 10, 11, 14, 16, 18, 7, 10, 3, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 11, 16, 13, 1, 4, 6, 9, 11, 13, 14, 18, 20, 17, 12, 1, 6, 11, 12, 14, 15, 18, 4, 15, 17, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 7, 11, 18, 16, 15, 1, 4, 5, 6, 7, 9, 10, 12, 14, 15, 18, 11, 7, 8, 8, 13, 17, 4, 11, 9, 2, 3, 4, 5, 6, 7, 8, 10, 15, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 1, 4, 6, 9, 11, 12, 14, 15, 20, 2, 4, 6, 10, 11, 12, 14, 15, 18, 10, 20, 12, 7, 17, 16, 3, 14, 2, 8, 13, 5, 7, 8, 9, 16, 10, 5, 1, 3, 16, 17, 15, 13, 16, 17, 7, 11, 7, 9, 8, 11, 15, 5, 7, 8, 9, 10, 11, 12, 13, 14, 18, 11, 14, 16, 4, 8, 9, 1, 20, 1, 2, 3, 11, 13, 14, 16, 18, 3, 15, 1, 6, 8, 9, 10, 11, 13, 16, 18, 1, 6, 19, 11, 17, 13, 15, 4, 2, 13, 20, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 14, 15, 16, 20, 6, 15, 9, 10, 11, 13, 16, 4, 20, 4, 15, 18, 6, 16, 10, 1, 3, 4, 6, 8, 10, 11, 16, 18, 20, 18, 20, 5, 10, 16, 10, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 16, 15, 10, 5, 6, 10, 11, 13, 6, 16, 17, 10, 20, 6, 10, 12, 15, 18, 5, 6, 10, 13, 14, 15, 1, 5, 7, 9, 10, 11, 13, 14, 18, 9, 11, 9, 12, 16, 16, 13, 15, 20, 13, 4, 5, 13, 14, 20, 4, 6, 17, 20, 2, 4, 8, 10, 12, 14, 16, 17, 20, 3, 5, 7, 8, 9, 10, 11, 12, 13, 14, 17, 18, 20, 20, 10, 8, 11, 17, 13, 20, 2, 4, 6, 15, 17, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 14, 14, 18, 9, 16, 17, 9, 9, 17, 18, 18, 11, 19, 1, 17, 18, 4, 9, 15, 11, 18, 12, 8, 11, 18, 15, 8, 2, 4, 6, 8, 10, 14, 15, 7, 5, 6, 11, 12, 16, 18, 2, 5, 6, 12, 14, 15, 9, 20, 19, 10, 11, 13, 14, 20, 3, 6, 11, 12, 5, 7, 13, 3, 12, 14, 5, 9, 16, 18, 7, 1, 3, 4, 5, 7, 9, 11, 12, 13, 14, 15, 18, 19, 20, 12, 13, 16, 18, 5, 6, 8, 16, 5, 10, 14, 2, 10, 2, 4, 7, 9, 10, 13, 16, 20, 15, 5, 3, 9, 9, 4, 5, 7, 10, 14, 20, 1, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 17, 18, 20, 5, 8, 9, 13, 16, 6, 14, 1, 8, 12, 1, 5, 14, 11, 13, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 5, 7, 9, 15, 3, 4, 13, 20, 10, 17, 11, 5, 10, 9, 14, 16, 8, 5, 8, 11, 14, 18, 8, 12, 7, 10, 16, 20, 9, 11, 13, 15, 20, 6, 17, 10, 14, 19, 19, 3, 4, 6, 11, 13, 15, 19, 20, 2, 12, 11, 5, 6, 8, 9, 11, 13, 14, 16, 18, 5, 11, 15, 9, 3, 6, 11, 12, 14, 17, 18, 15, 9, 13, 17, 15, 1, 7, 9, 14, 15, 8, 1, 6, 17, 5, 3, 5, 8, 9, 10, 11, 13, 14, 15, 16, 18, 1, 4, 8, 11, 13, 16, 7, 20, 17, 7, 18, 4, 7, 8, 10, 11, 13, 14, 18, 20, 11, 7, 4, 5, 6, 7, 10, 12, 15, 18, 9, 14, 18, 11, 13, 9, 2, 4, 5, 6, 7, 9, 10, 13, 14, 15, 20, 6, 19, 15, 3, 6, 8, 9, 11, 13, 16, 17, 1, 18, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 1, 2, 16, 4, 6, 9, 11, 13, 15, 20, 18, 3, 2, 4, 5, 6, 7, 8, 9, 10, 12, 14, 15, 16, 20, 1, 8, 11, 12, 14, 16, 18, 9, 12, 8, 3, 2, 4, 7, 8, 9, 11, 12, 14, 15, 16, 5, 6, 12, 5, 10, 19, 14, 6, 18, 16, 16, 12, 13, 11, 13, 14, 15, 14, 15, 15, 19, 7, 9, 1, 10, 17, 20, 5, 6, 7, 8, 9, 13, 4, 5, 9, 10, 12, 13, 14, 15, 18, 9, 14, 2, 14, 12, 7, 9, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 18, 18, 7, 12, 12, 4, 2, 14, 3, 4, 14, 18, 1, 4, 5, 6, 10, 11, 13, 14, 20, 6, 11, 18, 5, 6, 7, 9, 10, 16, 18, 2, 2, 5, 7, 10, 13, 14, 15, 20, 10, 14, 9, 12, 9, 11, 2, 13, 5, 6, 8, 11, 13, 14, 15, 16, 18, 20, 11, 15, 18, 4, 7, 2, 4, 5, 7, 8, 9, 10, 12, 13, 14, 16, 19, 20, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 15, 12, 14, 3, 10, 4, 18, 4, 6, 15, 18, 4, 5, 4, 5, 9, 10, 11, 13, 14, 15, 18, 20, 10, 19, 5, 8, 9, 17, 19, 14, 9, 16, 11, 4, 7, 12, 18, 20, 4, 14, 8, 11, 20, 1, 20, 1, 7, 11, 13, 14, 18, 20, 4, 9, 7, 5, 7, 10, 11, 13, 15, 11, 9, 13, 1, 3, 4, 5, 6, 7, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 1, 11, 13, 5, 7, 10, 4, 6, 8, 11, 15, 20, 1, 5, 7, 10, 13, 14, 15, 7, 16, 4, 20, 1, 4, 10, 20, 1, 11, 13, 11, 16, 3, 15, 1, 2, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 1, 11, 4, 10, 13, 14, 20, 2, 4, 8, 9, 19, 8, 11, 5, 7, 18, 9, 11, 18, 7, 4, 7, 20, 6, 11, 18, 6, 11, 11, 11, 2, 2, 4, 4, 8, 17, 20, 17, 16, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 15, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 13, 4, 10, 15, 4, 2, 5, 11, 4, 6, 15, 8, 3, 13, 4, 5, 6, 9, 10, 11, 14, 15, 16, 18, 20, 8, 18, 4, 6, 10, 14, 19, 20, 4, 5, 11, 8, 8, 14, 7, 2, 2, 5, 5, 13, 6, 5, 17, 13, 2, 3, 5, 9, 13, 9, 4, 5, 8, 12, 14, 15, 5, 18, 14, 20, 8, 11, 18, 6, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 13, 11, 8], \"Freq\": [0.9993170215058867, 1.00015513242737, 0.1262613129773168, 0.8734515486786983, 1.0000690174815785, 0.07634436458496888, 0.923179547135162, 0.3666019217663227, 0.1505686464397397, 0.2389458954369782, 0.19025657770238846, 0.0533945879358316, 0.4274316985954145, 0.014247723286513816, 0.0006626848040238984, 0.5576492625861106, 0.0012551997133737481, 0.01651070392207007, 0.06333930861332145, 0.48373465876942134, 0.0017379688339021126, 0.0009655382410567293, 0.10978169800815012, 0.04460786673682089, 0.059477155649094525, 0.1084299444706707, 0.07154638366230363, 0.0385249758181635, 0.8194520085837457, 0.023514324014585013, 0.028838321904679734, 0.12777594936227327, 0.031183627988103115, 0.18523608078403134, 0.16231478157910084, 0.24786986349517862, 0.37340395565241424, 0.9992261159667936, 0.03218324426545181, 0.6031920175206651, 0.10727748088483938, 0.06777986292269397, 0.06144073905222619, 0.0234059958294195, 0.10435173140616194, 0.01320162354445969, 0.22112719436969983, 0.1347342167625739, 0.5767944639792609, 0.05416548483682726, 0.9980026606009469, 0.9998429979757966, 0.9983676522837771, 1.000991009348156, 1.0003029824421397, 0.029742347579216295, 0.8832785548525397, 0.07078217602185584, 0.01613925837631892, 0.0021991554788141905, 0.2287121697966758, 0.38221322221790627, 0.02726952793729596, 0.3593420052382387, 0.7160572017176606, 0.2840751521568424, 0.0007852011868077349, 0.6588884892232639, 0.34030619436247234, 1.0013311921392352, 0.8610303363063109, 0.13883569414049698, 0.8675690169564327, 0.035812629558261075, 0.09679089069800291, 0.9999137800613402, 0.004967388340499677, 0.019407470725673157, 0.009530454374214497, 0.19055132715474923, 0.015248726998743195, 0.06573125501730968, 0.014324561726092092, 0.0389882224399684, 0.03292338783819553, 0.11037998975226608, 0.04447545374633432, 0.02801375982723655, 0.10986014678639984, 0.10714541129798721, 0.09010611408348251, 0.03442515640625358, 0.026569751588719204, 0.022064445884545078, 0.00046208263632555133, 0.03482947871303843, 0.9989347568441412, 1.0003419269951328, 0.02713846251980776, 0.012026374061255916, 0.024527473414403516, 0.05451428768556136, 0.16615385216208833, 0.017485714918010247, 0.002769230869368139, 0.19693187525306563, 0.3468659466088549, 0.05665055149907393, 0.08149450844140523, 0.013134066409003173, 0.9992130826455862, 0.9986700185521945, 1.0007049217851505, 0.9467171545886875, 0.0484366916301189, 0.9998346280514782, 1.000398417435443, 0.999191121613457, 1.0011126009665212, 0.0012631535484154079, 0.08195637434718794, 0.010996866186204728, 0.01374608273275591, 0.05045183878670953, 0.061002886073473525, 0.0007430314990678871, 0.5296328525355899, 0.24148523719706327, 0.0075789212904924476, 0.0009659409487882531, 0.11392981456024745, 0.0042077865125103074, 0.012623359537530923, 0.0008522099265843661, 0.11904307411975365, 0.01773661909703712, 0.00591220636567904, 0.23212067875341671, 0.4510853667651873, 0.0013315780102880722, 0.0003195787224691373, 0.040746287114815004, 0.003687965557025618, 0.04478243890673965, 0.2739631556647602, 0.6589867598182347, 0.01843982778512809, 0.9986899484430719, 1.0008020736200474, 0.14613486447358437, 0.8537879410682703, 0.998833019547158, 0.12195652189220445, 0.8774094213911375, 0.09355193117704994, 0.9064859538190011, 1.0006539425616732, 0.999686292638409, 0.4385891879388182, 0.001645738041046222, 0.13248191230422088, 0.42706902165149463, 0.9499977820539462, 0.0505317969177631, 0.9989105098072504, 1.0001152325032723, 1.000507912646596, 0.01969139608993911, 0.07600878890716498, 0.7297631390931435, 0.021660535698933024, 0.08979276617012236, 0.04647169477225631, 0.016146944793750072, 0.9999555667130413, 0.999656276586264, 1.0000873154146896, 0.25837851612108165, 0.309435348648002, 0.003867941858100025, 0.34734117885738225, 0.005801912787150037, 0.017792532547260115, 0.05685874531407036, 1.000041186195182, 0.9997604947588568, 0.06694226155614906, 0.12157072918056501, 0.017239311504426345, 0.19948346169407627, 0.0841815730605754, 0.15716878800139344, 0.3103076070796742, 0.011642132444547662, 0.0029105331111369155, 0.028209782461788565, 0.999762212913875, 0.99856612350675, 0.9992528889758996, 1.000044403397425, 0.700382459675601, 0.188374471076771, 0.11117181899612714, 0.9987238161712146, 0.017192990553808785, 0.98322414729594, 0.8421725503318066, 0.15751873787994414, 1.0001083919510798, 3.0601922906957793e-05, 3.0601922906957793e-05, 0.0582966631377546, 3.0601922906957793e-05, 0.08834775143238716, 9.180576872087338e-05, 0.0288576133012612, 0.029653263296842102, 0.007191451883135081, 0.06460065925658791, 0.08746029566808537, 0.02484876140044973, 0.18321371244395632, 0.33472383275630435, 6.120384581391559e-05, 3.0601922906957793e-05, 0.018361153744174675, 0.020319676810219976, 3.0601922906957793e-05, 0.05385938431624571, 0.9990704448420298, 0.9997694763388847, 0.9984359804035696, 0.9998896687426384, 0.9994823055909037, 0.0018323000277754276, 0.016228943103153787, 0.3381902336979789, 0.020678814599179824, 0.04737804357533606, 0.00026175714682506106, 0.5041442647850677, 0.017275971690454032, 0.05366021509913752, 0.03454824782627702, 0.3366445544002343, 0.19282742972805783, 0.4354686121358639, 0.9245323034904614, 0.07563786931869225, 0.014731558737434956, 0.01262705034637282, 0.07050103110058158, 0.02814779973045608, 0.012890113895255587, 0.01604687648184879, 0.018151384872910927, 0.0455099939567187, 0.043931612663422104, 0.05761091720532599, 0.19282558133106828, 0.3977520859107438, 0.06944877690505051, 0.01972976616620753, 0.9989119783412516, 0.9991037110481332, 0.999754709177767, 1.000099083520279, 0.23246405737282982, 0.04816321188682582, 0.08184962020073289, 0.6372577572771346, 1.000933857005769, 0.999602700285944, 1.0005631897794132, 0.32145399866315905, 0.5602652035254511, 0.0764666419509802, 0.041762550603996876, 1.0012001828988952, 1.0007065341711072, 0.010437033706886882, 0.1031278330561442, 0.02062556661122884, 0.03553561476392438, 0.6644911460051315, 0.16550153449492055, 0.9984162188066016, 0.9991004125975645, 0.9994149865282366, 0.07677297787266524, 0.03722326199886799, 0.8375233949745298, 0.04769230443604961, 1.0006010076189782, 0.8700980822027775, 0.13016667309753552, 0.7056647003697679, 0.18670592953074475, 0.10762226984160117, 0.9999250736934285, 0.9162244449467556, 0.08360720802304482, 0.9606455731215666, 0.039030160900089865, 0.999388482128597, 0.9997426283318156, 1.0013405120426855, 0.9996549551445041, 0.9982878471015889, 0.9974713310136688, 0.9998503781875759, 1.0005902880958228, 0.9999189972917182, 0.9987222169965787, 0.00015822680724670392, 0.06692993946535575, 0.01708849518264402, 0.1582268072467039, 0.011550556929009385, 0.001424041265220335, 0.01012651566378905, 0.05585406295808648, 0.03275294910006771, 0.0810121253103124, 0.038765567775442454, 0.026423876810199552, 0.08670829037119374, 0.13654973465390546, 0.054588248500112846, 0.0004746804217401117, 0.026582103617446257, 0.00015822680724670392, 0.19477719972069252, 0.9996459605492132, 1.0004343797078445, 1.001131242287519, 0.9999544367552641, 0.9623627079884012, 0.036088601549565044, 0.9992475345806672, 0.06242411594063852, 0.9380488773782437, 0.24474984604725405, 0.17547227839045795, 0.18875627129677783, 0.11886084350480404, 0.04070153640482894, 0.2037393795748363, 0.014905875761161261, 0.0006950926520748774, 0.012048272635964542, 0.15656682521742343, 0.07104713077093164, 0.08617753824992634, 0.0605216299159788, 0.6249516132628246, 0.99987380675804, 1.000012758432603, 0.0415212151211299, 0.5379304092359718, 0.0018453873387168842, 0.19145893639187675, 0.050748151814714315, 0.07704492139142992, 0.05628431383086497, 0.03044889108882859, 0.011533670866980527, 0.9998426181236476, 1.0000429501737365, 0.1759752822278129, 0.040951694667376665, 0.09922010593695833, 0.6730118506478588, 0.006084251779153105, 0.0046801936762716195, 0.00719578160953339, 0.0032256952042735887, 0.024813040032873757, 0.04416721125851529, 0.03225695204273589, 0.20892579707679704, 0.057318122475938385, 0.25061170433202495, 0.061040078480869446, 0.0004962608006574752, 0.2766653963665424, 0.01141399841512193, 0.022083605629257645, 0.9983493911788, 0.0016612392110135893, 0.9999461926660257, 0.36625806495781366, 0.0428814538862454, 0.5907550882446279, 1.000348302958054, 0.9997215306759673, 0.9969310558088652, 0.9987340442778131, 0.9993853877201939, 0.9997887850333672, 0.9999192206665641, 1.0002831217983381, 0.015711349882750435, 0.5295788084539114, 0.07713918401079725, 0.018073958887675313, 0.17424241411320973, 0.02279917689752507, 0.040991266235446626, 0.1214381028531387, 0.3933459095110802, 0.18474987391985992, 0.0256982907332136, 0.08288277551793215, 0.08241974325246884, 0.09075432403080838, 0.14006726030265068, 1.0001028562193142, 0.9999520992560907, 1.0004642536293005, 0.9993090302167998, 0.9991585924482608, 1.0001499676573715, 0.217877589778521, 0.08841919973226964, 0.6936151564654937, 0.9998656158737128, 0.9989757228682733, 0.998903756093257, 0.999972014355891, 1.0005681180613157, 1.0001398204993923, 0.016092010179454386, 0.16092010179454386, 0.07931062159873947, 0.7436807561504991, 0.11062226125560642, 0.02320746739628107, 0.8656385338812839, 0.015280885405050798, 0.024914487073452386, 0.025911066556390482, 0.018270623853865083, 0.0667708253568524, 0.3750460787457033, 0.09467505087911907, 0.11892515163061272, 0.024914487073452386, 0.23519275797339054, 1.0005893866223359, 0.9983869147826631, 1.0000707597610405, 1.000331953641037, 0.9993601841934354, 0.015127345155739486, 0.1788829230438265, 0.5626049788522565, 0.002314566471916424, 0.11787756389117217, 0.09580651931968341, 0.027278819133300714, 0.9990170787114288, 0.9989267624826415, 0.01846321937168393, 0.10557491882332018, 0.026641558153772112, 0.05315920208357319, 0.06108971241771931, 0.01809147669977083, 0.10210532055213126, 0.024039359450380417, 0.0076826818862040505, 0.4878502997739572, 0.039156894774846455, 0.04560043442134017, 0.010408794813566779, 0.21055272524727792, 0.7885405984750997, 0.11389582163880133, 0.014840428879153076, 0.20115039143430374, 0.015734430618861095, 0.005006409742364893, 0.016449632010627508, 0.03450846715272944, 0.003933607654715274, 0.05131569985924016, 0.24781728224706223, 0.011085621572379406, 0.2844713535750909, 0.0004711302519236353, 0.33584856529984863, 0.0704003205017318, 0.058352846916827406, 0.07490971005585802, 0.12458029947294987, 0.1677223696848142, 0.10526395914408081, 0.0005384345736270118, 0.038834593622848225, 0.022950773700851378, 0.15759237397220685, 0.06788594571110448, 0.06788594571110448, 0.08546355665415833, 0.620671503644384, 1.00002278484737, 0.06518386019569201, 0.14292850481043218, 0.0023799381004512296, 0.00030851049450293715, 0.0002203646389306694, 0.27576430915783967, 0.35571260016188655, 0.10105922341360499, 0.056369274638465236, 0.07918206727111682, 0.01603687438402366, 0.9050810980483353, 0.2683417431864299, 0.09423592651193388, 0.4833050944325336, 0.05311479494309001, 0.05706874990163269, 0.025173513236055066, 0.018451789806532507, 0.9997362290350514, 1.0002294788635233, 0.22470839608228832, 0.7748364642112066, 0.2949082434872106, 0.13547081847798667, 0.0010198555970739273, 0.4324187731593451, 0.07648916978054454, 0.012918170896269744, 0.0149578820904176, 0.03144554757644609, 1.0003477327289998, 8.208380115241624e-05, 0.0033654358472490656, 0.0018058436253531572, 0.12575238336550168, 0.0077158773083271254, 0.19133734048628223, 0.0009029218126765786, 0.029550168414869845, 0.00032833520460966495, 0.2047990838752785, 0.08183754974895899, 0.0014775084207434921, 0.016827179236245327, 0.036937710518587304, 0.187151066627509, 0.02544597835724903, 0.001723759824200741, 0.0480190236741635, 8.208380115241624e-05, 0.03496769929092931, 0.17327793388704002, 0.007876269722138183, 0.23955748664314624, 0.034180038416826077, 0.5449486994543531, 0.006791496412631349, 0.03613588657286869, 0.45720866415601236, 0.0002562828834955226, 0.028959965834994057, 0.0015376973009731357, 0.0748346019806926, 0.20617957977214793, 0.048565606422401535, 0.028191117184507487, 0.011276446873802994, 0.10007846600500159, 1.0000430569732417, 0.9993364541791926, 0.20158329742315462, 0.3415360325768097, 0.06291453231678074, 0.08185309051417902, 0.13000196728722552, 0.02086451326832014, 0.07190232264774941, 0.02535840843380448, 0.010913745401890535, 0.05328475696217144, 0.10765695689139436, 0.6663927044854411, 0.06675503061724454, 0.006945610122025443, 0.15241755545555832, 0.01453232004239634, 0.16989603249565174, 0.2552403847446339, 0.39977091316628477, 0.04729609613798082, 0.0031706880092501107, 0.0031706880092501107, 0.1062180483098787, 1.0008746856138853, 1.000263512214326, 0.9527349407402399, 0.04726033727113569, 1.0000271589109717, 0.19395609884532894, 0.09779989729912772, 0.7081589202191741, 0.9995205946502516, 0.5843562971535242, 0.3609702216831919, 0.05449175156351771, 0.6060537160963052, 0.06793236209246015, 0.128586256817871, 0.04124464841327938, 0.10238377429649351, 0.053375427358361545, 0.999688642109072, 1.000246129655127, 0.029489282231782855, 0.01598816506542444, 0.055780931450480825, 0.04760920263926389, 0.4796449519627332, 0.17906744873275374, 0.02273872364860365, 0.16947454969349907, 0.9989677345465457, 0.32184227681232186, 0.09670700272890226, 0.12071228709423261, 0.45335694187095316, 0.007373051626494321, 0.9998389877119043, 1.0000960432863237, 1.0002351374709504, 0.999110123762769, 0.9984394823159268, 0.999958020406599, 0.3517772561197428, 0.18657012369103768, 0.0498469796121093, 0.037741284563454186, 0.2257356076719807, 0.0655131732044865, 0.08260356621435255, 0.9997288800549666, 0.9995716443271246, 0.014646642780592108, 0.9834174438397557, 0.9984424419353045, 1.0003313855763347, 1.0000219043066167, 1.0005180608015416, 0.9994950148936992, 0.9996764377522401, 0.999892948537935, 0.04488404288202684, 0.954487224413102, 0.9998420222714356, 0.9999856779091484, 0.9992503756862013, 1.0007631960457855, 0.15509774260453674, 0.6793981413474768, 0.0937430173361438, 0.06947169281362779, 0.0022281871692801584, 0.1643228078989619, 0.8357298754156454, 0.7249475392594164, 0.2747680628710913, 0.9992973555232574, 0.9982182585143017, 1.0000840738399581, 0.09426966345022551, 0.9053445037012224, 0.840992460957104, 0.13785680340394882, 0.01956819059481889, 0.001319203860324869, 0.06592175183911624, 0.9334520060418859, 1.0000181771936794, 1.00087754463201, 0.8828133785627205, 0.11108735013580899, 0.00588542252375147, 1.0002083477458847, 0.032149367047692085, 0.30645864310138327, 0.0014395238976578546, 0.005758095590631418, 0.04254592853077659, 0.1972147739791261, 0.13195635728530333, 0.28230663104067927, 0.21942604605306282, 0.010407559496587959, 0.21552321124184232, 0.084995069222135, 0.46920747397117385, 1.000460788727918, 0.2911624188765783, 0.009252242882589063, 0.2677485797451284, 0.10970516560784176, 0.2228091143154101, 0.0500376400793082, 0.02284737528149544, 0.025679694531267606, 0.0007552851332725766, 0.2375196371486927, 0.7626306187368835, 1.0000047582307403, 0.9990384037916006, 0.019896103054486372, 0.6508120025454358, 0.13770197640341883, 0.14084346635939038, 0.050787420954873104, 0.9989504187682916, 0.12467028121992439, 0.43032607972484804, 0.30293713193626487, 0.14175904250863677, 0.011535097028685257, 0.043865861940070694, 0.05588835743475674, 0.021445532504034564, 0.0336304941540542, 0.005198916970675045, 0.5247656817275124, 0.04012914036739801, 0.03460529108605577, 0.08529473155013746, 0.021932930970035347, 0.03931680959073003, 0.08220787459879915, 0.16436414644483852, 0.2583060504445091, 0.0008204533100407913, 0.29782455154480725, 0.026664732576325716, 0.08354949540582057, 0.13387063175498912, 0.0347325234583935, 0.999462481613764, 0.9993177335825606, 0.044923335252128466, 0.00025428302972902903, 0.23258421119215192, 0.056535593609754124, 0.45186094382848463, 0.04068528475664465, 0.04246526596474785, 0.1304471942509919, 8.476100990967635e-05, 0.9995278400611122, 0.5699648418953133, 0.15712623004727722, 0.061743764170570474, 0.2111520236965264, 0.588875779476357, 0.4108165022829131, 0.0019247451506594398, 0.0002510537153034052, 0.019916928080736813, 0.0005857920023746121, 0.07673875231107419, 0.009707410325065, 0.703619879423677, 0.16745282810737128, 0.0002510537153034052, 0.0096237257532972, 0.009874779468600605, 0.13972087948103168, 0.000948331761183473, 0.47890753939765385, 0.33634166463307175, 0.043939371601500916, 0.9995210490953902, 1.0004049058866884, 1.0006251995424533, 0.29243285684981174, 0.7075530616883376, 7.15697622404098e-05, 0.005654011216992374, 0.006441278601636882, 0.0576852283657703, 0.09611819068887036, 0.026695521315672856, 0.02526412607086466, 0.07350214582090087, 0.05424987977823063, 0.16496830196414458, 0.0569695307433662, 0.0010019766713657372, 0.15802603502682483, 0.11651557292738715, 0.0005725580979232783, 0.13040010680202666, 0.0015029650070486058, 0.002791220727375982, 7.15697622404098e-05, 0.02147092867212294, 0.9999214311677246, 0.3381719236858324, 0.661517938400052, 0.26340624628291576, 0.008921067164662032, 0.12912070896221362, 0.15024955224693948, 0.2389906940427881, 0.0929669104527938, 0.1159738731406064, 0.9991947561278757, 0.7236411269490101, 0.03968465884555849, 0.18254943068956905, 0.018289451467953043, 0.03588873495598333, 0.006463850819328967, 0.23128466212911458, 0.09513980424699824, 0.0173715990769466, 0.05514472730240025, 0.1609902844689121, 0.08342407463696448, 0.06443651285518563, 0.18341176699845943, 0.01797758509125869, 0.0006059860143120907, 0.021815496515235264, 0.04100505363511813, 0.020805519824715114, 1.00089242974243, 1.0002924419296408, 0.9980478827094061, 0.8898630819921663, 0.10972293658048204, 0.061213602617950995, 0.9386085734752486, 1.0011708700570048, 0.5820972389399072, 0.09077621333090899, 0.0037649120736321703, 0.16523780767607857, 0.11838556853754491, 0.03953157677313779, 0.07751424813735804, 0.9222760079306026, 0.05786943535968574, 0.1721529071059394, 0.03638497432794613, 0.6275541762658137, 0.08753185252608754, 0.013791637888116723, 0.0011781801210953985, 0.0006930471300561167, 0.002772188520224467, 0.9999169017461683, 0.02656982067091902, 0.05209768759003729, 0.12295054271248801, 0.16827553091582045, 0.6293400660876505, 0.9999888826486231, 1.0010136489440749, 0.7755845914098413, 0.1349435405089179, 0.08905364962878083, 0.9995155524772621, 0.03422675058681838, 0.05419235509579577, 0.6374732296794924, 0.23816113949994458, 0.03493980789071043, 0.9994198973820435, 0.5574063764095293, 0.16997145110245734, 0.228711584939336, 0.042492862775614336, 0.9982156300028897, 0.036090695085993316, 0.7848294010763626, 0.04926666313326072, 0.1294682077688014, 0.885348315329734, 0.11454641276503297, 0.09319247105590814, 0.18000675017643092, 0.22311860307301706, 0.007795567921026536, 0.04760021018444991, 0.0356706289719699, 0.37170685223440164, 0.04074955958718417, 0.9994059097201036, 0.1516380614990586, 0.8481868805801, 1.0000543884875572, 0.9990589385193819, 0.0017064743339435158, 0.008077311847332642, 0.07758769971663185, 0.0026165939787133907, 0.050966700107113, 0.0006825897335774063, 0.15608551907803359, 0.11751919913091012, 0.11467507524100426, 0.23537969312860896, 0.1478944422751047, 0.06336708026710255, 0.023208050941631815, 0.00046721576977684377, 0.01728698348174322, 0.013237780143677241, 0.028032946186610626, 0.03574200638792855, 7.78692949628073e-05, 0.24256285380914475, 0.0053729813524337035, 0.02709851464705694, 0.5073184566826896, 0.09313167677551754, 0.012770564373900397, 0.01674189841700357, 0.0007942456264659446, 0.9380040848562806, 0.050831720093820455, 0.01032519314405728, 0.9990910035014028, 0.9364651692873774, 0.06151960966121458, 0.9994353582048433, 0.6216944363174056, 0.3790819733642717, 0.30605363384000867, 0.2363266320434154, 0.00958080940716549, 0.03140376416793132, 0.07398513931088906, 0.3071181682185826, 0.011709878164313375, 0.02341975632862675, 0.9998988495902743, 0.9996027625449999, 0.07851134376233745, 0.16868560453284823, 0.029868445996541426, 0.01564537647437884, 0.6024892249588071, 0.10468179168311662, 0.8428958590271474, 0.15619451773639023, 0.9999641042837178, 0.9998156465481687, 0.9985417211600983, 0.999551225349606, 0.9997263130932372, 0.998994039003647, 0.9997129012737281, 0.01430998274514435, 0.21913914752858307, 0.7256003015479077, 0.010381752187653744, 0.03030349287207039, 0.999204693148287, 0.9980183179032608, 0.9995491723911092, 0.9999298192355693, 1.0005339658277324, 0.13093854830504, 0.8155392590809735, 0.05325077451959844, 0.9998746302094096, 0.0007111934472226447, 0.9992267933478158, 1.0010331717788126, 0.9998993158951702, 0.9973585044182331, 0.9999981669918222, 0.020793038760451868, 0.00034274239715030553, 0.011082004174526545, 0.010510766845942703, 0.5345638920887599, 0.2306656332821556, 0.19182149493845432, 0.2522328521154422, 0.401417671548453, 0.34634821351083545, 0.07953890875142293, 0.24301114110241373, 0.3339755284590134, 0.020214308301466602, 0.32342893282346563, 0.30532864534969584, 0.40189770527425084, 0.00532549962819237, 0.0031952997769154217, 0.012071132490569372, 0.006745632862377001, 0.02769259806660032, 0.07207176163487007, 0.1114804588834936, 0.017751665427307897, 0.03585836416316195, 0.16418179601738583, 0.12563476564808654, 0.7100267816172163, 0.9993501726130751, 0.9981949075468707, 0.15257557547704484, 0.20102374399345244, 0.06291030837205167, 0.5828242361824556, 0.9314103864592109, 0.03285997713785537, 0.036259285117633516, 0.9991502212229509, 0.850277726205041, 0.14952390460823556, 0.03312465478429528, 0.01702887182572926, 0.0870105368629728, 0.015395966308193579, 0.22254169481843447, 0.15092712426365523, 0.4737758723021388, 0.24154547471056018, 0.06377990594743814, 0.0039048922008635594, 0.010413045868969491, 0.0031611032102228814, 0.17386067656225848, 0.012086571097911017, 0.026776403663064406, 0.038491080265655085, 0.13611338528724407, 0.0524371238401678, 0.23708274076671612, 0.5549165774319975, 0.3044642288176893, 0.1405788662827727, 0.7641689125398079, 0.019077725971867604, 0.21674416451371803, 0.9980722337610163, 0.871022416713653, 0.12886359041791032, 0.6763288880385947, 0.020798268766562707, 0.25111983769997936, 0.026190412520856743, 0.025420106270243308, 0.034731094429965005, 0.754477604531793, 0.1256231075126394, 0.08498033743502076, 0.012457519930015072, 0.06150900465444942, 0.019464874890648548, 0.021411362379713403, 0.8766979650748107, 0.008175247454072391, 0.9985047637964904, 0.999589199280248, 0.7226624830733418, 0.01695483084386931, 0.029894043856295884, 0.01695483084386931, 0.16359924498470385, 0.021565355020710962, 0.028258051406448846, 0.9998081173716973, 0.9987573164177376, 0.9602412699284695, 0.038859604107861385, 0.7965420104514037, 0.20327006382225327, 0.04808028331386054, 0.03907350847820623, 0.009801490262329697, 0.01973543309577196, 0.025960703938062442, 0.09377642034769494, 0.047285567887185166, 0.01099356340234277, 0.004635839988939722, 0.0045033874178271585, 0.16715514474405513, 0.3258333249369062, 0.20291733894444727, 1.000416725332931, 0.6967963025562768, 0.14491915546555237, 0.02418060823318524, 0.028457450505721408, 0.0031253847376225825, 0.0003289878671181666, 0.10215073274019072, 0.00019397510221580473, 0.00038795020443160947, 0.0019397510221580475, 0.12074950112933845, 0.026865551656888958, 0.09184721089918355, 0.027156514310212664, 0.015711983279480184, 0.025507725941378324, 0.04859076310505909, 0.03064806615009715, 0.009310804906358628, 0.05227629004715938, 0.22268341734374386, 0.14160182461753745, 0.037049244523218706, 0.01677884634166711, 0.004073477146531899, 0.00019397510221580473, 0.1262777915424889, 0.9989545218294875, 0.9984145529299712, 0.258538006948679, 0.11040908807382796, 0.5779778240448432, 0.05265059715976138, 1.0006895433370955, 0.9976017314899757, 0.9987276174452683, 0.9996530093591223, 0.9990099197417973, 0.9999220949780917, 0.03243320338480774, 0.7875447078311009, 0.13721739893572507, 0.02952253128617115, 0.012890119293962051, 0.9995032730829696, 0.09879282544958852, 0.9005346012135569, 0.05783520665769941, 0.0007067438695441883, 0.36727123087312985, 0.019906618992161302, 0.34206403285938713, 0.07974426661356925, 0.011307901912707013, 0.02897649865131172, 0.0919944936856685, 0.009752968766626416, 0.18693190136033963, 0.011920295159210063, 0.35733793897722893, 0.0037928211870213837, 0.08994404529222139, 0.12949775195687296, 0.007585642374042767, 0.019776853332325785, 0.058788728398831445, 0.05309949661829937, 0.07125085515618743, 1.000026570599809, 0.004086367136685004, 0.13251504857535654, 0.13339069867607475, 0.7302921839989913, 0.9985312625704574, 0.4453558501111887, 0.014266190614739861, 0.1736416255158086, 0.0037605439695757793, 0.03897833670052355, 0.27660890087324064, 0.017728278713714386, 0.02966651353776448, 1.000009840139644, 0.9996513249064527, 0.999829635465538, 0.9974816717833114, 1.0000026530268404, 0.9997116738504428, 1.000066750859393, 0.6389760120089519, 0.3569698391111463, 0.004045658176592992, 1.0001226177425147, 0.9997098388676235, 0.0002558462519737101, 8.52820839912367e-05, 0.00012792312598685504, 0.2842878269847875, 0.0033686423176538492, 0.05428204646042215, 0.025414061029388535, 0.004221463157566216, 0.0009381029239036036, 0.27699620880353676, 0.0006822566719298936, 0.019188468898028256, 0.09896985847183018, 0.1148323260942002, 0.057863893988054096, 0.00021320520997809172, 0.006055027963377805, 4.264104199561835e-05, 0.0001705641679824734, 0.05206471227665, 1.0003169718021465, 1.0003203934382507, 0.0012197970083104599, 0.0343285729481658, 0.4492338124891951, 0.0029623641630396884, 0.005227701464187685, 0.006098985041552299, 0.09322734277801371, 0.0013940537237833828, 0.009584119351010756, 0.09200754576970326, 0.0013940537237833828, 0.2021377899485905, 0.0013940537237833828, 0.01899398198654859, 0.08068085926396328, 0.03424034241069675, 0.3069322197141869, 0.004252068665380642, 0.04498241061797416, 0.026743273974367723, 0.0020141377888645146, 0.003356896314774191, 0.21215584709372887, 0.005706723735116125, 0.005818620278941931, 0.026967067062019335, 0.014322757609703215, 0.27996515265216754, 0.00011189654382580637, 0.03222620462183223, 0.9993264234565399, 0.9999352785145621, 0.9990384102320079, 1.0000184657458682, 1.0000027550696813, 0.9993959122229424, 1.001041371927111, 0.8603239997262133, 0.13952478280331662, 0.13096716187536322, 0.00757234575889091, 0.09052395157219587, 0.7706582797343975, 1.0004375998226829, 1.0005522851095916, 0.9983422093050628, 1.0013218979917768, 1.0000066099911362, 1.0007270037986107, 1.0001734126946533, 0.019586153722104534, 0.9806134296867004, 0.999856885765605, 0.9989747476199066, 0.2512666532540922, 0.7481745869282298, 0.10114352629242061, 0.8990535670437388, 0.007126226837396129, 0.10065795407822033, 0.00012725405066778804, 0.010434832154758619, 0.06209997672588056, 0.16746633067880903, 0.03664916659232295, 0.10943848357429771, 0.3453674935123767, 0.021124172410852814, 0.1392159314305601, 0.9993996744817989, 0.996944722417858, 1.0003519501831897, 0.9997320958441498, 0.9994346159466658, 1.0004555385754599, 0.9997125338498974, 0.23072531872092247, 0.06307800329551344, 0.15447102140367958, 0.5514419221434441, 0.9999597242300552, 0.9994685773833557, 0.9987778276712833, 1.0007248194228602, 0.9986204192461293, 0.4159302176566036, 0.5123338686877988, 0.004244185894455139, 0.06730066204064578, 0.9983409504363259, 0.9999934258647454, 0.0625437410551883, 0.1609271539509901, 0.09908615155934325, 0.5857326760617915, 0.09170739559215811, 1.0004593764185816, 1.0004823112219396, 0.04876027319751141, 0.007246488963861897, 0.07983420044932599, 0.007983420044932597, 0.5276426540466221, 0.26345286148277575, 0.06497275698106683, 0.013316108553911032, 0.03875583832854703, 0.010334890220945876, 0.0894365499889547, 0.010434264165378047, 0.01898042338654483, 0.002583722555236469, 0.005366192999337282, 0.10295140643173006, 0.05604690465974494, 0.10901321704209255, 0.39739640378425534, 0.12978237142841648, 0.015402961386986642, 0.9990441645530537, 1.000454702732825, 1.0000079651627771, 0.04383248935833121, 0.04477175698743831, 0.0034439813067260235, 0.024107869147082166, 0.05666914695612821, 0.11490373996076825, 0.03976232963220046, 0.6465292180353853, 0.020976977050058507, 0.0050094273552378525, 1.0002430320636986, 0.999661195256493, 0.28684035041072586, 0.7130225772058091, 0.9989424490494444, 0.9473880395196929, 0.052425766928365224, 0.2928296157386754, 0.7068906923931624, 0.9978163542364995, 0.026289646779880382, 0.28082360268051154, 0.01102806256571523, 0.021010811144158877, 0.005487898433175826, 0.3293261716899131, 0.2510844197426349, 0.02205612513143046, 0.052788356357215085, 0.1280560594657464, 0.07444728916446937, 0.06184334630366756, 0.24098738749853063, 0.07730418287958445, 0.005209629715798082, 0.01209978514636974, 0.10587312003073522, 0.1426766331842765, 0.13410595203893128, 0.017309414862167822, 0.010881886500754981, 0.10680370084074334, 0.007254591000503321, 0.08786115767276244, 0.006851558167142026, 0.05037910417016195, 0.5674702293727042, 0.07012771300486544, 0.0918914860063754, 0.9988565534846843, 0.0022268963908070095, 0.004701225713925909, 0.007917853833980477, 0.7408141993417985, 0.19794634584951193, 0.03216628120054569, 0.014103677141777725, 0.9995898994123606, 0.9997164282100219, 0.9990021322800986, 0.001322203265871549, 0.2807478267867256, 0.6269447152340928, 0.0033055081646788725, 0.08748578275850083, 0.9995521675840008, 0.9999907832778285, 1.0000985405589922, 0.01430875960745991, 0.002861751921491982, 0.9830117850324958, 1.0000997177005426, 0.8945361984689834, 0.027495989707038423, 0.05376993542709736, 0.023829857746099966, 0.9982811436044312, 1.0003199246636385, 1.0005009524578277, 0.8677135846716024, 0.13263995307856574, 0.9983986385114118, 1.0002274925808003, 0.01921155475143733, 0.04995004235373706, 0.004191611945768145, 0.05484025629046656, 0.08837315185661172, 0.6797397372054008, 0.06147697520459946, 0.031087788597780407, 0.01082833085990104, 0.006407943442287172, 0.3403329961570298, 0.6528982373974819, 0.1013591959466024, 0.8985355748779889, 1.0000807521636925, 0.9985275096408365, 0.27467443167699696, 0.29283087716073064, 0.4324958424202206, 0.9992683851717139, 0.9998788283830957, 1.0009038794803153, 1.0000964887639285, 0.014816368727115775, 0.01677735870570463, 0.02309610419226871, 0.0019609899785888525, 0.01547003205331206, 0.03399049296220678, 0.005229306609570274, 0.13378309409483952, 0.13073266523925683, 0.5667261038121785, 0.05708659715447549, 0.02606227609962367, 0.2973530153957063, 0.0022956408999668517, 0.08952999509870721, 0.0004051130999941503, 0.0006751884999902504, 0.10870534849843033, 0.028627992399586622, 0.0037810555999454026, 0.11491708269834064, 0.27264111629606314, 0.0020255654999707514, 0.03186889719953982, 0.0013503769999805009, 0.019580466499717265, 1.0000418484704463, 0.017368284042099672, 0.8597300600839337, 0.03280675874618827, 0.09021858655201774, 1.000412785927202, 0.998329547082117, 0.4884537543853908, 0.5115868391058748, 0.9993896802493886, 0.01416936077809938, 0.028963840414056086, 0.02875546746143698, 0.0003125594289286628, 0.0021879160025006397, 0.10814556240931733, 0.15607134151171229, 0.06917982026954403, 0.013023309538694284, 0.017190768591076454, 0.0697007526510918, 0.3681950072779648, 0.0016669836209528683, 0.035631774897867556, 0.08647477533693004, 0.9998994639677262, 0.9995517497619784, 1.0001835719233916, 0.2859579500929768, 0.7138157886283176, 0.011068111506355853, 0.7409485758421557, 0.20598985303495615, 0.041812865690677666, 0.9092750762838129, 0.08988236386253783, 1.0000526241196204, 1.000726298061378, 0.8775735411324507, 0.12236871110874417, 1.0000873867576723, 0.998539104316075, 0.9999609375806484, 0.0787829254463271, 0.27172582247889254, 0.0005018020729065421, 0.10864014878426635, 0.017813973588182243, 0.4400804179390374, 0.0822955399566729, 0.9335258680905306, 0.057216101592645424, 0.00903412130410191, 1.000153984532495, 0.9998332442960598, 0.7856284812982198, 0.12853994687907383, 0.0719440001188846, 0.01438880002377692, 0.37026339992869006, 0.01013045042940217, 0.09327315620584699, 0.3102108199057475, 0.08934874748094344, 0.10011805514463225, 0.026466942563302964, 0.9999490484845005, 0.15825929405630795, 0.7669323010330891, 0.07460179256605252, 0.9997039136518229, 0.13316562352964528, 0.09430183640511361, 0.2514715637469696, 0.40578365968261004, 0.10230320434251719, 0.012002051906105368, 0.9997194931401173, 0.001569571274166607, 0.02725346485143836, 0.03895390525886216, 0.09759879559363266, 0.23886021026862728, 0.00014268829765150972, 0.5835951373946748, 0.003995272334242272, 0.007990544668484544, 0.10991507612670288, 0.48700833729985277, 0.04700983255880523, 0.0686546475499098, 0.07136024942379787, 0.026041418036172683, 0.18364272719015282, 0.005749403982012151, 0.03459494696704576, 0.0745496744501127, 0.10037407148185107, 0.7903239997260312, 1.0000168045781297, 0.998855946573218, 0.406954682707406, 0.5929384969764014, 0.01363668694619667, 0.06588327066776946, 0.1938709710423141, 0.18006998666303073, 0.3197228047867316, 0.014129579245456792, 0.21243658098111198, 0.6411774008922413, 0.11095412909773855, 0.03868666094204335, 0.04732733648239821, 0.10427724345291887, 0.013353771289639329, 0.0441852726495419, 1.0001674129356504, 0.9990130711566245, 0.9986687939313693, 0.9999570808768232, 0.3552994985660068, 0.08525069935786453, 0.023563081499533983, 0.2086259350745256, 0.1286703102109384, 0.19856529353539873, 1.0008099648863238, 0.005877867336157515, 0.9933595798106201, 0.9997151508982804, 0.9992984208314702, 0.14991965449435593, 0.8499061787338261, 0.9978486309531995, 1.000016865578177, 0.2877347677457031, 0.3134012493756015, 0.13238501051210752, 0.055385565622412335, 0.056736433076617514, 0.07943100630726452, 0.06024868845755098, 0.014319195014574897, 1.0000643464771846, 0.9999320835328862, 0.032833425454306855, 0.9670118455720512, 0.11879237263208604, 0.11375879752055697, 0.01233225902324622, 0.15478243467951888, 0.521730060309988, 0.07827209298427704, 1.0009494523954676, 0.8648718302806948, 0.025905579903752314, 0.10924039718449771, 0.48570740400484547, 0.5141719639278937, 1.0006589567862507, 0.999506991669869, 0.051644265992389804, 0.1790496957755024, 0.0660169626600832, 0.13008508509403846, 0.48501761127758536, 0.08794141520402225, 0.3053107105032345, 0.00025211454211662633, 0.05975114648164045, 0.12126709475809727, 0.04891022117062551, 0.1253009274319633, 0.2221129116047478, 0.116729032999998, 1.0006013673319194, 0.9987282090907468, 0.0024906334434141976, 0.0006457197816259031, 0.0002767370492682442, 0.0006457197816259031, 0.0034130902743083453, 0.682156826446222, 0.00046122841544707366, 0.00525800393609664, 0.14814656704160006, 0.03994238077771658, 0.1165062977419308, 0.02781374667735612, 0.0008428408084047309, 0.025706644656344292, 0.18563568805114197, 0.13000819469642974, 0.5185578073710106, 0.06405590143875955, 0.04719908527066493, 0.09045397377446973, 0.9094291417325066, 0.9872072119524187, 0.012676818131010192, 0.10136796660526408, 0.8479248802681373, 0.05051888889448014, 0.9998595269311389, 0.5946513659020589, 0.08160259819518287, 0.04603930371147141, 0.2773385600822769, 0.9997092448138487, 0.16693202795526263, 0.010246143670909022, 0.0034575464239281475, 0.8193120068700955, 0.00781687332706882, 0.05750985376343489, 0.8481307559869671, 0.08598560659775703, 1.0004651391037698, 0.9998285509931099, 0.015816552309357912, 0.020130157484637343, 0.1826092857534959, 0.7807625367255769, 1.0000644641673926, 0.13374263387273178, 0.0026748526774546355, 0.13374263387273178, 0.21969456657494074, 0.45864807242755484, 0.051357171407129004, 0.19022767877023378, 0.019245908849187875, 0.06108484113003108, 0.25828567528040536, 0.35284166223511104, 0.11826471524718346, 1.000602715306925, 0.9986126788339846, 0.9995369690310568, 1.0003544191783933, 0.9990670496020885, 1.000022104095353, 0.9998931525025732, 0.0003154156968870909, 0.9285312423527811, 0.0010776702976975606, 0.060533529160914194, 0.0023919023680604393, 0.007123137821366803, 0.005305844853795049, 0.017364583157874706, 0.001447048596489559, 0.19969270631555913, 0.22284548385939207, 0.5532549133911747, 1.000070276366622, 0.20938941644645723, 0.7910266843532828, 0.9996772006367429, 0.9978786664598404, 1.001585391638025, 0.9990992186099711, 0.12700746850659286, 0.1910964906331916, 0.06057729488678508, 0.060284650950133946, 0.2396753841172801, 0.07520949171934187, 0.09671882106320033, 0.10974147624417586, 0.039506931447903314, 0.11586585886033783, 0.883477173810076, 0.022256305064599698, 0.9772541223819685, 1.0007163564024, 0.9989553913495128, 0.08821563218439483, 0.07769761450087084, 0.0764535478931422, 0.28059356852497896, 0.03064927733586026, 0.040714907162028385, 0.031554053050572003, 0.05903661538494116, 0.004297684644880774, 0.08052503860934504, 0.050328149130840646, 0.17122880400919716, 0.00848227232542258, 0.9999967629409809, 1.0005603245610406, 1.0001832464414384, 0.9998001597184611, 0.12351326626380388, 0.02646712848510083, 0.0017261170751152715, 0.15515874597425053, 0.03049473499370313, 0.30763242094276616, 0.08438794589452439, 0.010932074809063386, 0.07134617243809789, 0.08131929331654168, 0.10682746787102292, 1.0014851963294293, 0.03654539817068997, 0.7952974744764436, 0.16706467735172556, 1.0000022743274561, 0.5006175743846841, 0.49896537116889306, 0.9993942104126858, 0.0011095301870410763, 6.526648159065153e-05, 0.01103003538882011, 0.1569006217439263, 0.02369173281740651, 0.015076557247440506, 0.006135049269521245, 0.02878251838147733, 0.01723035113993201, 0.08008197291172944, 0.0035243900058951833, 0.05214791879093058, 0.21799004851277615, 0.30192274383835405, 0.025323394857172797, 0.0008484642606784701, 0.022908535038318693, 6.526648159065153e-05, 6.526648159065153e-05, 0.03517863357736118, 0.9995414281960139, 0.9986522226896721, 1.0000145465680974, 0.06460212702448086, 0.09148856139305094, 0.8439353010134494, 0.9994876664620541, 1.000145905004155, 0.9992094716723087, 0.9996302423403818, 0.3390616077438564, 0.00423385982614597, 0.1718241446110906, 0.4847769500937136, 0.9997036204382753, 0.9993024079124566, 5.722974632473056e-05, 0.08395603785837974, 0.0344523072874878, 0.28145589242502494, 5.722974632473056e-05, 0.027641967474844865, 0.000915675941195689, 0.057058057085756377, 0.07502819743172177, 0.057916503280627335, 0.030675144030055584, 0.001201824672819342, 0.0009729056875204196, 0.14255929809490384, 0.13958335128601784, 0.009843516367853657, 0.0026897980772623365, 0.05391042103789619, 5.722974632473056e-05, 5.722974632473056e-05, 0.0829087863592814, 0.02722067923074151, 0.02140251878447615, 0.7542829435694022, 0.11407750303570298, 0.4252977360651362, 0.27000763223483626, 0.22729213909292298, 0.07728789896245841, 0.0197870012999462, 0.8745540495190506, 0.006281587714268635, 0.010050540342829815, 0.05213717802842967, 0.03721840720704166, 0.9980179231913461, 0.9999016069762466, 1.000347294887813, 0.9994926837540292, 0.01691589377569561, 0.007180127573856409, 0.004320246252066145, 0.176399913869574, 0.026225720206204343, 0.08111110216907283, 0.0158206200779887, 0.03249311969863833, 0.027564388058957234, 0.12820787117046994, 0.018254561628448497, 0.004563640407112124, 0.07983328285508143, 0.12467865592230325, 0.10350336443330298, 0.04581894968740573, 0.043080765443138457, 0.000304242693807475, 0.000304242693807475, 0.06346502592823927, 0.006426782583074583, 0.9933969649838141, 0.9993062355773573, 0.05575108062657771, 0.160460042979856, 0.0031623512120117605, 0.017451493725546382, 0.1858759767949135, 0.16373951831083117, 0.2000479951894847, 0.007730191851584304, 0.20543570466180106, 0.999504490268539, 0.9997354265132907, 0.9998046157582023, 0.11629954292651445, 0.14313043455703697, 0.009218570361300688, 0.21459861425280494, 0.45656182684126034, 0.0601633013053308, 0.0535236318032247, 0.8848125382470582, 0.06188669927247855, 0.007946384000032105, 0.18887943507768618, 0.0003492916043970156, 0.020782850461622426, 0.008994258813223152, 0.004278822153863441, 0.0014844893186873162, 0.09614251411027853, 0.05745846892330907, 0.0058506343736500115, 0.07431178883546506, 0.29497675991327965, 0.015368830593468686, 0.0009605519120917929, 0.04593184597820755, 0.17630493731939362, 1.0004855864956579, 0.9997768879822223, 0.999682445174697, 1.000253363114376, 1.0003490958563441, 0.1468137082491082, 0.0032737190518669066, 0.04558024218368539, 0.2800288912058462, 0.06371160924017903, 0.036514558655438574, 0.006799262646185114, 0.01485764800462673, 0.16695967164521225, 0.03727003228279247, 0.1979340903667222, 1.000212762231227, 0.5803464619324468, 0.4201827024212775, 0.9986344955073894, 0.9990346806871945, 0.9989514658872612, 0.9999728172466412, 0.9999361987063835, 1.0001555605557968, 0.19985234973339708, 0.04388772108482949, 0.36198302184016384, 0.06057230926583904, 0.1527002527001092, 0.07544335525326061, 0.037358969187912705, 0.0018135421935879953, 0.06093501770455664, 0.005077918142046387, 0.0010314046432753933, 0.009626443337237006, 0.018152721721646923, 0.07907435598444683, 0.039055855825361564, 0.03991535969475773, 0.018049581257319383, 0.027916685677987316, 0.043869077493980065, 0.06549419484798748, 0.07549881988775879, 0.02911999109514194, 0.22089249443481343, 0.2072435729888024, 0.026575859641729302, 0.0002750412382067716, 0.020937514258490487, 0.02942941248812456, 0.00020628092865507868, 0.04761651436454733, 1.0012258028060437, 0.004629601210242931, 0.0003086400806828621, 0.04753057242516076, 0.3188252033453965, 0.027777607261457584, 0.004938241290925793, 0.5243794970801826, 0.027468967180774722, 0.043826891456966416, 0.0239854683571998, 0.0026495575510860243, 0.007390871063555752, 0.37205366033144804, 0.07837112335317609, 0.043926875189057774, 0.39060056318905023, 0.03542040094609738, 0.045181928765887995, 0.9585345321944589, 0.041418158798526006, 0.9997717193045139, 0.9996201054955506, 1.0002154025035537, 0.9991407843442975, 1.0001678477895997, 0.9999323194790734, 0.657086020305141, 0.34268162255155055, 0.9999470970017005, 0.06128722323147199, 0.6049776069493099, 0.045705725799741824, 0.09265797139402206, 0.19508034784526168, 0.9987479534231533, 0.9993553128144946, 0.12081340683775414, 0.8772912004218454, 0.9981831089410136, 1.0003454919486663, 1.0001094004877598, 0.25981838971508897, 0.6936898754529075, 0.04540515548419031, 0.9271434167542986, 0.0721597470587072, 1.0002367387512967, 1.0006508271684365, 0.016554617052913792, 0.1559619185511352, 0.8277308526456896, 0.1069094834554713, 0.001823183990713864, 0.02805677585709668, 0.04512380377016813, 0.00030386399845231066, 0.23007569082814122, 0.05185945573586102, 0.047605359757528665, 0.33419975429779963, 0.1539577592158374, 0.330433179158333, 0.0006648554912642515, 0.6695094797031013, 0.999566574308911, 0.15577440006977575, 0.8440140221962396, 0.9991673413862985, 0.9999764087049785, 0.02148529080847438, 0.00529347744556615, 0.014323527205649585, 0.002179667183468415, 0.06756968268752087, 0.23166748350007155, 0.099019166334708, 0.5579947989679143, 1.0005763057959105, 0.9973070979890674, 0.19102680708496908, 0.03338666718421982, 0.17312879993466568, 0.002065154671188855, 0.1273512047233127, 0.07744330016958206, 0.37241622570439015, 0.01927477693109598, 0.003441924451981425, 0.9992922146822726, 0.9997905697097483, 1.0005731827806061, 0.9995248347655212, 0.9991296382546886, 0.9436712661314924, 0.05622518010767346, 0.999826742338657, 0.9995310813443825, 0.9997950824910037, 0.999895981964553, 0.002630865535098226, 0.015426438819439598, 0.5597764349906725, 0.05082353874621573, 0.031570386421178716, 0.017818134760437986, 0.014708930037140083, 0.027145748930331698, 0.04556180767601928, 0.025830316162782585, 0.16574452871118825, 0.03778879586777452, 0.002630865535098226, 0.0023916959409983874, 1.0001945080778003, 1.0017200748048944, 0.011377676665301026, 0.2238964229493166, 0.6834732911084401, 0.08126911903786446, 0.9994694664783467, 0.9997951149379906, 0.9996655614967322, 0.6529496181068357, 0.346996082765347, 1.0006206609968202, 0.9987096627706775, 0.9999483850440771, 1.000268557871073, 0.02598073421644148, 0.01030113321564171, 0.06226260164852467, 0.07383998145725473, 0.0206934269022183, 0.01859673607071601, 0.562733587081029, 0.030356436821315835, 0.16235679873502554, 0.032726609065622775, 0.9995424108117572, 0.9985685634018995, 0.13024928315533083, 0.5316100371747207, 0.33806925050094755, 0.9996785558279901, 0.9999754933041636, 0.014943400211266753, 0.002490566701877792, 0.0004427674136671631, 0.05224655481272524, 0.03752453830829207, 0.006364781571465469, 0.03276478861137007, 0.01090314756155389, 0.008246543079550911, 0.08761260197938989, 0.035753468653623416, 0.03293082639149525, 0.26471956744625513, 0.2611774281369178, 0.06663649575690804, 0.00011069185341679077, 0.013283022410014892, 0.002767296335419769, 0.0008301889006259308, 0.06807548985132632, 0.9998576922915624, 0.9977868798135601, 1.000262789973694, 0.1422272725309181, 0.029610456055924928, 0.8281219349411135, 1.0004658954804977, 1.0000316977872798, 0.09683040186356949, 0.12027355178843369, 0.781778086624819, 0.963298735278875, 0.036445278560254174, 0.07725768710318241, 0.7806374643892989, 0.057416226530936525, 0.0057044199145206914, 0.07886980577467738, 0.011666244878645479, 0.01319431725569728, 0.0368500530927492, 0.010872822682868582, 0.14466731369665414, 0.7827256891375339, 0.029504974188577497, 0.04377714774956382, 0.0197614710844426, 0.0072047029995363655, 0.4361246882386013, 0.032592704045521656, 0.4009931840884811, 0.022711968503300352, 0.007273319218579569, 0.15443856656998947, 0.8452505978740741, 0.19028802277296533, 0.004904330483839313, 0.8043101993496473, 0.9984942249466334, 0.1559161662685213, 0.2442226675179493, 0.5998319445664271, 0.9989858217847121, 0.11368164735354826, 0.014044585803585216, 0.6240565956121356, 0.2480326851350144, 0.998425106785202, 0.47923727765841867, 0.00205460783562023, 0.017207340623319425, 0.5015811378707886, 0.014959619098295657, 0.3744769691353848, 0.060689836829671, 0.3051519050213317, 0.014473127420302302, 0.05351408457926902, 0.005837900135920257, 0.006081145974916934, 0.16467743300075058, 0.08710772016061392, 0.12655750127112858, 0.0013378935848662164, 0.03615928607746531, 0.0005062300050845143, 0.02057463377807776, 0.12156751979243836, 0.03276031318618357, 0.056155371278303626, 0.43575555651953446, 0.011607130830866364, 0.05449204411874022, 0.01533153729684529, 1.0003541775300586, 0.9989670016250741, 0.36725645445290567, 0.140421585526111, 0.4923756877101456, 0.9932384388259683, 0.005859813798383294, 0.06877616744875548, 0.6147531275034913, 0.05369831535422063, 0.1268391241987625, 0.014681066513099727, 0.12115186419819235, 6.207343458154397e-05, 0.0005586609112338957, 0.007262591846040644, 0.072005184114591, 0.003848552944055726, 0.057728294160835886, 6.207343458154397e-05, 0.012973347827542689, 0.028057192430857872, 0.17473671834704627, 0.09224112378817434, 0.009311015187231595, 0.2950350345660785, 0.10838021677937576, 0.03643710609936631, 0.001924276472027863, 0.022160216145611197, 0.028057192430857872, 6.207343458154397e-05, 0.04916216018858282, 1.0004536316671617, 1.000160911404131, 1.000165197742084, 0.48724420327392515, 0.16611695334611523, 0.3462379521778041, 0.999968139632122, 0.9018437101495139, 0.09845912747276923, 0.9997853297616935, 1.0003241469539976, 0.9992524398852458, 1.0001273894821718, 1.0000440929630152, 0.7933032331746183, 0.20641504660661655, 1.0005370884799734, 0.9753780919101338, 0.02448355239076358, 0.9992736989076293, 1.0006590979830088, 1.0004866406667103, 0.12640451926482982, 0.2896534051315159, 0.583274665127847, 0.999179123652692, 0.9986564972686892, 0.07036134696205594, 0.28638495198752567, 0.09011960351926354, 0.052688684152553594, 0.3319387101610876, 0.0953884719345189, 0.07299578116968362, 0.9989162218353, 0.035447437751996574, 0.7174361697129448, 0.07280870430280986, 0.08221142840134417, 0.02704323302675795, 0.06490375926421908, 0.024330319313736266, 0.016014893725497286, 0.4401015987256851, 0.04003723431374322, 0.12195957529417165, 0.35725532156878564, 1.000446591683828, 0.9989812959388096, 0.9999872031766764, 0.2687390247473469, 0.002505725172469435, 0.18135185935747536, 0.0303819177161919, 0.5171190324683796, 0.06164328361327985, 0.9035649979241595, 0.034764880575635634, 1.0005525748463442, 0.7068880520107683, 0.29298409184115565, 0.9997942133595639, 1.0012500793269312, 0.00775282144101446, 0.9919919624764693, 0.11977908352114491, 0.7186745011268695, 0.16101450571694892, 0.9998963750658976, 0.9992179758068042, 0.004410148153813815, 0.023814800030594604, 0.006527019267644447, 0.007232642972254657, 0.001411247409220421, 0.0015876533353729736, 0.24590986105665835, 0.049570065248867284, 0.01940465187678079, 0.5482696184821335, 0.0539802134026811, 0.01605293927988229, 0.00017640592615255263, 0.02152152299061142, 0.9993943260109686, 0.9987291437647446, 0.05509941356631898, 0.9449138236970225, 0.22848033632193385, 0.7081500079105779, 0.031977978105909605, 0.031514529147852945, 1.000293545097609, 0.16196349681919564, 0.8382415414847775, 1.0001943775336242, 0.9991948602557889, 0.0077490393709009784, 0.2284675107853972, 0.051272810504128144, 0.0675457931830202, 0.29795056381114265, 0.12475953387150576, 0.02634673386106333, 0.1956632441152497, 1.0000496824054645, 0.9998972235861812, 0.9992779670600389, 0.9987972385634758, 0.9997310197944448, 0.19536866053489746, 0.20935251694247828, 0.1378119182196372, 0.2928503262167291, 0.005674608397279179, 0.15888903512381702, 0.020641806327237243, 0.014191241849975604, 0.014621279481793047, 0.00010750940795436064, 0.032682860018125634, 0.0005375470397718032, 0.032037803570399474, 0.15255584988723775, 0.01161101605907095, 0.3734876832334489, 0.20641806327237244, 0.09353318492029376, 0.0037628292784026227, 0.042681234957881176, 0.0008600752636348852, 0.00030928554607344765, 0.00015464277303672383, 0.1731999058011307, 0.7790902905590147, 0.04716604577620077, 0.005091875629303565, 0.9946130395906297, 0.07430697664693661, 0.9009720918441064, 0.022292092994080984, 0.9997149717640825, 0.7577117161958888, 0.2425295401483273, 0.6450223615683871, 0.3549100833303674, 0.998799282223143, 0.0010369885521908607, 0.004592377873988097, 0.0014814122174155152, 0.1968056130836512, 0.05407154593566631, 0.06562656123150733, 0.01259200384803188, 0.028035726214588625, 0.03496132833100616, 0.10743942106806025, 0.0559233112074357, 0.0038887070707157275, 0.025998784415642292, 0.2337668479081683, 0.07992218912956704, 0.03984998864847736, 0.00014814122174155152, 0.03529464607992465, 0.00014814122174155152, 0.018443582106823165, 0.14664794393557962, 0.25266615448640994, 0.5999234070091893, 0.9994847764503048, 0.6957717185150897, 0.30399872008966994, 1.0000648410039656, 0.9986834321627336, 0.9993309934088944, 1.0005270764552407, 0.9991731629835142, 0.9979439521652776, 1.0002428265092644, 0.058484037743954276, 0.9415208051619306, 1.0003921399023157, 1.0000075011981557, 0.0887269551777472, 0.09214893141049778, 0.00024442687376789865, 0.7794773004458287, 0.03935272667663168, 1.0000645834075872, 0.9982134607776905, 0.12966761489137035, 0.3329445222766298, 0.011002100657449608, 0.5262671481146729, 0.061708963618376404, 0.0411393090789176, 0.26774271646443093, 0.6127059393146991, 0.016860372573326884, 0.9999358781072055, 0.9979517564244825, 0.03035951055915462, 0.969500918414425, 1.0003702538273513, 1.0006914566145622, 0.011762829239495494, 0.38282662433994424, 0.03814008268563691, 0.021743411624521973, 0.006416088676088451, 0.19640360336248536, 0.1621844637566803, 0.18036338167226423, 0.15994800856322183, 0.840718458233133, 1.0005061981328445, 0.09555573673121834, 0.013030327736075226, 0.32609230436947234, 0.08402890834930563, 0.055796531587809305, 0.00267288774073338, 0.3568305133879062, 0.06581986061555949, 0.9988449314033272, 1.0001489190362882, 0.861577201331997, 0.13853417589762684, 0.9994995753614676, 0.4411567887899532, 0.2822312869272248, 0.05628794753300838, 0.050395303025646564, 0.09850390818276467, 0.0022866978685284656, 0.0690406856459556, 0.9988611780738719, 0.7379343954715643, 0.26143504584962246, 0.9989503831389624, 0.999375600616124, 1.0004586398079587, 0.012428600518276274, 0.32803972883086774, 0.3528969298674203, 0.3063838339884166, 0.9992562444579461, 1.0003693195799914, 0.999499322374532, 0.9999234779347267, 1.0001607907510937, 0.0003388165292496482, 0.22971760683126147, 0.04489319012557839, 0.011350353729863214, 0.12129631747137405, 0.07165969593630059, 0.035745143835837885, 0.32475564328578777, 0.032865203337215876, 0.019990175225729243, 0.10706602324288883, 0.23708342068952137, 0.26393084637735914, 0.12680245671024923, 0.03386906009850305, 0.16191062876357556, 0.17595389758490612, 0.2316480519751077, 0.7682306049386524, 0.9994894216509832, 1.0012231049501912, 1.0004357906552583, 0.07361540622904052, 0.0174076316723942, 0.012374099622545274, 0.0675332216688064, 0.04823801547771886, 0.011115716610083043, 0.013003291128776389, 0.7338470267675578, 0.02265089422432016, 1.000072639790963, 1.0001140316174537, 0.4957836798216753, 0.0536299756301378, 0.0009786491903309817, 0.052651326439806814, 0.2622779830087031, 0.021138822511149204, 0.03366553214738577, 0.07946631425487571, 0.0007910717603226576, 0.9508682559078343, 0.04825537737968211, 0.2704349738864527, 0.7296943674096003, 1.0003326680620386, 0.039341612756087184, 0.3134975373969363, 0.05658920385567613, 0.017295105124656686, 0.007839814136176794, 0.05658920385567613, 0.16207033950605482, 0.01586968437262454, 0.006081795208670483, 0.24693038827703515, 0.07778045903588734, 0.9986687898722317, 0.9999530861423761, 0.9971155137140745, 0.2574262248866379, 0.043383214238707946, 0.023559096474000344, 0.15255951497188028, 0.11406050366070898, 0.04855472322080558, 0.022697178310317402, 0.33758461410915125, 0.9993657118162149, 1.0011493155104905, 0.006124387969104022, 0.02690647781093034, 0.014902677391486454, 0.18597724799512547, 0.02764140436722282, 0.052016468484256825, 0.013310336519519407, 0.04017598507732239, 0.00804336286608995, 0.12955122017311374, 0.04038013134295919, 0.01918974896985927, 0.00012248775938208045, 0.15943823346234137, 0.1511090658243599, 0.039359400014775184, 0.0076758995879437075, 0.022701064738812244, 0.0001633170125094406, 0.05520115022819092, 0.01838201739258087, 0.9374828870216244, 0.041359539133306956, 0.15360920335422076, 0.5596101439119919, 0.07184184279951247, 0.020323679213019977, 0.05340873839700599, 0.08271264795996502, 0.05860781912591807, 0.9999448021484407, 0.9991822964707382, 0.009090757131170054, 0.11688116311504355, 0.15324419163972378, 0.006060504754113369, 0.1445863277052761, 0.02207755303284156, 0.08441417336086479, 0.21233411299232913, 0.008874310532808863, 0.18289737561520705, 0.001948019385250726, 0.04588667885257266, 0.01103877651642078, 0.06857799051819491, 0.10605665975488283, 0.3829887111663975, 0.009455105005000295, 0.3301312566806127, 0.029048816581627415, 0.07359033534012278, 0.9608782773469888, 0.03880984685663325, 0.9993474653782838, 0.9993259444586025, 0.07446617063955525, 0.23959282783842034, 0.006366996002638553, 0.021454008269760343, 0.07225156333428967, 0.028097830185557095, 0.055365182631639594, 0.2146784956541825, 0.24125378331736952, 0.04609151454083996, 0.9988634349608454, 0.9982986838520085, 0.9986994195382367, 0.9997200183660735, 0.9996130385448867, 1.0000658978919672, 0.9995971081126567, 0.2753586576023183, 0.7249411572061035, 1.000001519885755, 0.9998362135258906, 1.0003573662670648, 0.99990873429427, 0.08356133721758989, 0.11990667574455736, 0.31030793558069514, 0.48610517721717533, 0.2587596882935923, 0.7411020565643669, 0.9995591518795086, 0.999989854681381, 0.8499195208397559, 0.1498059587091656, 0.03601488043135134, 0.060775110727905396, 0.07428069088966215, 0.8294677149345607, 0.006262101772948265, 0.6893878262930156, 0.008349469030597686, 0.010158520653893851, 0.07542353690973244, 0.21026746175388508, 0.4683567996657657, 0.047351148161755174, 0.009829858605731453, 0.08235503490411596, 0.002157773840282514, 0.009110600658970616, 0.2739174013914192, 0.05214620114016076, 0.054543727629363555, 0.051353160559363654, 0.9489636128365742, 0.9990786992365186, 0.9998804879648501, 1.0001010106409778, 0.9987642644552547, 0.9985298724290791, 0.004018827921275645, 0.027387568056100695, 0.041676733998414095, 0.02768525901323222, 0.015182238813707992, 0.0010419183499603525, 0.21180711599908308, 0.009377265149643172, 0.00833534679968282, 0.4145346578056545, 0.03706252416287539, 0.03810444251283575, 0.00416767339984141, 0.014586856899444934, 0.14512434160162052, 0.9999328363591571, 0.9998236520130285, 0.9998792869424749, 0.9989719044048121, 1.0004773277089785, 0.9993638115911136, 0.9984194055435709, 0.9977862406882622, 0.9996153382827611, 0.3056022309166292, 0.2931898153751975, 0.40104942628694895, 0.11356561463223763, 0.03151783798945285, 0.021293552743544556, 0.15894116155002902, 0.4380387992957737, 0.04182662146053395, 0.0027884414307022634, 0.09742645362423362, 0.09446901574318577, 0.09665672484729726, 0.9032639005096018, 0.9995257955181771, 0.014176631067986126, 0.003752637635643386, 0.08547674614521046, 0.031688940034321926, 0.8072340514006218, 0.0012508792118811286, 0.05628956453465079, 0.9999043566919865, 0.006693161068710544, 0.0479676543257589, 0.006693161068710544, 0.0022310536895701815, 0.0878477390268259, 0.7225825137095425, 0.03653350416671172, 0.08896326587161098, 0.8848990142739438, 0.1150934752040737, 0.829635237054047, 0.17027017060300192, 0.9594501830489028, 0.0406607140771654, 0.999781598027786, 0.9990395743512174, 0.000641692728821228, 0.21432537142629016, 0.03352844508090916, 0.09737687159862135, 0.003368886826311447, 0.19844347638796475, 0.013475547305245788, 0.27223814020240594, 0.001122962275437149, 0.16555672403587682, 0.6829551467187597, 0.22745580187621342, 0.089336645698151, 0.10923301216945057, 0.8899924615685436, 0.05384105141740534, 0.05617215839218127, 0.0027822889698938514, 0.044291032520742665, 0.09369546098615511, 0.06647414728070715, 0.5030679245564829, 0.013084277858419735, 0.0006015759934905625, 0.09369546098615511, 0.007444502919445711, 7.519699918632032e-05, 0.06481981329860811, 0.9995272365093053, 6.130335602728779e-05, 0.014651502090521781, 6.130335602728779e-05, 0.15577182766533829, 0.002636044309173375, 0.07252187018028146, 0.00018391006808186338, 0.056031267408941036, 0.021210961185441576, 0.1485380316541183, 0.0321229585582988, 0.0009808536964366046, 0.13431565305578755, 0.04898138146580294, 0.07319620709658162, 0.20561145611552326, 0.0011034604084911802, 0.009502020184229607, 6.130335602728779e-05, 0.02243702830598733, 1.0000016604104784, 0.9999711635342856, 0.9998700897203974, 0.9993994394944341, 0.9982911313025515, 0.830602795565015, 0.16933320489762194, 0.2524161827540571, 0.5374213092909149, 0.20412529333045226, 0.00622152563126197, 1.0004572173165245, 1.0005205911075983, 0.004066747904876622, 0.018910377757676292, 0.13176263211800257, 0.06771135261619576, 0.0274505483579172, 0.5207470692194515, 0.09719527492655126, 0.0010166869762191556, 0.08072494591180095, 0.05042767402047012, 0.9997600340080123, 1.00020321823723, 1.0010025412080716, 0.04142727589690086, 0.6897970224737937, 0.1643939519718288, 0.1038969776461958, 0.9989371262948198, 0.9997888098541914, 0.9997317191149374, 0.9997803353619306, 0.02837560925779645, 0.05446286293028674, 0.4274648233351917, 0.27917938140735216, 0.210071042731106, 0.9469310001499338, 0.05368427717385452, 0.08247722602015388, 0.9177338793598478, 0.9995271066650329, 0.5645796452043352, 0.4356850469595719, 0.011096856722944148, 0.0018692566137579712, 0.21606232795850075, 0.5197720215843197, 0.018455200218372353, 0.1364557328043319, 0.09625188023858507, 0.073203831164495, 0.926407104736885, 0.9995747016103179, 0.407322506274338, 0.03481220840683623, 0.06018381792368297, 0.059003743062434284, 0.3325844317285879, 0.10601005836884027, 1.0003386443906694, 0.9986475456769972, 0.9993663513365133, 0.010786872632520794, 0.028421064414380873, 0.0015007822793072407, 0.13113085165447017, 0.0010317878170237281, 0.012006258234457926, 0.01688380064220646, 0.03826994812233464, 0.016321007287466244, 0.2019490154592806, 0.45436183506026717, 0.013507040513765167, 0.016039610610096136, 0.03526838356372016, 0.0003751955698268102, 0.021855141942411695, 0.0016481892798019023, 0.06015890871276943, 0.9380943984205827, 0.01946378219681131, 0.9790282444996088, 0.9998557907852221, 0.9997622956990037, 0.26486844242162577, 0.046808647152097656, 0.019408463453308784, 0.078775528134018, 0.5896747866843521, 0.013652396499366122, 0.06854640742390074, 0.010239297374524592, 0.18302744056962705, 0.39307524921091624, 0.29338431227283657, 0.03811294022739709, 1.0000094456557886, 0.9996675330954459, 0.8788121669816249, 0.12121547130781034, 0.0034411348151310857, 0.2023100510062484, 0.4179544994211298, 0.37608735917036823, 0.999710215882695, 0.005197954400750803, 0.9945419420103202, 1.000130542393424, 1.0002195987540117, 1.0001549623089907, 0.9991966798531381, 8.233047986222749e-05, 0.01309054629809417, 0.0028404015552468483, 0.00032932191944890995, 0.00032932191944890995, 0.03429064486261775, 0.10530068374378895, 0.22031636411132074, 0.00024699143958668244, 0.021282429044385806, 0.10493019658440893, 0.391604927464685, 0.05470860386845016, 0.047463521640574144, 0.0030873929948335307, 0.8219447823128335, 0.1778600105132764, 0.10225075292408613, 0.007209988988236842, 0.8802741101092799, 0.007428473503031898, 0.002840298692335726, 0.03918007323122519, 0.2228768100202482, 0.7379984285684875, 0.1458965727684833, 0.8535445753802425, 0.10078520495659914, 0.899068018819186, 0.8709822649176951, 0.0379168103493333, 0.0909267199639352, 0.9990477411985851, 0.04755901303309202, 0.9534449755681781, 0.9973476169446784, 0.07858976487622162, 0.6148493369727926, 0.3062689366499813, 0.6309686354041417, 0.3308639252359755, 0.03804429232071156, 0.8647984262274575, 0.1351432770252641, 1.0000061047531965, 0.999290292029095, 0.9998831973963793, 0.9982701220974721, 0.9989337077221482, 1.000450182376218, 1.0008982047323518, 0.9997416170162292, 0.9996842188412483, 0.9985475978746099, 0.9998392970303814, 0.0013533498577683013, 0.03482273287873052, 0.024360297439829422, 0.17213569152460662, 0.03674865383017002, 0.19389339308411238, 0.02701494523775955, 0.03425016178505932, 0.015147108023483678, 0.09744118975931769, 0.014938900353057786, 0.006766749288841506, 0.009681656674804001, 0.1531887935158504, 0.05704890169669454, 0.04929316597333005, 0.019311261432001528, 0.0009369345169165162, 0.00026025958803236563, 0.05142729459519545, 0.9986439403381594, 0.004610193239003512, 0.13081423315672464, 0.02175434934654782, 0.002161028080782896, 0.018152635878576327, 0.04278835599950134, 0.0769325996758711, 0.11496669389765007, 0.018872978572170625, 0.02679674820170791, 0.05272908517110266, 0.0332798324440566, 0.05200874247750836, 0.019881458343202645, 0.0051864673938789504, 0.3786121197531634, 1.00038096064964, 0.9989172518372349, 0.9998268072581491, 1.00062649027008, 0.99901629407376, 0.9987978375851252, 1.0007054434556095, 0.9993734066158274, 0.7198927099880721, 0.27385150750649523, 0.006036170119052679, 0.9994280096598585, 0.854610014341272, 0.14543117006579903, 0.15991405587948443, 0.0005208926901611871, 0.015105888014674424, 0.02773753575108321, 0.3381895790871507, 0.0003906695176208903, 0.23205769346680885, 0.1170706321137268, 0.04388520914608001, 0.01041785380322374, 0.05430306294930375, 0.9983748649492853, 1.0006680405275905, 0.11368011512963239, 0.008133519052536094, 0.7159388282290492, 0.03764116956871355, 0.09438665133059328, 0.030075105333796256, 0.7901613798952054, 0.1998994062902704, 0.009932889753553808, 1.0000790876393784, 0.9980141276437066, 0.9988488677472374, 1.0007047465900754, 0.9997103035366918, 1.0000566465816143, 0.9998224250492974, 0.6820648546459568, 0.3180315372830369, 1.000368171193278, 0.057897181786968004, 0.94082920403823, 1.0005255740641665, 0.9992096901610803, 1.0003786026945083, 1.0001522548359847, 0.8206337537974223, 0.17923644417640308, 0.9982110960856125, 0.15409111589000446, 0.034070397483217066, 0.10550208311564374, 0.1548654431055321, 0.12737682695430017, 0.4237505686975122, 0.03699496751264051, 0.9639244313015777, 1.0004454325581762, 0.999634320454308, 0.4544979267575436, 0.5092655701759617, 0.036205455548417344, 0.9984540947016454, 1.0000781437114505, 0.00837632359484365, 9.00679956434801e-05, 0.0010808159477217613, 0.05178909749500106, 0.04341277390015741, 0.0498076015908445, 0.0167526471896873, 0.04359290989144437, 0.00882666357306105, 0.11825927827988937, 0.025669378758391828, 0.01594203522889598, 0.3049702332488236, 0.18779177091665603, 0.06592977281102744, 0.0070253036601914485, 0.011888975424939373, 9.00679956434801e-05, 9.00679956434801e-05, 0.038729238126696444, 0.9990829141549631, 1.0004740376170247, 0.9999150105122798], \"Term\": [\"2d\", \"3d\", \"abstract\", \"abstract\", \"academ\", \"acceler\", \"acceler\", \"access\", \"access\", \"access\", \"access\", \"access\", \"accuraci\", \"accuraci\", \"accuraci\", \"accuraci\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"achiev\", \"action\", \"action\", \"action\", \"action\", \"activ\", \"activ\", \"activ\", \"activ\", \"activ\", \"actuat\", \"ad\", \"ad\", \"ad\", \"ad\", \"ad\", \"ad\", \"ad\", \"adapt\", \"adapt\", \"adapt\", \"adapt\", \"adapt\", \"admm\", \"adversari\", \"advertis\", \"af\", \"affin\", \"agent\", \"agent\", \"agent\", \"agent\", \"al\", \"al\", \"al\", \"al\", \"al\", \"algebra\", \"algebra\", \"algorithm\", \"algorithm\", \"algorithm\", \"alic\", \"align\", \"align\", \"alloc\", \"alloc\", \"alloc\", \"alpha\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"amplifi\", \"amplitud\", \"analysi\", \"analysi\", \"analysi\", \"analysi\", \"analysi\", \"analysi\", \"analysi\", \"analysi\", \"analysi\", \"analysi\", \"analysi\", \"analysi\", \"angl\", \"anim\", \"anonym\", \"ant\", \"ant\", \"antenna\", \"ap\", \"api\", \"applianc\", \"applic\", \"applic\", \"applic\", \"applic\", \"applic\", \"applic\", \"applic\", \"applic\", \"applic\", \"applic\", \"applic\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approxim\", \"approxim\", \"approxim\", \"approxim\", \"approxim\", \"arab\", \"arc\", \"architectur\", \"architectur\", \"ari\", \"arithmet\", \"arithmet\", \"arm\", \"arm\", \"arrang\", \"array\", \"art\", \"art\", \"art\", \"art\", \"artifact\", \"artifact\", \"arxiv\", \"asp\", \"assembl\", \"assumpt\", \"assumpt\", \"assumpt\", \"assumpt\", \"assumpt\", \"assumpt\", \"assumpt\", \"attack\", \"auction\", \"authent\", \"automat\", \"automat\", \"automat\", \"automat\", \"automat\", \"automat\", \"automat\", \"automata\", \"automaton\", \"avail\", \"avail\", \"avail\", \"avail\", \"avail\", \"avail\", \"avail\", \"avail\", \"avail\", \"avail\", \"axiom\", \"axiomat\", \"backhaul\", \"bag\", \"balanc\", \"balanc\", \"balanc\", \"ball\", \"band\", \"band\", \"bandwidth\", \"bandwidth\", \"bank\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"base\", \"batteri\", \"bayesian\", \"bc\", \"beam\", \"beamform\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behaviour\", \"behaviour\", \"behaviour\", \"behaviour\", \"belief\", \"belief\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"beta\", \"bia\", \"bidder\", \"big\", \"binari\", \"binari\", \"binari\", \"binari\", \"biometr\", \"bipartit\", \"bisimul\", \"bit\", \"bit\", \"bit\", \"bit\", \"bitcoin\", \"blind\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"blocklength\", \"blood\", \"blur\", \"bodi\", \"bodi\", \"bodi\", \"bodi\", \"book\", \"boolean\", \"boolean\", \"bound\", \"bound\", \"bound\", \"brain\", \"broadcast\", \"broadcast\", \"bs\", \"bs\", \"bss\", \"buffer\", \"bug\", \"busi\", \"buyer\", \"ca\", \"cach\", \"calculi\", \"calculu\", \"calibr\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"call\", \"camera\", \"cancel\", \"cancer\", \"capac\", \"carrier\", \"carrier\", \"cartesian\", \"cascad\", \"cascad\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"categori\", \"categori\", \"categori\", \"categori\", \"categori\", \"cell\", \"cellular\", \"central\", \"central\", \"central\", \"central\", \"central\", \"central\", \"central\", \"central\", \"central\", \"cf\", \"chain\", \"challeng\", \"challeng\", \"challeng\", \"challeng\", \"challeng\", \"challeng\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"chang\", \"channel\", \"channel\", \"charact\", \"check\", \"check\", \"check\", \"chemic\", \"chip\", \"chordal\", \"chromat\", \"circl\", \"circuit\", \"citat\", \"citi\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"classic\", \"classic\", \"classic\", \"classic\", \"classic\", \"classic\", \"classic\", \"classif\", \"classifi\", \"client\", \"clinic\", \"cliqu\", \"cloud\", \"cluster\", \"cluster\", \"cluster\", \"cmo\", \"cnn\", \"coalgebra\", \"code\", \"codeword\", \"cognit\", \"coher\", \"coher\", \"coher\", \"coher\", \"collabor\", \"collabor\", \"collabor\", \"collect\", \"collect\", \"collect\", \"collect\", \"collect\", \"collect\", \"collect\", \"collect\", \"collect\", \"collect\", \"collis\", \"coloni\", \"color\", \"colour\", \"commerci\", \"commun\", \"commun\", \"commun\", \"commun\", \"commun\", \"commun\", \"commun\", \"commut\", \"compani\", \"compar\", \"compar\", \"compar\", \"compar\", \"compar\", \"compar\", \"compar\", \"compar\", \"compar\", \"compar\", \"compar\", \"compar\", \"compar\", \"compil\", \"compil\", \"complet\", \"complet\", \"complet\", \"complet\", \"complet\", \"complet\", \"complet\", \"complet\", \"complet\", \"complet\", \"complet\", \"complet\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"composit\", \"composit\", \"composit\", \"composit\", \"composit\", \"compress\", \"comput\", \"comput\", \"comput\", \"comput\", \"comput\", \"comput\", \"comput\", \"comput\", \"comput\", \"concurr\", \"concurr\", \"concurr\", \"condit\", \"condit\", \"condit\", \"condit\", \"condit\", \"condit\", \"condit\", \"confidenti\", \"congest\", \"conjectur\", \"conjectur\", \"connect\", \"connect\", \"connect\", \"connect\", \"connect\", \"connect\", \"connect\", \"connect\", \"consensu\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"consid\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"construct\", \"construct\", \"construct\", \"construct\", \"construct\", \"construct\", \"construct\", \"construct\", \"construct\", \"construct\", \"construct\", \"construct\", \"consumpt\", \"contact\", \"contain\", \"contain\", \"contain\", \"contain\", \"contain\", \"contain\", \"contain\", \"contain\", \"contain\", \"contain\", \"content\", \"content\", \"content\", \"content\", \"content\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"contour\", \"contract\", \"control\", \"control\", \"converg\", \"convex\", \"convex\", \"convex\", \"convolut\", \"cooper\", \"cooper\", \"cooper\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"corpora\", \"corpu\", \"correct\", \"correct\", \"correct\", \"correct\", \"correct\", \"correct\", \"correct\", \"correct\", \"corrupt\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"countri\", \"cours\", \"covari\", \"cp\", \"cr\", \"creation\", \"cross\", \"cross\", \"cross\", \"cross\", \"cross\", \"cross\", \"cross\", \"crowd\", \"cryptograph\", \"cryptographi\", \"cryptographi\", \"cryptosystem\", \"cs\", \"csi\", \"csit\", \"csp\", \"cultur\", \"curv\", \"cut\", \"cut\", \"cycl\", \"cyclic\", \"d2d\", \"dag\", \"data\", \"data\", \"data\", \"data\", \"data\", \"databas\", \"databas\", \"dataset\", \"dataset\", \"db\", \"dc\", \"de\", \"decentr\", \"decentr\", \"decis\", \"decis\", \"decis\", \"decis\", \"declar\", \"declar\", \"decod\", \"deduct\", \"deep\", \"deep\", \"deep\", \"defect\", \"defin\", \"defin\", \"defin\", \"defin\", \"defin\", \"defin\", \"defin\", \"defin\", \"definit\", \"definit\", \"definit\", \"definit\", \"definit\", \"deform\", \"degre\", \"degre\", \"degre\", \"degre\", \"degre\", \"degre\", \"degre\", \"degre\", \"degre\", \"delay\", \"delay\", \"delet\", \"delta\", \"demand\", \"demand\", \"demand\", \"demand\", \"demand\", \"denois\", \"densiti\", \"densiti\", \"densiti\", \"densiti\", \"depend\", \"depend\", \"depend\", \"depend\", \"depend\", \"depend\", \"depend\", \"depend\", \"depend\", \"depend\", \"depend\", \"depend\", \"depend\", \"deriv\", \"deriv\", \"deriv\", \"deriv\", \"deriv\", \"deriv\", \"deriv\", \"deriv\", \"descent\", \"descriptor\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"destin\", \"detect\", \"detect\", \"detect\", \"detect\", \"detector\", \"detector\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"develop\", \"devic\", \"devic\", \"devic\", \"devic\", \"devic\", \"df\", \"diagnosi\", \"diamet\", \"dictionari\", \"dictionari\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differ\", \"differenti\", \"diffus\", \"diffus\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"digit\", \"dilemma\", \"dimens\", \"dimens\", \"dimens\", \"dimens\", \"dimens\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"direct\", \"dirichlet\", \"disciplin\", \"discontinu\", \"discrimin\", \"discrimin\", \"disjoint\", \"disjoint\", \"disjunct\", \"distanc\", \"distanc\", \"distanc\", \"distanc\", \"distanc\", \"distanc\", \"distort\", \"distort\", \"distribut\", \"distribut\", \"distribut\", \"distribut\", \"distribut\", \"distribut\", \"distribut\", \"distribut\", \"distribut\", \"diverg\", \"divers\", \"divers\", \"divers\", \"divers\", \"divers\", \"divis\", \"dna\", \"document\", \"document\", \"document\", \"dof\", \"domin\", \"domin\", \"domin\", \"domin\", \"domin\", \"downlink\", \"draw\", \"draw\", \"draw\", \"draw\", \"drift\", \"dual\", \"dual\", \"dual\", \"dual\", \"duplex\", \"duplex\", \"dynam\", \"dynam\", \"dynam\", \"dynam\", \"dynam\", \"dynam\", \"dynam\", \"dynam\", \"eavesdropp\", \"econom\", \"econom\", \"edg\", \"educ\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effici\", \"effici\", \"effici\", \"effici\", \"effici\", \"effici\", \"effici\", \"effici\", \"effici\", \"effici\", \"effici\", \"effici\", \"effici\", \"effort\", \"effort\", \"effort\", \"effort\", \"eh\", \"eigenvector\", \"eigenvector\", \"elect\", \"electr\", \"electr\", \"embed\", \"embed\", \"embed\", \"embed\", \"embed\", \"embed\", \"embed\", \"embed\", \"emph\", \"empti\", \"encod\", \"encod\", \"encod\", \"encod\", \"encod\", \"encod\", \"encrypt\", \"encrypt\", \"energi\", \"engin\", \"english\", \"ensembl\", \"entangl\", \"enterpris\", \"entropi\", \"environ\", \"environ\", \"environ\", \"environ\", \"environ\", \"environment\", \"ep\", \"epidem\", \"epistem\", \"epsilon\", \"equat\", \"equat\", \"equat\", \"equilibria\", \"equilibrium\", \"equilibrium\", \"er\", \"erasur\", \"erd\", \"ergod\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"estim\", \"estim\", \"estim\", \"et\", \"et\", \"et\", \"et\", \"et\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"evolut\", \"evolut\", \"evolut\", \"evolutionari\", \"exce\", \"exchang\", \"exchang\", \"exchang\", \"exchang\", \"expans\", \"expans\", \"expans\", \"explan\", \"expon\", \"expon\", \"express\", \"express\", \"express\", \"express\", \"express\", \"express\", \"express\", \"extend\", \"extend\", \"extend\", \"extend\", \"extend\", \"extend\", \"extend\", \"extend\", \"extend\", \"extend\", \"extend\", \"extend\", \"extract\", \"extract\", \"extract\", \"face\", \"face\", \"face\", \"facebook\", \"fade\", \"fade\", \"failur\", \"failur\", \"failur\", \"failur\", \"failur\", \"famili\", \"famili\", \"famili\", \"famili\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"fast\", \"fastest\", \"fault\", \"featur\", \"featur\", \"featur\", \"featur\", \"featur\", \"featur\", \"featur\", \"feedback\", \"femtocel\", \"file\", \"file\", \"filter\", \"filter\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"find\", \"fingerprint\", \"finit\", \"finit\", \"finit\", \"finit\", \"finit\", \"finit\", \"finit\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"firstli\", \"floor\", \"flow\", \"flow\", \"flow\", \"flow\", \"fluid\", \"fo\", \"forbidden\", \"forecast\", \"forest\", \"formal\", \"forward\", \"forward\", \"forward\", \"forward\", \"forward\", \"fractal\", \"fragment\", \"fragment\", \"framework\", \"framework\", \"framework\", \"framework\", \"framework\", \"framework\", \"framework\", \"framework\", \"framework\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"free\", \"freedom\", \"frequenc\", \"frequenc\", \"frequenc\", \"frequenc\", \"friend\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"fuse\", \"fuzzi\", \"ga\", \"gabor\", \"game\", \"gamma\", \"gate\", \"gaussian\", \"gaussian\", \"gaussian\", \"gender\", \"gene\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"gener\", \"genom\", \"gestur\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"gpu\", \"gradient\", \"grain\", \"grammar\", \"graph\", \"gray\", \"green\", \"grid\", \"grid\", \"group\", \"group\", \"group\", \"group\", \"guard\", \"hamiltonian\", \"handov\", \"handwritten\", \"hard\", \"harmon\", \"harvest\", \"hash\", \"hash\", \"health\", \"heat\", \"heurist\", \"heurist\", \"hidden\", \"hidden\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"histogram\", \"hit\", \"hoc\", \"homolog\", \"hop\", \"http\", \"hull\", \"human\", \"human\", \"human\", \"human\", \"hypergraph\", \"hypothesi\", \"ia\", \"ic\", \"id\", \"identif\", \"identif\", \"identif\", \"identif\", \"illumin\", \"imag\", \"impact\", \"impact\", \"impact\", \"impact\", \"impact\", \"impair\", \"imperfect\", \"implement\", \"implement\", \"implement\", \"implement\", \"implement\", \"implement\", \"implement\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"improv\", \"impuls\", \"incent\", \"index\", \"individu\", \"individu\", \"individu\", \"individu\", \"individu\", \"individu\", \"individu\", \"individu\", \"individu\", \"individu\", \"induct\", \"industri\", \"inequ\", \"inequ\", \"infect\", \"infer\", \"infer\", \"influenc\", \"influenc\", \"influenti\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"inform\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"instanc\", \"instanc\", \"instanc\", \"instanc\", \"instanc\", \"instanc\", \"instanc\", \"instanc\", \"instanc\", \"instantan\", \"integr\", \"integr\", \"integr\", \"integr\", \"integr\", \"integr\", \"integr\", \"intel\", \"intellig\", \"intension\", \"interact\", \"interact\", \"interact\", \"interact\", \"interact\", \"interfac\", \"interfer\", \"interleav\", \"interpol\", \"interpol\", \"interpol\", \"intersect\", \"interv\", \"interv\", \"interv\", \"interv\", \"intract\", \"intrus\", \"intuitionist\", \"invari\", \"invari\", \"invert\", \"isomorph\", \"issu\", \"issu\", \"issu\", \"issu\", \"issu\", \"issu\", \"issu\", \"issu\", \"issu\", \"item\", \"item\", \"item\", \"iter\", \"iter\", \"jam\", \"join\", \"joint\", \"joint\", \"joint\", \"journal\", \"jump\", \"kalman\", \"kernel\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"l1\", \"label\", \"label\", \"label\", \"label\", \"lambda\", \"landscap\", \"languag\", \"languag\", \"laplacian\", \"larg\", \"larg\", \"larg\", \"larg\", \"larg\", \"larg\", \"larg\", \"larg\", \"larg\", \"larg\", \"larg\", \"larg\", \"larg\", \"larg\", \"larg\", \"lasso\", \"latenc\", \"latent\", \"lattic\", \"lattic\", \"layer\", \"layer\", \"layer\", \"layer\", \"layout\", \"layout\", \"ldpc\", \"leader\", \"learn\", \"learn\", \"learner\", \"legitim\", \"lemma\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"let\", \"let\", \"let\", \"lexic\", \"lift\", \"light\", \"light\", \"light\", \"light\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linguist\", \"link\", \"link\", \"link\", \"liquid\", \"list\", \"list\", \"list\", \"list\", \"list\", \"list\", \"load\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"locat\", \"locat\", \"locat\", \"locat\", \"locat\", \"locat\", \"locat\", \"locat\", \"log\", \"log\", \"log\", \"log\", \"logic\", \"logist\", \"loop\", \"loop\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lp\", \"lte\", \"lyapunov\", \"mac\", \"machin\", \"machin\", \"machin\", \"machin\", \"machin\", \"machin\", \"magnet\", \"magnitud\", \"magnitud\", \"maker\", \"malici\", \"manag\", \"manag\", \"manet\", \"manifold\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"margin\", \"market\", \"markov\", \"markov\", \"match\", \"match\", \"match\", \"match\", \"match\", \"match\", \"matlab\", \"matric\", \"matric\", \"matric\", \"matrix\", \"matrix\", \"matroid\", \"max\", \"maxim\", \"maxim\", \"maxim\", \"maxim\", \"maxim\", \"maxim\", \"maximum\", \"maximum\", \"maximum\", \"maximum\", \"maximum\", \"maximum\", \"maximum\", \"maximum\", \"md\", \"mdp\", \"measur\", \"measur\", \"measur\", \"measur\", \"measur\", \"measur\", \"measur\", \"measur\", \"measur\", \"measur\", \"measur\", \"mechan\", \"mechan\", \"mechan\", \"mechan\", \"mechan\", \"mechan\", \"mechan\", \"mechan\", \"media\", \"media\", \"medic\", \"medic\", \"memori\", \"memori\", \"memori\", \"memoryless\", \"messag\", \"messag\", \"messag\", \"messag\", \"meter\", \"method\", \"method\", \"method\", \"method\", \"methodolog\", \"methodolog\", \"methodolog\", \"methodolog\", \"migrat\", \"mimo\", \"min\", \"min\", \"min\", \"min\", \"mine\", \"minim\", \"minim\", \"minim\", \"minim\", \"minim\", \"minim\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minor\", \"mismatch\", \"miso\", \"mixtur\", \"ml\", \"mmse\", \"mobil\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"modul\", \"modul\", \"modul\", \"modul\", \"modul\", \"modul\", \"molecular\", \"moment\", \"moment\", \"monad\", \"motif\", \"mrf\", \"mu\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multicast\", \"multicast\", \"multidimension\", \"multidimension\", \"multilay\", \"multipath\", \"multipl\", \"multipl\", \"multipl\", \"multipl\", \"multipl\", \"multipl\", \"multipl\", \"multipl\", \"multipl\", \"multipl\", \"multipl\", \"multipl\", \"multipl\", \"multiplex\", \"multipli\", \"multius\", \"music\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"natur\", \"negat\", \"nest\", \"nest\", \"nest\", \"network\", \"neural\", \"neural\", \"neuron\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"news\", \"newton\", \"node\", \"nois\", \"nois\", \"nois\", \"nonconvex\", \"nonlinear\", \"nonzero\", \"norm\", \"notion\", \"notion\", \"notion\", \"notion\", \"np\", \"null\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"numer\", \"numer\", \"numer\", \"numer\", \"numer\", \"object\", \"object\", \"object\", \"object\", \"observ\", \"observ\", \"observ\", \"observ\", \"observ\", \"observ\", \"occup\", \"odd\", \"ofdm\", \"offlin\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"onlin\", \"onlin\", \"ontolog\", \"oper\", \"oper\", \"oper\", \"oper\", \"oper\", \"oper\", \"oper\", \"oper\", \"oper\", \"opinion\", \"opportunist\", \"optic\", \"optim\", \"optim\", \"optim\", \"optim\", \"optim\", \"optim\", \"oracl\", \"oracl\", \"oracl\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"ordin\", \"oscil\", \"outag\", \"outer\", \"outlier\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"overhead\", \"overlap\", \"overlap\", \"overlay\", \"overview\", \"p2p\", \"pack\", \"packet\", \"page\", \"pair\", \"pair\", \"pair\", \"pair\", \"pair\", \"pair\", \"pair\", \"pair\", \"pair\", \"pair\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paradox\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"paramet\", \"paramet\", \"paramet\", \"paramet\", \"paramet\", \"paramet\", \"paramet\", \"paramet\", \"paramet\", \"parameter\", \"parameter\", \"pariti\", \"pars\", \"parti\", \"particl\", \"password\", \"patch\", \"path\", \"path\", \"patient\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"payment\", \"pca\", \"peak\", \"peak\", \"pedestrian\", \"peer\", \"penalti\", \"peopl\", \"peopl\", \"peopl\", \"percept\", \"percept\", \"perceptu\", \"percol\", \"perfect\", \"perfect\", \"perfect\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"perform\", \"period\", \"period\", \"period\", \"permut\", \"persist\", \"persist\", \"perturb\", \"petri\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phase\", \"phi\", \"phylogenet\", \"physic\", \"physic\", \"physic\", \"physic\", \"physic\", \"physic\", \"physic\", \"physic\", \"physic\", \"pi\", \"piecewis\", \"pivot\", \"pixel\", \"placement\", \"plan\", \"plan\", \"planar\", \"plane\", \"platform\", \"player\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"polar\", \"poli\", \"polici\", \"polici\", \"polici\", \"polici\", \"polit\", \"polygon\", \"polymorph\", \"polynomi\", \"polynomi\", \"polytop\", \"poorli\", \"popul\", \"posterior\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"precod\", \"predic\", \"predict\", \"predict\", \"predict\", \"predictor\", \"preferenti\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"price\", \"primal\", \"prime\", \"prior\", \"prior\", \"prior\", \"prioriti\", \"privaci\", \"privat\", \"privat\", \"privat\", \"probabilist\", \"probabilist\", \"probabl\", \"probabl\", \"probabl\", \"probabl\", \"probabl\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"processor\", \"processor\", \"profil\", \"profil\", \"profil\", \"profit\", \"program\", \"program\", \"program\", \"programm\", \"project\", \"project\", \"project\", \"project\", \"prolog\", \"proof\", \"proof\", \"proof\", \"proof\", \"properti\", \"properti\", \"properti\", \"properti\", \"properti\", \"properti\", \"properti\", \"properti\", \"properti\", \"propos\", \"propos\", \"propos\", \"propos\", \"propos\", \"propos\", \"propos\", \"propos\", \"propos\", \"propos\", \"propos\", \"propos\", \"propos\", \"proposit\", \"protein\", \"protocol\", \"protocol\", \"protocol\", \"prototyp\", \"prototyp\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"provid\", \"prune\", \"pseudo\", \"pu\", \"public\", \"public\", \"public\", \"publicli\", \"publish\", \"publish\", \"puls\", \"pursuit\", \"qo\", \"quantiz\", \"quantum\", \"quasi\", \"quasi\", \"qubit\", \"queri\", \"queri\", \"queue\", \"radar\", \"radiat\", \"radio\", \"radio\", \"radio\", \"radiu\", \"ran\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"rao\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"ratio\", \"ratio\", \"ratio\", \"ratio\", \"ratio\", \"ratio\", \"rayleigh\", \"reachabl\", \"reaction\", \"reason\", \"reason\", \"reason\", \"reason\", \"reason\", \"receiv\", \"receiv\", \"receiv\", \"recept\", \"recognit\", \"recognit\", \"recommend\", \"reconfigur\", \"reconstruct\", \"reconstruct\", \"record\", \"record\", \"record\", \"recoveri\", \"recurr\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reduc\", \"reed\", \"refactor\", \"regim\", \"regim\", \"region\", \"region\", \"region\", \"region\", \"registr\", \"regress\", \"regress\", \"regret\", \"reinforc\", \"relat\", \"relat\", \"relat\", \"relat\", \"relat\", \"relat\", \"relat\", \"relat\", \"relax\", \"relay\", \"repair\", \"replic\", \"repositori\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"represent\", \"requir\", \"requir\", \"requir\", \"requir\", \"requir\", \"requir\", \"requir\", \"requir\", \"requir\", \"requir\", \"requir\", \"requir\", \"requir\", \"requir\", \"requir\", \"research\", \"research\", \"research\", \"research\", \"research\", \"residu\", \"residu\", \"resili\", \"resili\", \"resili\", \"resist\", \"resolut\", \"resolut\", \"resourc\", \"resourc\", \"restor\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"retriev\", \"retriev\", \"retriev\", \"revenu\", \"revers\", \"revers\", \"review\", \"revis\", \"reward\", \"rewrit\", \"rf\", \"rigid\", \"ring\", \"risk\", \"risk\", \"road\", \"robot\", \"robust\", \"robust\", \"robust\", \"robust\", \"robust\", \"rout\", \"rs\", \"rule\", \"rule\", \"rule\", \"rule\", \"run\", \"run\", \"run\", \"run\", \"run\", \"sa\", \"safe\", \"sampl\", \"sampl\", \"sat\", \"satisfact\", \"satisfi\", \"satisfi\", \"satisfi\", \"satisfi\", \"satisfi\", \"satisfi\", \"satisfi\", \"satisfi\", \"sc\", \"sc\", \"scalar\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scatter\", \"scene\", \"schedul\", \"schedul\", \"schema\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scholar\", \"scientif\", \"scientif\", \"screen\", \"sdp\", \"se\", \"search\", \"search\", \"search\", \"search\", \"secondari\", \"secreci\", \"secret\", \"secur\", \"segment\", \"select\", \"select\", \"select\", \"select\", \"select\", \"select\", \"select\", \"select\", \"select\", \"select\", \"select\", \"self\", \"self\", \"self\", \"self\", \"self\", \"self\", \"semant\", \"semant\", \"semidefinit\", \"semigroup\", \"sender\", \"sens\", \"sens\", \"sens\", \"sens\", \"sens\", \"sens\", \"sens\", \"sens\", \"sens\", \"sensor\", \"sentenc\", \"sequenc\", \"sequenc\", \"sequenc\", \"sequenc\", \"sequenc\", \"sequenc\", \"sequenc\", \"sequenc\", \"sequenti\", \"sequenti\", \"sequenti\", \"servic\", \"servic\", \"session\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"shadow\", \"shape\", \"shapley\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"share\", \"shed\", \"shot\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"si\", \"si\", \"si\", \"side\", \"side\", \"side\", \"side\", \"side\", \"side\", \"side\", \"signal\", \"signatur\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"similar\", \"simul\", \"simul\", \"simul\", \"simul\", \"simul\", \"simul\", \"simul\", \"singular\", \"singular\", \"sink\", \"sinr\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"skeleton\", \"skew\", \"slice\", \"slide\", \"slot\", \"smart\", \"smooth\", \"snr\", \"snr\", \"social\", \"societi\", \"soft\", \"softwar\", \"solut\", \"solut\", \"solut\", \"solut\", \"solv\", \"solv\", \"solvabl\", \"solver\", \"sort\", \"sort\", \"sound\", \"sound\", \"sound\", \"sound\", \"sourc\", \"sourc\", \"sourc\", \"sourc\", \"sourc\", \"sourc\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"span\", \"span\", \"spanner\", \"spars\", \"sparsiti\", \"speaker\", \"speci\", \"specif\", \"specif\", \"specif\", \"specif\", \"specif\", \"specif\", \"specif\", \"specif\", \"specif\", \"specif\", \"specif\", \"specif\", \"specif\", \"specif\", \"specif\", \"spectral\", \"spectrum\", \"speech\", \"sphere\", \"spheric\", \"spike\", \"spin\", \"spline\", \"spread\", \"squar\", \"squar\", \"squar\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"station\", \"station\", \"stationari\", \"statist\", \"statist\", \"statist\", \"statist\", \"statist\", \"statist\", \"statist\", \"steiner\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"stochast\", \"stochast\", \"storag\", \"storag\", \"store\", \"store\", \"straight\", \"strateg\", \"strategi\", \"strategi\", \"strategi\", \"strategi\", \"strategi\", \"strategi\", \"strategi\", \"strategi\", \"strategi\", \"strategi\", \"stream\", \"stream\", \"stream\", \"string\", \"string\", \"structur\", \"structur\", \"structur\", \"structur\", \"structur\", \"structur\", \"structur\", \"structur\", \"structur\", \"structur\", \"structur\", \"structur\", \"structur\", \"student\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"studi\", \"su\", \"subcarri\", \"subgraph\", \"submodular\", \"suboptim\", \"subspac\", \"subspac\", \"sum\", \"sum\", \"sum\", \"sum\", \"super\", \"supervis\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"support\", \"sure\", \"surfac\", \"surveil\", \"survey\", \"survey\", \"survey\", \"survey\", \"sustain\", \"svm\", \"swarm\", \"switch\", \"symbol\", \"symbol\", \"symbol\", \"symbol\", \"symbol\", \"symmetri\", \"symmetri\", \"synchron\", \"synchron\", \"syntax\", \"synthesi\", \"synthesi\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"tabl\", \"tabl\", \"tag\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"tcp\", \"teach\", \"team\", \"techniqu\", \"techniqu\", \"techniqu\", \"techniqu\", \"techniqu\", \"techniqu\", \"techniqu\", \"techniqu\", \"techniqu\", \"techniqu\", \"techniqu\", \"techniqu\", \"techniqu\", \"techniqu\", \"techniqu\", \"techniqu\", \"technolog\", \"technolog\", \"technolog\", \"templat\", \"templat\", \"tempor\", \"tensor\", \"termin\", \"termin\", \"termin\", \"termin\", \"termin\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"text\", \"textur\", \"theorem\", \"theorem\", \"theori\", \"theori\", \"theori\", \"theori\", \"thermal\", \"thread\", \"thread\", \"throughput\", \"tie\", \"tier\", \"tile\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"toler\", \"toler\", \"tool\", \"tool\", \"tool\", \"tool\", \"tool\", \"topolog\", \"topolog\", \"topolog\", \"trace\", \"trace\", \"traffic\", \"traffic\", \"train\", \"train\", \"train\", \"transact\", \"transceiv\", \"transceiv\", \"transduc\", \"translat\", \"translat\", \"translat\", \"transmiss\", \"transmiss\", \"transmiss\", \"transmit\", \"transmit\", \"transmitt\", \"transport\", \"tree\", \"treewidth\", \"triangl\", \"triangul\", \"trigger\", \"trust\", \"ture\", \"tv\", \"twitter\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"tx\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"uml\", \"unbound\", \"uncertainti\", \"unconstrain\", \"undecid\", \"undirect\", \"unsupervis\", \"uplink\", \"upper\", \"upper\", \"upper\", \"urban\", \"user\", \"user\", \"valu\", \"valu\", \"valu\", \"valu\", \"valu\", \"valu\", \"valu\", \"valu\", \"valu\", \"valu\", \"valu\", \"valuat\", \"vanish\", \"variabl\", \"variabl\", \"variabl\", \"variabl\", \"variabl\", \"variabl\", \"vector\", \"vector\", \"vector\", \"vehicl\", \"vehicular\", \"veloc\", \"verb\", \"vertex\", \"vertic\", \"video\", \"visual\", \"visual\", \"voltag\", \"vote\", \"vote\", \"vulner\", \"walk\", \"wave\", \"wavelet\", \"web\", \"web\", \"websit\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"white\", \"white\", \"width\", \"win\", \"wireless\", \"wireless\", \"wireless\", \"wiretap\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"workflow\", \"wsn\", \"zone\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el581402085494934563659634911\", ldavis_el581402085494934563659634911_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el581402085494934563659634911\", ldavis_el581402085494934563659634911_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el581402085494934563659634911\", ldavis_el581402085494934563659634911_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 201,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics = model_2.top_topics(corpus_1) #, num_words=20)\n",
    "model_2.num_topics\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / NUM_TOPICS\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "lda_display = pyLDAvis.gensim.prepare(model_2, corpus_1, dictionary_1, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCnaQ2PsTPKU"
   },
   "source": [
    "As model_1, in model_2 we also got rid of stop words. Something good for this model. In this case, we have too many topics close to each other and even overlapping one over the other one, meaning that these topics have a close relationship with each other. Another thing that can be observed is the size of the circles. They are much smaller than the topics from model_1. \n",
    "\n",
    "This is something that might be obvious because there are the same amount of documents but they have to be classified in 20 different topics instead of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSv25EMFTQJm",
    "outputId": "850c8839-fdc6-4ee4-921a-0f7f548d20bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.088*\"quantum\" + 0.037*\"filter\" + 0.036*\"circuit\" + 0.024*\"classic\" + 0.021*\"comput\"\n",
      "1: 0.198*\"graph\" + 0.059*\"tree\" + 0.054*\"edg\" + 0.031*\"path\" + 0.029*\"vertic\"\n",
      "2: 0.148*\"user\" + 0.064*\"interfer\" + 0.061*\"scheme\" + 0.031*\"cell\" + 0.029*\"propos\"\n",
      "3: 0.026*\"bound\" + 0.018*\"function\" + 0.016*\"gener\" + 0.016*\"set\" + 0.013*\"result\"\n",
      "4: 0.046*\"imag\" + 0.040*\"learn\" + 0.024*\"featur\" + 0.019*\"method\" + 0.019*\"relay\"\n",
      "5: 0.077*\"channel\" + 0.037*\"rate\" + 0.026*\"capac\" + 0.024*\"receiv\" + 0.023*\"inform\"\n",
      "6: 0.044*\"word\" + 0.038*\"languag\" + 0.030*\"pattern\" + 0.026*\"text\" + 0.018*\"document\"\n",
      "7: 0.186*\"network\" + 0.050*\"node\" + 0.032*\"commun\" + 0.023*\"mobil\" + 0.017*\"link\"\n",
      "8: 0.097*\"data\" + 0.024*\"queri\" + 0.015*\"web\" + 0.015*\"memori\" + 0.014*\"kernel\"\n",
      "9: 0.064*\"model\" + 0.016*\"distribut\" + 0.013*\"measur\" + 0.012*\"structur\" + 0.012*\"gener\"\n",
      "10: 0.031*\"control\" + 0.025*\"energi\" + 0.025*\"system\" + 0.021*\"power\" + 0.018*\"time\"\n",
      "11: 0.170*\"code\" + 0.051*\"decod\" + 0.038*\"error\" + 0.021*\"block\" + 0.018*\"binari\"\n",
      "12: 0.032*\"system\" + 0.015*\"develop\" + 0.013*\"applic\" + 0.012*\"paper\" + 0.011*\"comput\"\n",
      "13: 0.041*\"algorithm\" + 0.032*\"method\" + 0.020*\"propos\" + 0.018*\"base\" + 0.014*\"approach\"\n",
      "14: 0.091*\"problem\" + 0.045*\"algorithm\" + 0.033*\"time\" + 0.032*\"optim\" + 0.021*\"approxim\"\n",
      "15: 0.032*\"social\" + 0.018*\"studi\" + 0.018*\"onlin\" + 0.017*\"dynam\" + 0.015*\"interact\"\n",
      "16: 0.054*\"secur\" + 0.048*\"group\" + 0.039*\"color\" + 0.031*\"attack\" + 0.029*\"protocol\"\n",
      "17: 0.054*\"signal\" + 0.028*\"system\" + 0.028*\"nois\" + 0.026*\"compress\" + 0.023*\"estim\"\n",
      "18: 0.066*\"constraint\" + 0.047*\"shape\" + 0.032*\"gradient\" + 0.030*\"cycl\" + 0.026*\"array\"\n",
      "19: 0.031*\"logic\" + 0.030*\"game\" + 0.023*\"program\" + 0.019*\"semant\" + 0.019*\"languag\"\n"
     ]
    }
   ],
   "source": [
    "for i,topic in model_2.show_topics(formatted=True, num_topics=20, num_words=5):\n",
    "    print(str(i)+\": \"+ topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7wM2O3oExc_"
   },
   "source": [
    "**Model 3:**\n",
    "   - *Preprocessing:* Method #2\n",
    "   - *Number of topics:* 3 (Known three categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "wApzuFA0Ex1Z",
    "outputId": "1955dd20-ffd0-4ac8-a185-b490e0fb2012"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -0.1938.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el581402029456411681159948789\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el581402029456411681159948789_data = {\"mdsDat\": {\"x\": [-0.17406609169127, 0.05074101805354209, 0.12332507363772786], \"y\": [0.03534524290729261, -0.1448164185982245, 0.10947117569093191], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [19.385354987971493, 37.52115196685045, 43.09349304517806]}, \"tinfo\": {\"Term\": [\"channel\", \"network\", \"code\", \"graph\", \"rate\", \"scheme\", \"problem\", \"algorithm\", \"power\", \"user\", \"system\", \"capacity\", \"interference\", \"optimal\", \"energy\", \"coding\", \"performance\", \"transmission\", \"signal\", \"communication\", \"wireless\", \"information\", \"bound\", \"data\", \"error\", \"relay\", \"multiple\", \"function\", \"source\", \"set\", \"channel\", \"interference\", \"coding\", \"transmission\", \"capacity\", \"relay\", \"mimo\", \"receiver\", \"decoding\", \"antenna\", \"equilibrium\", \"transmitter\", \"transmit\", \"fading\", \"achievable\", \"calculus\", \"decoder\", \"base_station\", \"hop\", \"precoding\", \"snr\", \"outage\", \"broadcast\", \"csi\", \"beamforming\", \"modulation\", \"cellular_network\", \"dof\", \"relaying\", \"mac\", \"code\", \"station\", \"radio\", \"delay\", \"rate\", \"scheme\", \"throughput\", \"wireless\", \"power\", \"feedback\", \"packet\", \"allocation\", \"cooperative\", \"energy\", \"signal\", \"message\", \"communication\", \"multiple\", \"error\", \"noise\", \"source\", \"optimal\", \"user\", \"performance\", \"network\", \"proposed\", \"at\", \"information\", \"system\", \"node\", \"two\", \"a\", \"paper\", \"which\", \"it\", \"result\", \"this_paper\", \"can\", \"graph\", \"polynomial\", \"sparse\", \"edge\", \"vertex\", \"sampling\", \"equation\", \"automaton\", \"bayesian\", \"np\", \"entropy\", \"polynomial_time\", \"gradient\", \"norm\", \"estimator\", \"color\", \"sparsity\", \"boolean\", \"conjecture\", \"tensor\", \"algebra\", \"combinatorial\", \"projection\", \"permutation\", \"coloring\", \"string\", \"manifold\", \"equivalence\", \"compressed_sensing\", \"c\", \"tree\", \"algebraic\", \"proof\", \"partition\", \"formula\", \"inequality\", \"dimensional\", \"approximation\", \"theorem\", \"matrix\", \"kernel\", \"function\", \"problem\", \"algorithm\", \"prove\", \"family\", \"set\", \"quantum\", \"variable\", \"class\", \"space\", \"linear\", \"sequence\", \"given\", \"if\", \"property\", \"random\", \"complexity\", \"show\", \"bound\", \"number\", \"method\", \"show_that\", \"time\", \"be\", \"point\", \"which\", \"our\", \"result\", \"it\", \"a\", \"can\", \"can_be\", \"from\", \"model\", \"two\", \"one\", \"such\", \"also\", \"paper\", \"where\", \"this_paper\", \"social\", \"software\", \"service\", \"research\", \"agent\", \"human\", \"development\", \"community\", \"technology\", \"device\", \"web\", \"cloud\", \"challenge\", \"database\", \"traffic\", \"management\", \"content\", \"routing\", \"project\", \"video\", \"activity\", \"semantic\", \"social_network\", \"consumption\", \"platform\", \"neural\", \"privacy\", \"document\", \"internet\", \"fuzzy\", \"world\", \"attack\", \"architecture\", \"modeling\", \"interaction\", \"feature\", \"data\", \"image\", \"network\", \"quality\", \"system\", \"level\", \"environment\", \"model\", \"based\", \"task\", \"different\", \"application\", \"a\", \"approach\", \"process\", \"been\", \"used\", \"from\", \"have\", \"their\", \"using\", \"it\", \"paper\", \"information\", \"dynamic\", \"be\", \"this_paper\", \"analysis\", \"can\", \"which\", \"or\", \"ha\", \"method\", \"our\", \"these\", \"such\", \"based_on\"], \"Freq\": [16969.0, 39086.0, 13555.0, 17362.0, 11319.0, 11782.0, 35171.0, 38922.0, 10593.0, 14713.0, 33698.0, 5686.0, 5673.0, 11094.0, 8301.0, 5199.0, 15688.0, 5023.0, 8878.0, 7831.0, 5985.0, 17834.0, 12493.0, 25690.0, 8624.0, 4407.0, 8073.0, 14378.0, 6746.0, 17115.0, 16968.787329804403, 5673.680807529364, 5198.905318487958, 5023.783923055029, 5686.485077351277, 4407.146852476831, 3567.522765646633, 3498.918171536335, 3294.991375745727, 3229.643325496091, 2264.0567741804552, 2017.301404824332, 1916.1719934562375, 1929.6234441850634, 1917.0575125683567, 1738.4094215860189, 1511.0426614594103, 1217.015216235406, 1153.2090682521068, 1092.3362023277025, 1148.0104558280045, 1103.839011459298, 1127.334978043185, 1038.195240419473, 1034.575339250929, 1012.9021406672038, 959.7105877595275, 961.3121731726729, 948.6939859373398, 948.4394123386732, 12258.60284884562, 1625.5280831057073, 1918.2912710106427, 2870.8027435122385, 9897.80258582344, 9666.325576207591, 2078.592578619099, 5026.2064803884805, 8028.341331149462, 2645.8406620671744, 2135.3608478633228, 2500.488273745464, 1543.911905687776, 5781.811945950692, 5733.829325130167, 2782.349164885811, 5135.487110958914, 5235.236316691892, 5488.666733321911, 4079.210046157613, 4477.603727509005, 6050.380322319242, 7070.336379927968, 6897.00810811281, 11277.236283850894, 6710.420712537508, 6999.69414534293, 6217.37587046026, 8334.460660793276, 4874.908914464859, 5750.879248937384, 6926.50946128812, 5669.292650171505, 5853.6352232470235, 5697.606124680379, 5376.383015073739, 5336.996870764453, 5211.695916399589, 17362.038953408177, 5313.868798582238, 4927.209799652478, 4685.6103285818945, 4387.4685417561495, 2970.4921451042565, 2716.9143013850335, 2324.1030152543335, 2296.670770934034, 1937.4276044578935, 2207.1841136819326, 1734.69283314753, 1665.9815635322022, 1641.8764753159385, 1586.494949263026, 1560.7035099394282, 1446.1489349591582, 1371.6951659148046, 1374.4330215036262, 1267.771536606352, 1320.734157068639, 1218.801579803172, 1176.3305949815797, 1153.067982588233, 1146.3882256256177, 1147.9726704910072, 1076.9683195962687, 1088.7301573837474, 1003.9423829530929, 982.3099523714267, 5136.356012988802, 1810.5118404968855, 3526.0602947738453, 1507.3779200535862, 1879.7351857973902, 1390.072894330996, 3548.439974184552, 5147.0789414482915, 2493.565843853017, 8329.037098160552, 2279.0227980781347, 12440.48806716605, 28466.374105595198, 30766.362109178997, 4538.153904844772, 2479.17734405407, 13868.962693948359, 5260.255682970061, 4324.843911875041, 6867.007455772275, 6616.299780365497, 8044.9026487107, 4109.0515286520995, 6775.067924182234, 5990.638202013807, 6112.404583774185, 5497.679669820146, 7031.120524728303, 13462.907158630507, 8411.208897376646, 10908.050244481978, 13784.804677192642, 9926.043529972816, 12782.263027977138, 16877.872092804195, 6071.254308937145, 15483.155530769112, 12445.817216557527, 12201.446811717216, 15021.934749811964, 17022.862410931015, 13532.322484604038, 8981.884361161021, 10595.447185859291, 10855.177062331908, 8667.103231549458, 8019.366293051396, 8183.162320365819, 7909.75792390673, 8726.306050839632, 7218.193413498618, 7574.519211642636, 6093.1475188033, 5829.968492364242, 4897.892983691574, 5075.056710101828, 4195.818357360693, 3682.9458295989552, 3701.497559010777, 3226.082387938498, 3222.3759580193064, 3122.66910645348, 3187.6638668554237, 2850.1055034950646, 2888.142656522904, 2801.335689013922, 2547.673914264395, 2559.9253265093116, 2384.365537701477, 2356.825065510387, 2131.398408060987, 2014.1176489322402, 1928.6660722586455, 1839.4598467163464, 1791.3236000081922, 1769.4652196040458, 1758.9533424922986, 1699.3027028766244, 1662.6856709709416, 1645.9189193992543, 1643.5576520534314, 1642.5359947958825, 3331.9603883337477, 2313.303664506634, 3460.0535893595365, 2845.282147363529, 2952.207521789401, 6955.553074623718, 21804.856785715558, 9058.6637628942, 27775.461542936042, 4065.0465206304725, 22378.60968242357, 5829.664566864284, 3258.8350363358286, 19981.320151190488, 18982.359114822873, 4596.427234631442, 8378.373289008823, 8570.94048578182, 24592.947752124608, 11912.330747223861, 7216.280240539081, 7494.922061260587, 8830.518579518499, 15194.819662302047, 10168.803669506804, 8128.707257875562, 12223.009238001452, 18012.99107059726, 14816.613601210849, 10472.566686216132, 5547.65443334229, 15845.740412393465, 12193.685103032487, 8129.76515240426, 13659.169443946224, 13436.092802754427, 9604.502271375353, 9073.05755767776, 10757.737644937684, 10449.207673655947, 8669.433973236279, 8732.231410720742, 8243.654219847906], \"Total\": [16969.0, 39086.0, 13555.0, 17362.0, 11319.0, 11782.0, 35171.0, 38922.0, 10593.0, 14713.0, 33698.0, 5686.0, 5673.0, 11094.0, 8301.0, 5199.0, 15688.0, 5023.0, 8878.0, 7831.0, 5985.0, 17834.0, 12493.0, 25690.0, 8624.0, 4407.0, 8073.0, 14378.0, 6746.0, 17115.0, 16969.01139749474, 5673.877385847737, 5199.1019469088515, 5023.97643391594, 5686.725816836748, 4407.3396140188315, 3567.707826927268, 3499.106475082743, 3295.1799648030574, 3229.8282386408105, 2264.234251381811, 2017.4805094564986, 1916.3486172716325, 1929.8026533489558, 1917.2360500244247, 1738.5855507268136, 1511.2164941249796, 1217.1818354814495, 1153.3781303009212, 1092.498538341409, 1148.1825568761535, 1104.0059064276772, 1127.5070665179958, 1038.3618534702655, 1034.7427378309615, 1013.0698334969015, 959.8697735255821, 961.475725670795, 948.8581210550641, 948.607590936555, 13555.147920899224, 1655.357602605489, 1977.4183588080462, 3041.3977944130793, 11319.886096944536, 11782.883814783007, 2240.482810093754, 5985.152521221156, 10593.378515809334, 2982.1561028422593, 2354.8266231711714, 2837.750906316738, 1625.6461617903158, 8301.056280616744, 8878.98524833853, 3387.1402347880735, 7831.416569529006, 8073.548222158891, 8624.257806851812, 5769.646425715203, 6746.729632779072, 11094.179872440869, 14713.500214590647, 15688.338124998189, 39086.055911919975, 17717.86682965417, 19232.61362959754, 17834.46886238833, 33698.01968895731, 10983.609294802882, 19122.368144007953, 48542.31962434374, 29212.212302221986, 34772.88355677056, 38732.531945089606, 25333.457428498637, 25105.201185439575, 32403.187844949847, 17362.272796756246, 5314.074575358869, 4927.411072757754, 4685.813008178624, 4387.6691538016385, 2970.6840697231933, 2717.1078854838993, 2324.2932175278943, 2296.860067767108, 1937.6149785428024, 2207.4047798792803, 1734.8768092126631, 1666.1606617660143, 1642.0579032984351, 1586.675682605366, 1560.8825409768724, 1446.327325623068, 1371.876263690068, 1374.6150133683125, 1267.9434119602402, 1320.9157426529846, 1218.9815085766204, 1176.5066478860792, 1153.2447835946016, 1146.5644449500603, 1148.15281080985, 1077.1396973274552, 1088.9075700477033, 1004.1157563188598, 982.4815491154147, 5210.5217625207015, 1820.8105743131464, 3598.8651108804615, 1513.5167508032714, 1904.9211422466863, 1397.48049191275, 3715.528662067847, 5473.929919958139, 2581.5889581661722, 9279.187196092646, 2359.1356699013727, 14378.049022955467, 35171.10324073291, 38922.437050340835, 4986.204164984954, 2594.9706971977384, 17115.545067258558, 5968.686377829962, 4802.973934770166, 8323.24073136311, 8296.886462328053, 10652.52378866924, 4817.719113114553, 8808.89768708053, 7702.686989452423, 7916.78377329035, 7092.104760202646, 9753.868926409814, 22726.639097431427, 12493.49515503733, 17623.30661197911, 25318.553376709962, 16064.37676588496, 24413.88169387601, 37685.12350613112, 8207.349625933753, 34772.88355677056, 25109.275684000204, 25333.457428498637, 38732.531945089606, 48542.31962434374, 32403.187844949847, 17459.74256112686, 28853.401292938186, 32300.548599117414, 19122.368144007953, 16294.98435503685, 18322.747704741603, 17210.780629486104, 29212.212302221986, 13063.68250235602, 25105.201185439575, 6093.354246455729, 5830.175745727043, 4898.101512293131, 5075.277403695992, 4196.021363493898, 3683.143540947464, 3701.698273100994, 3226.2794183160618, 3222.5738763291647, 3122.863573916596, 3187.864393815292, 2850.295025411115, 2888.336057049563, 2801.5316625254623, 2547.866579639037, 2560.1200324691067, 2384.5558862304083, 2357.0200171607403, 2131.5865678911578, 2014.302985676953, 1928.853027543334, 1839.6480879286216, 1791.5075884436508, 1769.648618081881, 1759.1370489926592, 1699.4866800114783, 1662.8682560317443, 1646.105057747359, 1643.745970004161, 1642.7242876926632, 3365.2362954630826, 2340.610643762225, 3589.4230884445687, 2922.6737896636987, 3039.4046621269913, 7559.599677460735, 25690.36627762558, 10822.451646870875, 39086.055911919975, 4560.317576084835, 33698.01968895731, 6986.020845907158, 3532.4662385549004, 32300.548599117414, 30769.53232219974, 5425.227645774128, 11618.810487342413, 12108.943654978568, 48542.31962434374, 19118.740605344734, 10071.819631951894, 10692.099462433864, 13505.548814824619, 28853.401292938186, 16465.822831871694, 12086.102080106299, 21866.38618879109, 38732.531945089606, 29212.212302221986, 17834.46886238833, 7219.566300866713, 37685.12350613112, 25105.201185439575, 13564.199516630453, 32403.187844949847, 34772.88355677056, 18532.047339790723, 17004.49026678256, 25318.553376709962, 25109.275684000204, 16943.44337264933, 18322.747704741603, 15890.982288387453], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.19789981842041, -5.293499946594238, -5.380899906158447, -5.41510009765625, -5.291200160980225, -5.54610013961792, -5.757400035858154, -5.776800155639648, -5.836900234222412, -5.856900215148926, -6.212100028991699, -6.327499866485596, -6.379000186920166, -6.372000217437744, -6.378499984741211, -6.47629976272583, -6.616499900817871, -6.832900047302246, -6.8867998123168945, -6.940999984741211, -6.891300201416016, -6.930500030517578, -6.90939998626709, -6.991799831390381, -6.995299816131592, -7.016499996185303, -7.070400238037109, -7.06879997253418, -7.081999778747559, -7.082200050354004, -4.523099899291992, -6.543499946594238, -6.377900123596191, -5.974699974060059, -4.736999988555908, -4.760700225830078, -6.297599792480469, -5.414599895477295, -4.946300029754639, -6.056300163269043, -6.270699977874756, -6.112800121307373, -6.59499979019165, -5.274600028991699, -5.282899856567383, -6.00600004196167, -5.393099784851074, -5.373899936676025, -5.326600074768066, -5.6234002113342285, -5.530200004577637, -5.2291998863220215, -5.073400020599365, -5.098199844360352, -4.606500148773193, -5.1255998611450195, -5.083399772644043, -5.202000141143799, -4.908899784088135, -5.445199966430664, -5.279900074005127, -5.093900203704834, -5.2941999435424805, -5.262199878692627, -5.289299964904785, -5.347300052642822, -5.354599952697754, -5.378399848937988, -4.835400104522705, -6.019400119781494, -6.094900131225586, -6.145199775695801, -6.210899829864502, -6.60099983215332, -6.690199851989746, -6.846399784088135, -6.8582000732421875, -7.028299808502197, -6.8979997634887695, -7.138899803161621, -7.179299831390381, -7.19379997253418, -7.2281999588012695, -7.244500160217285, -7.320799827575684, -7.373600006103516, -7.371600151062012, -7.452400207519531, -7.411499977111816, -7.491799831390381, -7.527299880981445, -7.547299861907959, -7.553100109100342, -7.551700115203857, -7.615499973297119, -7.604700088500977, -7.685800075531006, -7.707499980926514, -6.053299903869629, -7.096099853515625, -6.429500102996826, -7.279300212860107, -7.058599948883057, -7.360300064086914, -6.4232001304626465, -6.051300048828125, -6.776000022888184, -5.569900035858154, -6.865900039672852, -5.168700218200684, -4.341000080108643, -4.263299942016602, -6.177199840545654, -6.781799793243408, -5.059999942779541, -6.0295000076293945, -6.225299835205078, -5.763000011444092, -5.800099849700928, -5.604599952697754, -6.276500225067139, -5.776400089263916, -5.899499893188477, -5.87939977645874, -5.985400199890137, -5.739299774169922, -5.089700222015381, -5.560100078582764, -5.30019998550415, -5.066100120544434, -5.394499778747559, -5.141600131988525, -4.863699913024902, -5.886099815368652, -4.949900150299072, -5.168300151824951, -5.1880998611450195, -4.980199813842773, -4.855100154876709, -5.08459997177124, -5.494500160217285, -5.3292999267578125, -5.304999828338623, -5.530200004577637, -5.607800006866455, -5.587600231170654, -5.621600151062012, -5.5233001708984375, -5.713099956512451, -5.664899826049805, -6.020999908447266, -6.065100193023682, -6.239299774169922, -6.203800201416016, -6.394100189208984, -6.524400234222412, -6.519400119781494, -6.656899929046631, -6.6579999923706055, -6.689499855041504, -6.668900012969971, -6.780799865722656, -6.767499923706055, -6.798099994659424, -6.89300012588501, -6.888199806213379, -6.959199905395508, -6.970799922943115, -7.071400165557861, -7.127999782562256, -7.171299934387207, -7.218699932098389, -7.245200157165527, -7.257500171661377, -7.263400077819824, -7.297900199890137, -7.319699764251709, -7.329899787902832, -7.331299781799316, -7.331900119781494, -6.624599933624268, -6.989500045776367, -6.586900234222412, -6.78249979019165, -6.74560022354126, -5.888599872589111, -4.745999813079834, -5.6244001388549805, -4.504000186920166, -6.4257001876831055, -4.71999979019165, -6.065199851989746, -6.6468000411987305, -4.833399772644043, -4.8846001625061035, -6.3028998374938965, -5.702499866485596, -5.679800033569336, -4.625699996948242, -5.350599765777588, -5.851799964904785, -5.813899993896484, -5.649899959564209, -5.1072001457214355, -5.508800029754639, -5.732800006866455, -5.32480001449585, -4.937099933624268, -5.132400035858154, -5.479400157928467, -6.114799976348877, -5.065299987792969, -5.327199935913086, -5.732600212097168, -5.213699817657471, -5.230199813842773, -5.565899848937988, -5.622799873352051, -5.452499866485596, -5.481599807739258, -5.668300151824951, -5.661099910736084, -5.718699932098389], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.6406, 1.6406, 1.6406, 1.6406, 1.6406, 1.6406, 1.6406, 1.6406, 1.6406, 1.6406, 1.6406, 1.6406, 1.6406, 1.6406, 1.6406, 1.6406, 1.6405, 1.6405, 1.6405, 1.6405, 1.6405, 1.6405, 1.6405, 1.6405, 1.6405, 1.6405, 1.6405, 1.6405, 1.6405, 1.6405, 1.5401, 1.6225, 1.6103, 1.5829, 1.5064, 1.4427, 1.5657, 1.466, 1.3634, 1.521, 1.5428, 1.5141, 1.5891, 1.279, 1.2033, 1.444, 1.2187, 1.2075, 1.1888, 1.2939, 1.2307, 1.0344, 0.9078, 0.8188, 0.3977, 0.6697, 0.6299, 0.5869, 0.2436, 0.8283, 0.4391, -0.3064, 0.0011, -0.1411, -0.276, 0.0905, 0.0922, -0.1867, 0.9803, 0.9802, 0.9802, 0.9802, 0.9802, 0.9802, 0.9802, 0.9802, 0.9802, 0.9802, 0.9802, 0.9802, 0.9802, 0.9802, 0.9802, 0.9802, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9801, 0.9659, 0.9746, 0.9598, 0.9762, 0.967, 0.975, 0.9343, 0.9187, 0.9456, 0.8722, 0.9457, 0.8355, 0.7688, 0.7451, 0.8861, 0.9346, 0.7699, 0.8539, 0.8754, 0.7879, 0.7539, 0.6995, 0.8212, 0.7178, 0.7289, 0.7216, 0.7256, 0.6529, 0.4567, 0.5846, 0.5005, 0.3723, 0.4988, 0.3332, 0.177, 0.6788, 0.1712, 0.2784, 0.2497, 0.0331, -0.0676, 0.1071, 0.3156, -0.0215, -0.1102, 0.1889, 0.2713, 0.1742, 0.2028, -0.228, 0.387, -0.218, 0.8418, 0.8418, 0.8418, 0.8418, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8417, 0.8319, 0.8301, 0.8051, 0.815, 0.8127, 0.7585, 0.6778, 0.6639, 0.5002, 0.7268, 0.4325, 0.6608, 0.7612, 0.3615, 0.3588, 0.676, 0.5148, 0.4962, 0.1618, 0.3687, 0.5084, 0.4865, 0.4169, 0.2005, 0.3598, 0.4451, 0.2602, 0.0762, 0.163, 0.3094, 0.5784, -0.0246, 0.1196, 0.3299, -0.022, -0.1091, 0.1845, 0.2136, -0.0141, -0.0349, 0.1717, 0.1007, 0.1855]}, \"token.table\": {\"Topic\": [1, 2, 3, 1, 3, 3, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 3, 2, 1, 1, 2, 3, 1, 2, 3, 2, 1, 2, 3, 1, 1, 2, 3, 2, 1, 2, 3, 1, 2, 1, 1, 2, 3, 1, 2, 3, 1, 1, 3, 1, 1, 2, 3, 3, 1, 2, 3, 1, 2, 2, 2, 1, 2, 3, 3, 1, 2, 3, 2, 2, 3, 3, 1, 3, 1, 1, 2, 3, 3, 1, 1, 1, 3, 3, 3, 1, 2, 3, 1, 2, 3, 3, 1, 1, 2, 3, 2, 1, 2, 3, 2, 1, 2, 3, 2, 1, 2, 1, 2, 3, 2, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 2, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 1, 1, 2, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 3, 1, 2, 3, 1, 2, 1, 2, 3, 2, 3, 1, 2, 3, 2, 2, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 1, 2, 3, 1, 1, 1, 3, 1, 2, 3, 3, 2, 1, 2, 3, 3, 1, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 3, 3, 3, 1, 2, 3, 1, 2, 3, 2, 2, 1, 3, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 3, 2, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 3, 1, 2, 3, 3, 1, 1, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3], \"Freq\": [0.14270022639227448, 0.3506836947994353, 0.5066300949422847, 0.9998768800407118, 1.0000761968146703, 0.9999949086308082, 1.0000637870715707, 0.0054920594932134775, 0.9946119742209608, 0.07597160466019962, 0.7904438244760573, 0.13359903423504835, 0.8809793680041064, 0.00035239174720164254, 0.11875601880695354, 0.19284424521185137, 0.45959565520510526, 0.34757284569367125, 0.13329205293561872, 0.2673950641579032, 0.5993718973266483, 1.0000531797193222, 0.029482340505665842, 0.26269838977177323, 0.707823922896532, 0.07244201009834386, 0.3045179659152043, 0.6230535915461892, 0.059555018929159584, 0.9402750994735718, 0.00018268410714466132, 0.03593892300277717, 0.9639432061210002, 0.3639650925669056, 0.3126460145149719, 0.3234089822523076, 0.011535451260104088, 0.9882036579489168, 0.9998738465845518, 0.9998506094355429, 0.1586959447049181, 0.22437780099175805, 0.6169089540013835, 0.18110900558382328, 0.30017024205519005, 0.5187847957029322, 1.0000609232729742, 0.13166999437305055, 0.4478690376921296, 0.4204842262868519, 1.0002486242808313, 0.05461976874156976, 0.24438605431801677, 0.7009848745172352, 1.0000901949492145, 0.32664998460055084, 0.6732303407192436, 8.004165268330087e-05, 0.9995502764168372, 0.9995098644693651, 0.9996632028107165, 0.16084837161514987, 0.4176132319064098, 0.42153259936518267, 0.13980733057512257, 0.5144405748569237, 0.3457668392798095, 0.9998723664793898, 1.000135670981637, 0.9998836502945208, 0.9999993283347819, 0.08734578554967952, 0.8250392150889262, 0.08758607656907341, 0.999896493026692, 0.9043796549869564, 0.0002213181307578815, 0.09538811435664693, 0.9999803914387729, 1.0000752516733604, 0.9995077076107267, 1.0000151695684056, 0.6556923583888511, 0.00025538163909984466, 0.34399906786749074, 0.9999133930203083, 0.2248338599324602, 0.7208421656110933, 0.05433741256917643, 0.99988471815313, 0.9995525922805066, 0.9996334763436913, 0.9997668806029592, 0.9497761790300053, 0.04982634099833577, 0.9996515150580155, 0.03242460582298049, 0.11883832122155995, 0.8487617406603717, 0.9998102243381455, 0.9998567418197054, 0.9999453854402552, 0.943973854809097, 0.05589535190440491, 0.9998113641227682, 1.000043686213046, 0.1195475217977936, 0.15931062840008348, 0.7210720933203131, 0.025568366884062343, 0.9549112179437178, 0.019378130691078826, 0.9999361779815543, 0.9995052130198471, 0.04169225511009778, 0.18990060384034574, 0.7684672137901081, 1.0000399059503762, 0.6965378627176847, 0.00024093319360694732, 0.30321442415434324, 0.9998166263464816, 0.07728311654343845, 0.000283088338986954, 0.9225848967584831, 0.9999602940006631, 0.9998965427796757, 1.0000848831937983, 0.6364605654111003, 0.28651740884147, 0.07710808453240693, 0.9995741520382687, 1.0001022626073717, 0.03198494691659917, 0.9553094386295101, 0.01271690660539485, 0.0002645642739473473, 0.07963384645815154, 0.9201545447888738, 0.887277496130443, 0.00033532785190115006, 0.11267015823878643, 0.013123902845928155, 0.9869174940137974, 0.10615732852090694, 0.3672010759644169, 0.5266276875204638, 0.08728583398180886, 0.8652077886324321, 0.047502967816394785, 1.0001678384555475, 0.10409929057808306, 0.7691087171935799, 0.1268036069528013, 0.9999035736650727, 0.9999842879581815, 0.11085307294875256, 0.3556119533798975, 0.5335649500604944, 0.08957948928886506, 0.2928490151531575, 0.6175822553074364, 0.9996721540915445, 0.9999610275988791, 0.11074057678418514, 0.7777805340141304, 0.11151952574163546, 9.240050523017422e-05, 0.16290209072079717, 0.8370561768801483, 0.005009014466040243, 0.9946471582565626, 0.3485946258321842, 0.06420151947528566, 0.5872336362136826, 0.00329011800389947, 0.02533390863002592, 0.9712428347511236, 1.0000216102929134, 1.0001545433421433, 0.1471114774546097, 0.387839349653062, 0.46506125717618196, 0.9660317670900535, 0.03391072460166927, 0.10306296186073083, 0.06241034912677589, 0.834523705066751, 0.24463686274720378, 0.7552200924026302, 0.00018774893533937359, 0.99935949180424, 0.9999531145151069, 0.9998703071404741, 0.10227188868434646, 0.8976001694962293, 0.00010776805973060744, 0.8213418421319258, 0.0005904686140416433, 0.17802628713355545, 0.030649460435359117, 0.544462386728641, 0.4249057929943214, 1.0000818937779958, 0.04532430758900493, 0.3360624036056342, 0.6185963046010298, 0.0010264573523770502, 0.025319281358633906, 0.973423722504236, 0.9999310674401779, 0.6484137898169567, 0.07419290546329649, 0.27744926250047436, 0.28851721507569356, 0.0008442908661432906, 0.7106114790039363, 0.9997136311703985, 0.44384317296380027, 0.07092386292077957, 0.485268535773755, 0.7069757310985255, 0.28320626246996583, 0.009705967379631633, 0.9999647373589452, 0.9996826105549282, 0.19996247455654134, 0.6189530852618482, 0.18106704208567634, 0.16348588878371928, 0.4921146179266685, 0.3443390848218652, 0.545330981610353, 0.45140786048010706, 0.003244944683962431, 0.11687861358681702, 0.36488143355219604, 0.518291358957238, 0.08817458647008186, 0.4956733980156454, 0.4161410361453864, 0.9999946500035527, 0.9066484891039929, 0.0930004773366625, 0.19406267287632972, 0.29871068680875873, 0.5072193727303894, 0.003964277234999619, 0.9956942988574042, 0.4396259148067537, 0.07298414853613644, 0.4873683840238421, 0.9997877435926147, 0.9999220930553776, 0.12220753906117265, 0.7397028610572076, 0.1380470007540465, 0.999985966444804, 1.0000710083774724, 0.7578318841358479, 0.026714801097464495, 0.21541758340782324, 0.9995436713881871, 1.0000792269428307, 0.09044356607830176, 0.8093576082945418, 0.10019589024204192, 0.03753045763456991, 0.24603300004884715, 0.7164544505054403, 0.9997248209854606, 0.999569362496175, 0.018061249309813048, 0.9797533087138587, 0.0022229229919769906, 0.03700997884880014, 0.7720306850643905, 0.19086033460934132, 0.37871376190555617, 0.17677071569123723, 0.44452303856455444, 0.08964735201558856, 0.910111148650427, 0.00020055336021384464, 0.09056386821958405, 0.01798120385957843, 0.8913852888925161, 0.11861906543285457, 0.881265938102846, 0.00016754105287126352, 0.9699515489257101, 0.029836882891875336, 0.22391096207589373, 0.7752282553484029, 0.0009870130570096072, 0.8743904236520249, 0.025883652670240787, 0.09973598588635443, 0.9999695707794257, 0.9999229435331575, 1.000149525984747, 0.9999453421608463, 0.21220948680902588, 0.481616061859547, 0.3061563950317717, 0.9999915074286198, 0.9997697265319577, 0.8203424689525387, 0.08648137552892995, 0.09318601602626604, 0.9996477109220648, 0.10295328315214844, 0.8528932267584233, 0.04400422586341828, 0.9999792751757234, 0.02652559402671237, 0.8103159990230703, 0.16318498704098602, 0.20187762829034134, 0.5923885156218103, 0.20574973624359982, 0.24202619601506942, 0.6178888944561675, 0.14006145602723924, 0.6457945181374154, 0.31974374555146884, 0.03446339772411041, 0.9998410036147473, 0.9999418634726621, 0.9997166696658585, 0.9999698558440245, 0.6637289833349154, 0.00044465988164465076, 0.3358664306022595, 0.0926853710113593, 0.7974075612628779, 0.1099207520966966, 0.9999165742919185, 0.9997736849624085, 0.9822650993602343, 0.018122972312919452, 0.9998669072544949, 0.07678979281234623, 0.44660332237628225, 0.476566077354234, 0.24731423617545734, 0.08858087292821457, 0.6641043066199376, 0.00018432406256333408, 0.15262032380244062, 0.8471533915410834, 0.9998219198841708, 1.0000446297833374, 0.09225472303723861, 0.23522885882947925, 0.6725907117217154, 0.034087533463309616, 0.9660716870169793, 0.08705432346656253, 0.401276166270616, 0.5116433424621224, 0.2125854304284697, 0.3017303045710433, 0.48571608368835667, 0.9279249948420731, 0.07230584375392778, 0.15388785966561014, 0.5235545973505001, 0.3225623888386159, 1.000052365521032, 1.0000046907234479, 0.9998180825406763, 0.9997618269647482, 0.9856978310585445, 0.01420203261260364, 0.30074726920274736, 0.45323884231963335, 0.2459946364683922, 0.10055126367833093, 0.24560275524375824, 0.6538793884707956, 0.4805110882445927, 6.79647932453455e-05, 0.5193869499809303, 0.14003228396147185, 0.3010099585350776, 0.5589858284980634, 0.080366873783268, 0.9004837541778086, 0.019154798932799626, 0.9998474921927377, 0.9998495828685617, 1.0000425382538138, 0.2871319016918477, 0.552524144604574, 0.16036825754316741, 0.16834957015982585, 0.44526074389897224, 0.3863930346203314, 0.8397446818906698, 0.00016708011975540585, 0.1600627547256788, 0.009806146464214021, 0.9901236369321552], \"Term\": [\"a\", \"a\", \"a\", \"achievable\", \"activity\", \"agent\", \"algebra\", \"algebraic\", \"algebraic\", \"algorithm\", \"algorithm\", \"algorithm\", \"allocation\", \"allocation\", \"allocation\", \"also\", \"also\", \"also\", \"analysis\", \"analysis\", \"analysis\", \"antenna\", \"application\", \"application\", \"application\", \"approach\", \"approach\", \"approach\", \"approximation\", \"approximation\", \"approximation\", \"architecture\", \"architecture\", \"at\", \"at\", \"at\", \"attack\", \"attack\", \"automaton\", \"base_station\", \"based\", \"based\", \"based\", \"based_on\", \"based_on\", \"based_on\", \"bayesian\", \"be\", \"be\", \"be\", \"beamforming\", \"been\", \"been\", \"been\", \"boolean\", \"bound\", \"bound\", \"bound\", \"broadcast\", \"c\", \"calculus\", \"can\", \"can\", \"can\", \"can_be\", \"can_be\", \"can_be\", \"capacity\", \"cellular_network\", \"challenge\", \"channel\", \"class\", \"class\", \"class\", \"cloud\", \"code\", \"code\", \"code\", \"coding\", \"color\", \"coloring\", \"combinatorial\", \"communication\", \"communication\", \"communication\", \"community\", \"complexity\", \"complexity\", \"complexity\", \"compressed_sensing\", \"conjecture\", \"consumption\", \"content\", \"cooperative\", \"cooperative\", \"csi\", \"data\", \"data\", \"data\", \"database\", \"decoder\", \"decoding\", \"delay\", \"delay\", \"development\", \"device\", \"different\", \"different\", \"different\", \"dimensional\", \"dimensional\", \"dimensional\", \"document\", \"dof\", \"dynamic\", \"dynamic\", \"dynamic\", \"edge\", \"energy\", \"energy\", \"energy\", \"entropy\", \"environment\", \"environment\", \"environment\", \"equation\", \"equilibrium\", \"equivalence\", \"error\", \"error\", \"error\", \"estimator\", \"fading\", \"family\", \"family\", \"family\", \"feature\", \"feature\", \"feature\", \"feedback\", \"feedback\", \"feedback\", \"formula\", \"formula\", \"from\", \"from\", \"from\", \"function\", \"function\", \"function\", \"fuzzy\", \"given\", \"given\", \"given\", \"gradient\", \"graph\", \"ha\", \"ha\", \"ha\", \"have\", \"have\", \"have\", \"hop\", \"human\", \"if\", \"if\", \"if\", \"image\", \"image\", \"image\", \"inequality\", \"inequality\", \"information\", \"information\", \"information\", \"interaction\", \"interaction\", \"interaction\", \"interference\", \"internet\", \"it\", \"it\", \"it\", \"kernel\", \"kernel\", \"level\", \"level\", \"level\", \"linear\", \"linear\", \"linear\", \"mac\", \"management\", \"manifold\", \"matrix\", \"matrix\", \"matrix\", \"message\", \"message\", \"message\", \"method\", \"method\", \"method\", \"mimo\", \"model\", \"model\", \"model\", \"modeling\", \"modeling\", \"modeling\", \"modulation\", \"multiple\", \"multiple\", \"multiple\", \"network\", \"network\", \"network\", \"neural\", \"node\", \"node\", \"node\", \"noise\", \"noise\", \"noise\", \"norm\", \"np\", \"number\", \"number\", \"number\", \"one\", \"one\", \"one\", \"optimal\", \"optimal\", \"optimal\", \"or\", \"or\", \"or\", \"our\", \"our\", \"our\", \"outage\", \"packet\", \"packet\", \"paper\", \"paper\", \"paper\", \"partition\", \"partition\", \"performance\", \"performance\", \"performance\", \"permutation\", \"platform\", \"point\", \"point\", \"point\", \"polynomial\", \"polynomial_time\", \"power\", \"power\", \"power\", \"precoding\", \"privacy\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"project\", \"projection\", \"proof\", \"proof\", \"proof\", \"property\", \"property\", \"property\", \"proposed\", \"proposed\", \"proposed\", \"prove\", \"prove\", \"prove\", \"quality\", \"quality\", \"quality\", \"quantum\", \"quantum\", \"quantum\", \"radio\", \"radio\", \"random\", \"random\", \"random\", \"rate\", \"rate\", \"rate\", \"receiver\", \"relay\", \"relaying\", \"research\", \"result\", \"result\", \"result\", \"routing\", \"sampling\", \"scheme\", \"scheme\", \"scheme\", \"semantic\", \"sequence\", \"sequence\", \"sequence\", \"service\", \"set\", \"set\", \"set\", \"show\", \"show\", \"show\", \"show_that\", \"show_that\", \"show_that\", \"signal\", \"signal\", \"signal\", \"snr\", \"social\", \"social_network\", \"software\", \"source\", \"source\", \"source\", \"space\", \"space\", \"space\", \"sparse\", \"sparsity\", \"station\", \"station\", \"string\", \"such\", \"such\", \"such\", \"system\", \"system\", \"system\", \"task\", \"task\", \"task\", \"technology\", \"tensor\", \"their\", \"their\", \"their\", \"theorem\", \"theorem\", \"these\", \"these\", \"these\", \"this_paper\", \"this_paper\", \"this_paper\", \"throughput\", \"throughput\", \"time\", \"time\", \"time\", \"traffic\", \"transmission\", \"transmit\", \"transmitter\", \"tree\", \"tree\", \"two\", \"two\", \"two\", \"used\", \"used\", \"used\", \"user\", \"user\", \"user\", \"using\", \"using\", \"using\", \"variable\", \"variable\", \"variable\", \"vertex\", \"video\", \"web\", \"where\", \"where\", \"where\", \"which\", \"which\", \"which\", \"wireless\", \"wireless\", \"wireless\", \"world\", \"world\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el581402029456411681159948789\", ldavis_el581402029456411681159948789_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el581402029456411681159948789\", ldavis_el581402029456411681159948789_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el581402029456411681159948789\", ldavis_el581402029456411681159948789_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 202,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics = model_3.top_topics(corpus_2) #, num_words=20)\n",
    "model_3.num_topics\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / NUM_TOPICS\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "lda_display = pyLDAvis.gensim.prepare(model_3, corpus_2, dictionary_2, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUDsa-NYV_di"
   },
   "source": [
    "Different from Model 1, in this case, we did not remove the stop words, that is why we could see some words like `a` in topic 1. These stopwords could add some noise to the model as they can appear in any document of any topic. \n",
    "\n",
    "Even though we can observe again 3 different topics pretty far from each other without overlapping. Meaning that they are pretty different from each other. And in this case, topic 1 is approximately half of the size of topics 2 and 3. Meaning that it has half of the documents than the other 2 topics, this one is less important to this corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YsGu1RBlWACo",
    "outputId": "be9056e4-b118-42e5-c19f-34134248b3c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.015*\"channel\" + 0.011*\"code\" + 0.010*\"network\" + 0.009*\"rate\" + 0.009*\"scheme\"\n",
      "1: 0.014*\"algorithm\" + 0.013*\"problem\" + 0.008*\"graph\" + 0.008*\"a\" + 0.008*\"be\"\n",
      "2: 0.011*\"network\" + 0.010*\"a\" + 0.009*\"system\" + 0.009*\"data\" + 0.008*\"model\"\n"
     ]
    }
   ],
   "source": [
    "for i,topic in model_3.show_topics(formatted=True, num_topics=3, num_words=5):\n",
    "    print(str(i)+\": \"+ topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MykfJZX9EyJV"
   },
   "source": [
    "**Model 4:**\n",
    "   - *Preprocessing:* Method #2\n",
    "   - *Number of topics:* 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 877
    },
    "id": "dFTkgTQMjwqF",
    "outputId": "f2c4623e-1d88-466d-d29b-d3884b3f07fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average topic coherence: -2.4898.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el581402029456414248214264015\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el581402029456414248214264015_data = {\"mdsDat\": {\"x\": [0.01813188767820709, -0.036820386993798304, 0.04776268528199585, -0.1899737800253198, 0.16085884661854524, 0.16026455371773624, -0.20157071156942888, 0.16817000636548496, -0.008322906200085523, -0.13411604988973522, -0.04759410750898005, 0.1312748401935251, -0.2209342661666784, -0.20081151905155908, 0.20737782841752186, 0.027115222925434185, -0.07216523007991626, 0.05771840540036148, 0.06133548751023289, 0.07229919337645652], \"y\": [-0.03007005488197406, 0.0037352283899651376, 0.11575142915177077, -0.05767350729195783, 0.06721638313021419, 0.08047253903753668, 0.05073521823886757, -0.12376162288631025, 0.19480874444429497, 0.03351727668732654, 0.150935622382729, 0.035764989641004094, 0.11602909348366768, -0.2179489075889061, -0.08046265483662016, -0.08366203841491127, -0.14875529742011687, 0.1278221819022477, 0.018749636706998182, -0.2532042598758245], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [2.1012933245361785, 2.6880338717209, 17.373734005307757, 3.285775359654074, 2.815114460748854, 3.595064930562677, 4.858634996422168, 2.572505787995139, 3.9365373681763014, 15.643737172906752, 4.169868011414437, 5.732387284482572, 3.1615448285530827, 1.6649627305525119, 3.7374434595592936, 4.6490204669274595, 2.1972521970242327, 3.2225154464180417, 10.958871088730048, 1.635703208307535]}, \"tinfo\": {\"Term\": [\"network\", \"data\", \"graph\", \"code\", \"algorithm\", \"model\", \"bound\", \"channel\", \"ha\", \"system\", \"been\", \"have\", \"method\", \"problem\", \"image\", \"time\", \"user\", \"be\", \"function\", \"node\", \"matrix\", \"signal\", \"based\", \"quantum\", \"information\", \"set\", \"scheme\", \"approach\", \"error\", \"ha_been\", \"quantum\", \"security\", \"attack\", \"secure\", \"secret\", \"downlink\", \"authentication\", \"uplink\", \"ring\", \"information_theoretic\", \"eavesdropper\", \"centralized\", \"adversary\", \"cryptography\", \"trust\", \"feature_selection\", \"cryptographic\", \"observer\", \"constellation\", \"model_checking\", \"entanglement\", \"clock\", \"register\", \"synchronous\", \"nonparametric\", \"well_studied\", \"multiplex\", \"causality\", \"arxiv\", \"reconstructed\", \"copy\", \"asynchronous\", \"signature\", \"causal\", \"jointly\", \"trace\", \"synchronization\", \"key\", \"round\", \"privacy\", \"protocol\", \"message\", \"communication\", \"classical\", \"scheme\", \"broadcast\", \"identity\", \"party\", \"information\", \"private\", \"state\", \"against\", \"bit\", \"two\", \"computation\", \"group\", \"game\", \"spectrum\", \"player\", \"equilibrium\", \"transmit\", \"cognitive\", \"achievable\", \"compression\", \"correlated\", \"distortion\", \"hop\", \"localization\", \"stationary\", \"auction\", \"secondary\", \"nash\", \"duplex\", \"payoff\", \"side_information\", \"nash_equilibrium\", \"trade\", \"achievable_rate\", \"cognitive_radio\", \"trade_off\", \"forest\", \"patient\", \"white\", \"gaussian_noise\", \"piecewise\", \"rayleigh\", \"source_coding\", \"cooperative\", \"forward\", \"source\", \"strategy\", \"gain\", \"gaussian\", \"side\", \"radio\", \"transmission\", \"rate\", \"coding\", \"information\", \"primary\", \"two\", \"optimal\", \"at\", \"where\", \"between\", \"software\", \"development\", \"project\", \"transmitter\", \"server\", \"robot\", \"review\", \"engineering\", \"interface\", \"will_be\", \"aspect\", \"library\", \"file\", \"integration\", \"team\", \"building\", \"client\", \"qos\", \"overview\", \"plan\", \"medical\", \"developer\", \"university\", \"software_development\", \"popularity\", \"today\", \"paradigm\", \"instruction\", \"2014\", \"methodology\", \"tool\", \"will\", \"survey\", \"could_be\", \"should_be\", \"working\", \"computer\", \"oriented\", \"system\", \"application\", \"article\", \"architecture\", \"concept\", \"towards\", \"issue\", \"such_a\", \"platform\", \"implementation\", \"a\", \"discus\", \"it\", \"process\", \"such\", \"how\", \"paper\", \"be\", \"use\", \"research\", \"these\", \"computing\", \"design\", \"used\", \"their\", \"different\", \"this_paper\", \"or\", \"can\", \"work\", \"new\", \"which\", \"have\", \"present\", \"analysis\", \"model\", \"from\", \"based\", \"approach\", \"graph\", \"vertex\", \"np\", \"at_most\", \"motion\", \"tensor\", \"plane\", \"planar\", \"np_hard\", \"pixel\", \"shortest\", \"factorization\", \"clique\", \"intersection\", \"euclidean\", \"subgraph\", \"np_complete\", \"disjoint\", \"cancellation\", \"coding_scheme\", \"alpha\", \"undirected\", \"fixed_point\", \"shortest_path\", \"hull\", \"scalar\", \"polygon\", \"software_engineering\", \"covering\", \"planar_graph\", \"curve\", \"width\", \"edge\", \"directed\", \"there_exists\", \"path\", \"distance\", \"reconstruction\", \"partition\", \"conjecture\", \"cycle\", \"polynomial_time\", \"point\", \"polynomial\", \"set\", \"every\", \"connected\", \"degree\", \"maximum\", \"minimum\", \"problem\", \"complete\", \"if\", \"at\", \"two\", \"most\", \"such\", \"number\", \"image\", \"recognition\", \"database\", \"segmentation\", \"mining\", \"vehicle\", \"manifold\", \"dataset\", \"peer\", \"volume\", \"secrecy\", \"journal\", \"scene\", \"aggregation\", \"big_data\", \"road\", \"data_mining\", \"broadcast_channel\", \"analytics\", \"navigation\", \"face_recognition\", \"registration\", \"password\", \"bounding\", \"cancer\", \"histogram\", \"session\", \"object_oriented\", \"salient\", \"card\", \"object\", \"face\", \"data\", \"extraction\", \"classification\", \"feature\", \"pattern\", \"classifier\", \"attribute\", \"extracted\", \"unsupervised\", \"retrieval\", \"query\", \"detection\", \"map\", \"similarity\", \"spatial\", \"from\", \"using\", \"region\", \"processing\", \"human\", \"technique\", \"method\", \"information\", \"set\", \"used\", \"agent\", \"web\", \"market\", \"business\", \"student\", \"publication\", \"cellular_network\", \"twitter\", \"indicator\", \"country\", \"recommendation\", \"customer\", \"page\", \"provider\", \"social_medium\", \"collaborative\", \"collective\", \"cloud_computing\", \"urban\", \"economic\", \"intensity\", \"financial\", \"collaboration\", \"consumer\", \"reward\", \"company\", \"affine\", \"google\", \"adoption\", \"community_structure\", \"preference\", \"decision_making\", \"people\", \"risk\", \"content\", \"ranking\", \"service\", \"user\", \"online\", \"internet\", \"mechanism\", \"activity\", \"social\", \"impact\", \"information\", \"medium\", \"organization\", \"their\", \"decision\", \"who\", \"research\", \"technology\", \"individual\", \"study\", \"group\", \"human\", \"from\", \"factor\", \"matrix\", \"convex\", \"equation\", \"rank\", \"dimensional\", \"differential\", \"transform\", \"invariant\", \"inverse\", \"sufficient_condition\", \"trajectory\", \"wavelet\", \"pca\", \"eigenvalue\", \"smooth\", \"rational\", \"integral\", \"packing\", \"singular\", \"principal\", \"symmetry\", \"outlier\", \"triangle\", \"multivariate\", \"computable\", \"bin\", \"splitting\", \"sphere\", \"derivative\", \"multiplication\", \"inequality\", \"dimension\", \"quasi\", \"projection\", \"algebraic\", \"vector\", \"decomposition\", \"function\", \"stability\", \"linear\", \"shape\", \"algebra\", \"condition\", \"spectral\", \"space\", \"group\", \"discrete\", \"sufficient\", \"non\", \"polynomial\", \"property\", \"form\", \"finite\", \"solution\", \"point\", \"problem\", \"which\", \"result\", \"a\", \"sensor\", \"sensing\", \"antenna\", \"recovery\", \"filter\", \"compressed\", \"controller\", \"alignment\", \"compressed_sensing\", \"c\", \"beamforming\", \"compressive\", \"optical\", \"brain\", \"patch\", \"encryption\", \"resource_allocation\", \"tracking\", \"rf\", \"hash\", \"compressive_sensing\", \"signal_processing\", \"pursuit\", \"transceiver\", \"pulse\", \"buyer\", \"gesture\", \"android\", \"impairment\", \"music\", \"measurement\", \"frequency\", \"signal\", \"collision\", \"band\", \"frame\", \"full_duplex\", \"sparse\", \"dictionary\", \"noise\", \"estimation\", \"control\", \"nonlinear\", \"detection\", \"system\", \"design\", \"sampling\", \"low\", \"proposed\", \"error\", \"performance\", \"using\", \"from\", \"this_paper\", \"relay\", \"semantic\", \"reasoning\", \"decoder\", \"closed_form\", \"mac\", \"ontology\", \"spreading\", \"repair\", \"time_varying\", \"lambda\", \"speech\", \"corpus\", \"grammar\", \"termination\", \"annotation\", \"sentence\", \"voltage\", \"natural_language\", \"d2d\", \"schema\", \"english\", \"linguistic\", \"syntax\", \"thread\", \"matlab\", \"python\", \"atom\", \"parsing\", \"fpga\", \"program\", \"character\", \"text\", \"word\", \"language\", \"document\", \"translation\", \"specification\", \"programming\", \"rule\", \"massive\", \"temporal\", \"semantics\", \"representation\", \"knowledge\", \"verification\", \"automatic\", \"domain\", \"form\", \"based\", \"natural\", \"from\", \"logic\", \"model\", \"type\", \"using\", \"approach\", \"structure\", \"which\", \"tree\", \"kernel\", \"bayesian\", \"additive\", \"worst\", \"worst_case\", \"spanning\", \"nearest\", \"lp\", \"walk\", \"running_time\", \"column\", \"bayesian_network\", \"sat\", \"posterior\", \"random_variable\", \"epsilon\", \"fourier\", \"nearest_neighbor\", \"embedding\", \"high_probability\", \"row\", \"boolean_function\", \"bayes\", \"spanning_tree\", \"box\", \"mixing\", \"uniformly\", \"logarithmic\", \"sorting\", \"probability_distribution\", \"cite\", \"let_be\", \"relaxation\", \"even_when\", \"number\", \"sequence\", \"doe_not\", \"any\", \"doe\", \"instance\", \"where\", \"if\", \"show_that\", \"consider\", \"almost\", \"show\", \"given\", \"size\", \"can_be\", \"even\", \"we_consider\", \"be\", \"all\", \"case\", \"when\", \"only\", \"can\", \"time\", \"known\", \"not\", \"problem\", \"one\", \"than\", \"set\", \"each\", \"which\", \"it\", \"or\", \"our\", \"result\", \"algorithm\", \"a\", \"also\", \"from\", \"such\", \"stochastic\", \"uncertainty\", \"entropy\", \"regression\", \"chain\", \"fuzzy\", \"gradient\", \"sparsity\", \"latent\", \"modulation\", \"divergence\", \"conditional\", \"imaging\", \"markov_chain\", \"time_series\", \"outer\", \"descent\", \"monte\", \"carlo\", \"monte_carlo\", \"wave\", \"fractional\", \"molecular\", \"lasso\", \"mutual_information\", \"graphical_model\", \"pilot\", \"artifact\", \"svm\", \"labeling\", \"markov\", \"distribution\", \"prediction\", \"inference\", \"probabilistic\", \"measure\", \"statistical\", \"sample\", \"probability\", \"model\", \"hidden\", \"variable\", \"statistic\", \"estimate\", \"estimation\", \"norm\", \"parameter\", \"process\", \"information\", \"observation\", \"decision\", \"mean\", \"random\", \"between\", \"state\", \"a\", \"from\", \"data\", \"processor\", \"evolutionary\", \"big\", \"spread\", \"switching\", \"genetic\", \"cache\", \"force\", \"neuron\", \"predicting\", \"temperature\", \"disease\", \"epidemic\", \"dimensionality\", \"transaction\", \"gpu\", \"perturbation\", \"uncertain\", \"genetic_algorithm\", \"coupling\", \"gene\", \"variability\", \"friend\", \"reaction\", \"plant\", \"calibration\", \"tuning\", \"spin\", \"scheduler\", \"phase_transition\", \"window\", \"core\", \"switch\", \"memory\", \"population\", \"dynamic\", \"parallel\", \"visual\", \"speed\", \"video\", \"event\", \"physic\", \"real_time\", \"effect\", \"flow\", \"simulation\", \"time\", \"phase\", \"change\", \"high\", \"model\", \"long\", \"level\", \"cell\", \"real\", \"correlation\", \"response\", \"at\", \"scale\", \"state\", \"using\", \"large\", \"behavior\", \"study\", \"result\", \"from\", \"performance\", \"between\", \"analysis\", \"system\", \"cloud\", \"automaton\", \"calculus\", \"diagram\", \"equivalence\", \"visualization\", \"particle\", \"hardness\", \"randomness\", \"turing\", \"fractal\", \"modal\", \"dynamical_system\", \"beta\", \"closure\", \"cellular_automaton\", \"reachability\", \"reverse\", \"quantifier\", \"oscillator\", \"join\", \"rewriting\", \"finite_automaton\", \"turing_machine\", \"recursion\", \"controllability\", \"curvature\", \"branching\", \"rough\", \"csp\", \"propositional\", \"logic\", \"proof\", \"first_order\", \"notion\", \"formula\", \"completeness\", \"theorem\", \"boolean\", \"relation\", \"theory\", \"definition\", \"finite\", \"infinite\", \"property\", \"class\", \"operator\", \"complexity\", \"order\", \"semantics\", \"state\", \"regular\", \"complete\", \"type\", \"set\", \"language\", \"prove\", \"system\", \"model\", \"first\", \"a\", \"bound\", \"lower_bound\", \"upper\", \"al\", \"et\", \"upper_bound\", \"et_al\", \"color\", \"tight\", \"coloring\", \"consensus\", \"min\", \"regret\", \"delta\", \"error_probability\", \"workflow\", \"omega\", \"best_known\", \"bandit\", \"health\", \"minimax\", \"ml\", \"semidefinite\", \"chromatic\", \"gap_between\", \"approximation_ratio\", \"maximum_degree\", \"steiner\", \"phi\", \"nuclear\", \"lower\", \"max\", \"log\", \"optimum\", \"gap\", \"constant\", \"approximation\", \"bounded\", \"complexity\", \"ratio\", \"known\", \"prove\", \"noisy\", \"new\", \"result\", \"best\", \"maximum\", \"wireless\", \"mobile\", \"allocation\", \"routing\", \"scheduling\", \"packet\", \"station\", \"wireless_sensor\", \"ad\", \"mobility\", \"job\", \"hoc\", \"energy_consumption\", \"energy_efficiency\", \"energy_efficient\", \"congestion\", \"multiple_output\", \"power_consumption\", \"streaming\", \"routing_protocol\", \"tcp\", \"decentralized\", \"balancing\", \"ad_hoc\", \"mobile_device\", \"energy_harvesting\", \"lte\", \"lifetime\", \"slot\", \"ip\", \"bandwidth\", \"traffic\", \"load\", \"delay\", \"throughput\", \"smart\", \"grid\", \"fault\", \"resource\", \"distributed\", \"protocol\", \"transmission\", \"device\", \"network\", \"node\", \"power\", \"communication\", \"storage\", \"access\", \"performance\", \"layer\", \"control\", \"efficiency\", \"data\", \"simulation\", \"service\", \"time\", \"channel\", \"interference\", \"mimo\", \"receiver\", \"fading\", \"snr\", \"outage\", \"precoding\", \"csi\", \"dof\", \"ofdm\", \"multiple_input\", \"interference_channel\", \"multiple_access\", \"convolutional\", \"multiuser\", \"quantization\", \"power_allocation\", \"csit\", \"harvesting\", \"simulator\", \"fading_channel\", \"outage_probability\", \"capacity_region\", \"bs\", \"sum_rate\", \"interference_alignment\", \"transmit_power\", \"massive_mimo\", \"outer_bound\", \"capacity\", \"coded\", \"buffer\", \"freedom\", \"feedback\", \"relaying\", \"diversity\", \"rate\", \"user\", \"scheme\", \"multiple\", \"region\", \"power\", \"sum\", \"at\", \"noise\", \"output\", \"input\", \"joint\", \"information\", \"system\", \"two\", \"optimal\", \"performance\", \"communication\", \"state\", \"proposed\", \"result\", \"shown\", \"a\", \"single\", \"paper\", \"multi\", \"it\", \"code\", \"lattice\", \"subspace\", \"cyclic\", \"high_dimensional\", \"erasure\", \"ldpc\", \"parity\", \"polar\", \"sc\", \"finite_field\", \"ldpc_code\", \"spatially\", \"correction\", \"message_passing\", \"error_rate\", \"support_vector\", \"polar_code\", \"belief_propagation\", \"parity_check\", \"convergence_rate\", \"md\", \"correcting\", \"error_correction\", \"low_dimensional\", \"low_density\", \"thermal\", \"ber\", \"dirichlet\", \"hamming\", \"decoding\", \"passing\", \"block\", \"error\", \"binary\", \"check\", \"coding\", \"construction\", \"length\", \"symbol\", \"over\", \"low\", \"bit\", \"weight\", \"rate\", \"complexity\", \"linear\", \"density\", \"encoding\", \"finite\", \"field\", \"new\", \"this_paper\", \"paper\", \"topology\", \"social_network\", \"neural\", \"neural_network\", \"opinion\", \"queue\", \"centrality\", \"scale_free\", \"cascade\", \"power_law\", \"leader\", \"online_social\", \"dilemma\", \"forwarding\", \"tie\", \"migration\", \"voting\", \"suboptimal\", \"instantaneous\", \"switched\", \"infection\", \"election\", \"attachment\", \"similarity_measure\", \"router\", \"interconnected\", \"electricity\", \"hashing\", \"rounding\", \"er\", \"biological\", \"network\", \"cellular\", \"community\", \"cooperation\", \"node\", \"poisson\", \"social\", \"link\", \"connectivity\", \"degree_distribution\", \"law\", \"degree\", \"structure\", \"influence\", \"complex\", \"scale\", \"interaction\", \"world\", \"connected\", \"layer\", \"individual\", \"real_world\", \"model\", \"between\", \"distribution\", \"real\", \"property\", \"a\", \"different\", \"study\", \"dynamic\", \"large\", \"learning\", \"consumption\", \"optimization_problem\", \"heuristic\", \"3d\", \"citation\", \"machine_learning\", \"regularization\", \"mixture\", \"descriptor\", \"soft\", \"supervised\", \"least_square\", \"objective_function\", \"variational\", \"ieee\", \"blind\", \"overlapping\", \"maximum_likelihood\", \"image_processing\", \"802\", \"interpolation\", \"cpu\", \"penalty\", \"modularity\", \"learner\", \"radius\", \"radar\", \"alternating\", \"deep\", \"benchmark\", \"optimization\", \"energy\", \"method\", \"art\", \"estimator\", \"we_propose\", \"propose\", \"selection\", \"algorithm\", \"effectiveness\", \"low_rank\", \"clustering\", \"novel\", \"proposed\", \"approach\", \"efficient\", \"search\", \"based\", \"based_on\", \"local\", \"demonstrate\", \"technique\", \"task\", \"performance\", \"problem\", \"computational\", \"our\", \"solution\", \"existing\", \"experiment\", \"using\", \"this_paper\", \"result\", \"paper\", \"new\", \"multi\", \"which\", \"show\", \"a\", \"present\", \"been\", \"ha_been\", \"have_been\", \"circuit\", \"testing\", \"gate\", \"texture\", \"artificial\", \"discriminative\", \"recent_year\", \"layout\", \"artificial_intelligence\", \"cr\", \"payment\", \"bp\", \"board\", \"ca\", \"non_uniform\", \"merging\", \"homology\", \"sketch\", \"db\", \"codebook\", \"latent_variable\", \"data_stream\", \"electric\", \"consuming\", \"email\", \"dominated\", \"relational_database\", \"belief\", \"frequent\", \"super\", \"test\", \"relational\", \"ha\", \"intelligence\", \"year\", \"have\", \"stream\", \"embedded\", \"recent\", \"decade\", \"recently\", \"paper\", \"this_paper\", \"last\", \"proposed\", \"studied\", \"wa\", \"however\", \"shown\"], \"Freq\": [37204.0, 24016.0, 17305.0, 14513.0, 36688.0, 32335.0, 12651.0, 16847.0, 17422.0, 33752.0, 11202.0, 16889.0, 23396.0, 34317.0, 9972.0, 24485.0, 14484.0, 38410.0, 14124.0, 10301.0, 9012.0, 7994.0, 29583.0, 6492.0, 17728.0, 17423.0, 11474.0, 18413.0, 8771.0, 5443.0, 6492.6910765801595, 3381.2608251073357, 2627.714048821675, 1544.108378262598, 1061.6304262725564, 908.7147915093672, 733.9819712464023, 682.4914572543237, 664.1963664355962, 623.749846797413, 610.924513387133, 560.12631170079, 524.4352354734021, 488.13250081090416, 474.74740673880314, 459.8772269619608, 453.8033635126492, 436.8853734107481, 430.04820514979, 441.38890884894363, 427.3622602603592, 397.49279751447204, 376.98092223678566, 376.8234904412611, 361.15925478337124, 359.3172400766114, 326.0231512848485, 326.56735116456287, 317.2228735127888, 300.50936804754394, 302.71324218728273, 596.1076278640254, 840.22648853279, 1041.042086565581, 683.5136809403982, 782.2686171013911, 719.7863770235184, 2520.0690041464986, 781.5011228484082, 1132.3768096298368, 2471.3187267836183, 1725.6623500107999, 2464.899020677049, 1533.139109862335, 2758.9298594417087, 733.0714089967623, 629.5645633754891, 596.3707361797899, 1921.0673558066694, 636.6031668158042, 1343.9545409633483, 754.9259289737535, 692.9019054795964, 762.131882070716, 671.5765660926307, 664.856702189091, 5871.848945498192, 2373.497017805883, 2258.571324540118, 2204.0842845471466, 1865.4015855833577, 1550.886123117626, 1866.2646074247275, 1533.4995433546442, 1252.0101972145367, 1229.7355422401863, 1122.6230549064924, 980.2328363044991, 895.1295933754876, 848.6938996773715, 817.3474530997871, 786.1280244376866, 759.7408181033373, 749.9427202681089, 683.2815745214501, 671.9657511346743, 1171.4436521520506, 641.0176391565664, 607.6480203051993, 682.4497602965137, 532.8356711825975, 522.5857556015048, 530.614133673985, 453.0489519559894, 428.4727352696721, 375.8479077063786, 377.0959207037499, 1404.8153744812607, 1605.0809198239963, 4827.932009641803, 4249.126097610396, 2071.6829093985825, 2667.7122174416218, 1251.632935047652, 1273.7534477296183, 1991.7306002258988, 2807.4473824520464, 1920.7515015877154, 2240.6899436436843, 831.2126762552059, 1944.243107772987, 1608.340803271442, 1087.9628407026205, 1029.5173187270425, 982.0364615383725, 6035.117180256953, 3831.716040549782, 2206.349677580565, 1857.9997096463176, 1580.3718823826318, 1545.6797293244306, 1550.0091056808496, 1502.6798063043238, 1414.4518854729429, 1375.2048505244907, 1770.020740326424, 1009.2125502279031, 968.7726569841109, 1114.0798104177, 858.7498148182523, 1564.586141557451, 734.7144664337628, 708.9088690924038, 662.1886938589871, 662.1267210738275, 621.6888896622411, 593.4982237346096, 597.0653112697684, 574.5665982391859, 601.059433709511, 626.971068135744, 1033.2562235850987, 538.5615293417707, 524.8056328685346, 1685.8278840314454, 4557.901826428152, 4708.376932831038, 1412.9017411110694, 862.3738089222934, 1086.7125813636062, 643.9278707443741, 3216.26996644051, 1118.9392543795054, 24284.658420315307, 9543.937101639523, 2136.7167734096247, 3164.9649832951113, 3237.4048069216474, 1568.3164083843324, 2354.3131188997377, 5182.324528866918, 1619.5654275127145, 3255.577206889374, 23305.365883050345, 2276.071888540766, 17628.37034155572, 6056.323654679873, 9403.926677323861, 4841.576948642198, 12527.541674639504, 15275.005901108654, 5943.250891405582, 3585.468239088769, 8242.051475632123, 3435.418694853177, 5002.639268874829, 6693.675341058332, 6137.163971808087, 5846.958378993606, 9037.486075796223, 7491.348501903104, 10051.592708766992, 5115.207766901052, 6032.4629542035755, 8862.746385442655, 6242.566719276497, 5277.884678479364, 5284.631936008875, 7016.006871658082, 6220.762666970822, 6119.615069899419, 5132.831601683031, 17305.190999311642, 4373.040662483108, 1931.012611342986, 1574.9619950902195, 1370.5769962670233, 1263.5529816978994, 1028.5873119751507, 984.8279098420728, 840.0817479862068, 810.740953255418, 713.9399677051301, 699.7609395668505, 701.855921189077, 648.8194627003196, 691.3565916797536, 571.4621437469737, 565.420298747328, 560.2407786655739, 554.966558818935, 555.0197243810562, 621.2918230914603, 526.3379063200794, 531.6985814814835, 494.46566432128486, 471.9808651805789, 465.6108910661821, 461.3183846880824, 425.5710728748001, 676.1221847970033, 401.21447160482904, 1397.4543493021426, 725.6221307013102, 4316.208681982365, 1264.9270864275256, 674.8923356621686, 2765.507652540732, 2983.594838333141, 1382.3545274970168, 1135.0785122435868, 1080.8884992070455, 1094.4253515279186, 1202.1582996781183, 3122.0165710909455, 2166.5477274637096, 3917.8603823203885, 1377.0122129488514, 1164.4211786873757, 1776.8244595644578, 1559.8800882523801, 1413.5532202033557, 3539.4146308925388, 1294.568959563755, 1673.6522520911064, 2072.1522496352795, 1461.617473107415, 1225.4357247097607, 1308.420348797831, 1133.1300590105093, 9972.064221140996, 2761.690326076398, 2590.917677760668, 1365.3205850880888, 1124.3834909994534, 1076.7061713480243, 974.2593209420073, 1390.752235738376, 819.6427655622085, 778.7677099279454, 768.4766119721826, 709.0131761796938, 692.0859018844146, 609.8857502810713, 563.3103364634269, 527.074166937526, 481.2946376349628, 457.3641141420242, 387.7394342309418, 361.30259041066, 356.9683511022897, 354.77687192204934, 311.5779060477924, 309.8736937508077, 305.78803233331945, 306.06835778833147, 331.2870725815493, 297.3498046913064, 287.99141313404016, 275.47895930659774, 4111.132318283994, 1565.365747507169, 16781.673666301554, 886.1638967657655, 2608.7683995436782, 4699.529568468628, 2842.705069834228, 1169.1976881746577, 947.7449313577472, 594.3493743786868, 451.4287896211132, 821.5872513661927, 2095.662091753245, 2098.431136059877, 1190.030962837499, 1009.9285396804562, 1073.9313998800942, 3227.635980526655, 2464.7319728598272, 1209.062090745155, 1167.3161247828036, 1030.38473804342, 1217.4151173175876, 1131.332293983704, 1099.4764483240867, 1088.421881586191, 982.8900002941795, 4143.25388354993, 3147.7087005534477, 1169.376440816092, 1116.0330126976198, 955.1246680891547, 863.5712836835338, 843.1525795627344, 769.3861077320299, 769.8228461642018, 666.4026295681358, 664.3800874037406, 664.859392839517, 659.7495970666156, 613.1151773032007, 592.1697735570446, 568.9063941128851, 568.8314508316249, 640.1599499472919, 533.5685159624137, 516.6900895400289, 496.4961177441017, 495.13621656365376, 490.83334099997546, 475.3547009916566, 471.5947131921628, 507.82162247289983, 453.10507936186406, 436.1010973446548, 436.38726658194594, 429.26126737370845, 967.877703361516, 753.2831516708443, 1181.7272105904722, 1330.7171842652963, 1992.8630647135221, 962.5856447484383, 3536.1226127568802, 7339.374481013872, 2260.8413198319186, 1214.2280198924545, 2446.013149051706, 1326.016772870704, 2378.093569664567, 1530.3293209140677, 3378.0085749554823, 985.9430811799439, 822.2253143335782, 2072.42991246839, 1275.4141136784767, 791.0167768489288, 1324.7735043049433, 1103.1869443864528, 1055.7014771076724, 1462.3766826169133, 1076.258170484143, 1013.7862898882099, 1399.2957964367638, 900.561180905169, 9012.201651184974, 3346.2022911576705, 2663.864861285923, 3005.182108308919, 3633.3307626657106, 1296.138438148259, 1318.9210461698972, 1208.77007210155, 944.2525466422319, 886.803379789855, 792.0617201494484, 719.8259006664771, 664.9970665169968, 669.7815921237392, 671.3214099053654, 657.5382384738382, 652.1309192755286, 615.7645444788103, 634.2175146476568, 671.4916880389608, 634.2594252099503, 532.0738302733638, 523.129714307538, 504.16554730379767, 505.0641203029098, 493.98767268617684, 496.43153292708877, 466.7138470967407, 456.3618393645589, 474.63972091074174, 1363.46815185557, 2759.314717173136, 827.0567101790411, 1130.8931304721284, 1718.7487330102674, 3262.7327935522544, 1731.6450611283558, 9694.41071348542, 1717.454250171124, 6982.417238556817, 1700.1457151207564, 1151.195239459403, 3530.4063293259233, 1413.6727880682142, 4077.400583364246, 2595.107552576209, 1610.1058802133841, 1249.6076976415775, 3000.7641024309137, 1936.107716190937, 2183.461350757489, 1665.7302901782268, 1718.194142928093, 1844.2936674798027, 1693.4032545661098, 1781.094516454389, 1633.4901288541112, 1564.9135100214553, 1614.1082071182007, 4337.807545460253, 3033.4935794982057, 2747.4517742794533, 2138.335418810087, 1952.3069649794202, 1464.9187548675814, 1312.3438285888258, 1196.5844882372442, 938.8500561702269, 918.6196479575018, 880.064905100343, 814.6093688064794, 792.7771330718748, 752.5498743338882, 682.8857638874622, 669.6029816194497, 601.1088926088482, 1331.8468375382938, 520.9665064552607, 478.7021250491745, 472.6393596529781, 467.09663867441645, 311.21540920183963, 298.0491266527458, 285.8389338154425, 269.871633765663, 270.3194197472748, 264.1724458839894, 265.71506405486406, 260.557954005769, 3777.8237165511205, 3059.555184183958, 6749.4088081006885, 496.31577302854237, 816.810686645957, 1134.0651356348692, 382.858584355215, 3043.7296446486935, 885.3607401816096, 3169.911645088402, 2401.392830846457, 3056.5197018401655, 1130.2177489906164, 2180.6549273667847, 3836.4971479145124, 1801.7382482957, 1060.4435238053743, 1331.1921502888808, 1350.9707949914057, 1194.6980231870814, 1121.8699632015773, 1105.3240025233865, 1057.5951946488474, 939.4829019030052, 4700.613685261085, 2205.005686441782, 1835.3170682266539, 1611.603077825913, 1073.512703433125, 1011.5266184725019, 927.6752899899013, 886.9719014680775, 798.2773328098394, 745.517819798466, 750.7881330305003, 684.333771524078, 667.4711931241561, 683.2658486244594, 661.9548016677272, 652.8418453534338, 632.5919406639708, 555.3983922863366, 549.8141411156083, 527.0957659061492, 483.3651186897761, 423.7343958268496, 423.06423443118854, 419.2047999404737, 414.27258398680334, 408.0603501570753, 405.08653565923225, 406.0409497055067, 400.86519159072196, 381.29770148687425, 4616.9883066690545, 1310.3215364522064, 2170.1056115672955, 3612.1925603147965, 6216.652879950817, 1741.255068460449, 1002.6100335423099, 1184.5342926935725, 2420.1294165179934, 2338.228133830097, 926.6863854830153, 1470.6417399039558, 1508.0654913917394, 2230.407964073045, 2224.631292437852, 947.0808190840504, 960.6609841280252, 1370.9960228750815, 1336.1155958171664, 2248.7156714162716, 1097.0739592953328, 1950.2967314917173, 1253.8883088684422, 1441.6973026460403, 1139.860069764523, 1229.519463676186, 1207.2952203753343, 1069.0785970031018, 1094.1456871549226, 5365.558782806956, 2429.998635877107, 2364.7085979045833, 1135.2218122347492, 1012.0799278254948, 871.4544635625041, 762.6534345003778, 746.5212452801625, 730.6419146834114, 688.4415237340546, 658.2563465360296, 619.242175807827, 581.5193504096507, 583.4479610013292, 566.9871139185204, 564.455398114174, 567.8688569220539, 695.5938105120397, 531.9241575519378, 698.3298500876433, 523.5681533956706, 537.35581751475, 505.8439149359647, 494.5097273786031, 489.1775771237034, 784.9701838934848, 502.4102465338873, 500.07176839794454, 601.0937480441894, 446.7551988994992, 696.1403712957976, 888.0473360520261, 530.6818244661075, 981.8791558224984, 564.3606092825964, 14665.076222489488, 4353.76868496229, 2205.8185404939845, 6692.171286883695, 2653.2205524949145, 2280.9254551524223, 9933.263579767034, 6082.157681700771, 11327.71581938556, 5096.548184876859, 1405.7404384142874, 14963.289630991523, 6565.755342127325, 5307.569871825851, 11824.01677455014, 3497.2915993988054, 3811.2510930891294, 21759.134756976353, 7905.921959553453, 8409.700782832462, 7473.023752698536, 6566.545478912541, 18116.3987924913, 14066.106709665326, 5119.4931290838285, 8986.24772437264, 16789.456145332446, 8853.753412639137, 5582.535351338616, 8179.479026611799, 6593.478449707832, 12159.538048724873, 12877.324274538685, 8022.167969726326, 9284.383901459581, 8220.701930942067, 9627.861708782964, 10082.685150556521, 6501.059604137451, 6345.814699780021, 5755.750563204263, 3444.088239936019, 1944.0241195195906, 2137.7364645816992, 1851.7289172218552, 1663.1783874164862, 1626.400269907027, 1613.5564157552126, 1400.6315081369785, 898.7369052911781, 892.3458009315515, 850.5506500987069, 1046.344009231014, 752.0928274299198, 663.8027119190425, 649.1960246177532, 604.3930856749142, 598.8683541422624, 604.2910031008109, 603.9377012501606, 603.1788968752326, 552.242633280669, 522.6315042494649, 502.79847193129626, 498.61580105430824, 504.827511549638, 467.6699352972721, 460.3521982864561, 455.44929384647276, 433.606054872387, 410.5197838228342, 2089.897346696622, 6214.522431941641, 2199.002070789457, 2177.58497707624, 2179.0536088127037, 3784.861702693978, 2153.0209123085037, 2322.4730084411494, 4387.581652151565, 13294.721380247418, 916.5436692076981, 2507.0953103063125, 1163.9412117130512, 1686.3589929444902, 2319.211342948801, 1116.96286766612, 2498.459520425266, 3019.528793680571, 3634.731434232786, 1301.1227722316323, 1602.2624069556025, 1646.4326601607715, 1831.0612962355185, 2067.222007493848, 1932.4705212379117, 2644.6976433187046, 2050.178459276788, 1888.2403192634633, 1106.3452109815496, 922.9437210042618, 949.8966761069784, 744.4939051094983, 744.5341006770321, 711.3313179306439, 719.5341681206426, 665.2235033222087, 658.1456625368816, 631.0262884548491, 609.4642431382986, 601.1656466399479, 585.5434099621534, 573.6162110843882, 543.0574725559729, 519.2835825570794, 504.58770987767207, 516.172546701984, 469.19294698956924, 706.7910847444236, 419.48175913453315, 404.7785392962633, 398.1394288544443, 406.87267394137933, 387.29937624520164, 379.19215574198574, 376.33788170851625, 371.6902400570193, 373.1871167721639, 367.5837613606859, 869.9867216339369, 1968.4156604949846, 519.2707541844621, 2703.2889081232893, 1259.8244829553737, 6017.895642606492, 2355.6596026209377, 1243.646350130834, 1666.3491581341193, 1691.1107162029675, 1910.2785642618364, 631.731110345523, 1258.7292509247166, 2389.635664119148, 1752.4544391041377, 3441.6673336368885, 8285.869197760121, 1799.9632674977963, 1797.4967990559303, 3046.683140212285, 6598.584602001018, 1294.9886072533618, 2331.1432608383598, 1370.3992238371325, 2092.6594600127855, 1241.2461227403005, 1024.838473982375, 2965.6690904693232, 1628.1908916672778, 2267.164512453905, 2830.6937741493925, 1969.0818028985248, 1384.481822557725, 1844.6019613245678, 1966.0465321895836, 1886.6990824188779, 1634.2177388705488, 1538.700630776002, 1503.0918673083306, 1538.4250928817273, 3179.8438673933465, 2536.281069919135, 1725.6602757901308, 1345.5567789419322, 1188.0833320550212, 872.4947868879286, 849.2597512112488, 631.8933094749092, 679.0696518853763, 563.7555830502031, 553.2783214167446, 547.7832487290281, 463.9841513555071, 441.205226736714, 428.8296820786578, 395.72559001859605, 387.6574369275132, 355.49905600608935, 351.54334205886397, 331.04576600341346, 329.7565029426369, 380.302329881518, 322.6442663518331, 294.430858020109, 293.8357953891207, 286.08823215648374, 282.2723916952813, 313.83118618045154, 273.313477763641, 258.93701758902034, 524.0602852787567, 4023.36863415897, 2917.7609184394255, 795.3165250782884, 2079.759053267843, 1510.4918030973386, 448.22385700624613, 1712.5068510247959, 1014.3007739127767, 1653.4642886855738, 2993.4576018649254, 1121.4382898491826, 2359.8379139655003, 997.4103858406047, 2440.95098588287, 2378.89020927811, 1237.5514642286614, 2352.153019371681, 2395.7283699112945, 1130.0841178647604, 2242.662695900609, 879.6457438214298, 1161.5560810166392, 1294.0616389720694, 1699.1740177169963, 1257.9632166230833, 1090.9619068930372, 1466.3588453191464, 1447.198836273585, 1196.6968287988448, 1312.5040996071132, 12650.864663226923, 3287.4068881159915, 3061.8074049701604, 2348.5684162109837, 2337.7311878771043, 2217.7665441896347, 2172.0857542878516, 1628.7595982694872, 1225.0282665586396, 1196.3571865973274, 1017.7130044452387, 704.6365356858327, 670.4658635849413, 585.3422974784847, 536.1713705049652, 510.03702828331075, 547.1656771371378, 491.58954156705977, 485.2796729037092, 469.3134632743547, 447.72319118049427, 482.58350836906146, 386.67645837236233, 368.20765453224874, 371.76569477289917, 284.42284445142616, 277.6129943903601, 268.8203582479785, 254.23138385936605, 251.6463438655321, 4930.349780551429, 929.21451309538, 1824.8074055195264, 766.534779200123, 938.1444008043264, 1153.5892552138637, 1242.9198370087347, 848.5155599289701, 1052.5566563399386, 742.7107706038815, 879.0137703203421, 765.4082234000584, 601.2552142981825, 892.3383276364519, 875.7865745518442, 681.7228857033621, 585.6223557095703, 5518.337676298868, 3705.9756603784203, 2602.842119311449, 2395.3871191616536, 2315.268525082428, 2153.033522228624, 1499.5809395201575, 1198.7860416247279, 1092.8313015700176, 1061.3233935356945, 871.0543038459969, 836.3778329126314, 803.3544304617112, 763.6535660748648, 664.4149648213133, 652.3886394261986, 631.0256782114807, 594.9343842302627, 581.9191882100356, 566.1312208552972, 554.2584370391995, 551.620755935154, 548.3527382397987, 541.0128526146698, 518.2249809390177, 494.49279560357377, 476.2714806228414, 458.27315323078386, 439.0741195388988, 449.0953814945878, 1485.8394497580498, 2488.7260030969283, 1702.3311499324516, 2402.560232982568, 1813.8669160187833, 983.1472601061665, 1721.3072467261798, 1117.7734695700826, 2970.5888506170622, 3254.934472659947, 3108.9285460485034, 2693.007979582097, 1962.2482003036307, 10552.940200104813, 4262.349108590584, 4058.6498703003244, 2986.9805420411612, 1234.4161025826786, 1760.9328356937988, 2715.402644909636, 1361.477360521553, 1699.2691385022417, 1389.1208262257514, 2042.819967613762, 1444.0026390143057, 1338.5098923406326, 1488.0866618019538, 16847.847336625455, 5633.181554443933, 3542.025294492003, 3473.908167211745, 1915.792502295679, 1139.749098757023, 1095.8948233939059, 1084.4763505131564, 1030.7186669684927, 954.384955663217, 908.1595926961035, 795.1445180491819, 781.601814493743, 775.6859496606894, 715.9377451899201, 713.2492430821869, 668.0505275028053, 659.0781766439003, 630.7898858445466, 601.8214301163473, 565.2661750399923, 568.4662353258773, 565.9692286189882, 565.0440353306827, 544.5343545509919, 541.6653915156278, 523.6266760860435, 489.62041584894376, 471.4478364957535, 469.4016037831461, 5323.99031847024, 748.4272067391693, 604.4850888958181, 922.0225481912482, 2323.3256118166564, 871.1153528210837, 1221.0311722840418, 5086.28481375925, 6090.020347420015, 5021.704266670805, 3723.3669622478305, 2103.4711103823656, 3504.497492473726, 1588.0135385594579, 3614.11079666443, 1686.3241372569496, 1427.4519907582371, 1651.1416967565494, 1098.5288467310334, 2133.0226907292695, 2553.565255005904, 2092.593768067979, 1736.6713488750906, 1835.5486781167988, 1476.6113886256048, 1543.7688320070006, 1613.7383635961144, 1695.55047016215, 1276.4296504684032, 1581.7924917244009, 1293.5351016807033, 1419.1346462292522, 1304.6121994873106, 1310.923539840316, 14513.75542480124, 1895.3835042794346, 1686.638977566628, 1015.3193432912088, 1003.2863823584169, 930.5498728349761, 869.3629507245292, 868.622155474521, 862.5503642033935, 774.9966980344216, 679.4183162108825, 645.2712253549013, 615.8963006653385, 743.9081516349071, 516.211687612089, 504.3687383662411, 475.4968261082853, 476.85322227065257, 461.6306219298779, 443.2638586294073, 436.8156797161685, 431.83591922552637, 421.44815672269493, 409.9701217031062, 399.9649454670543, 380.1297935450672, 367.93006576783705, 365.84512259939714, 348.4996423151701, 346.15838005648476, 3065.151951954338, 642.5148638510086, 2492.7208842795885, 5002.649627455338, 2272.386717502086, 739.6967821944787, 2054.4418821255267, 1514.4942302071142, 1562.5311872991304, 872.4212567723549, 1874.311756537225, 1375.198975072322, 1037.9936739187851, 924.967951719116, 1474.5327698102162, 1325.035293697516, 1147.0013760859451, 829.3151267973984, 741.1503000770076, 810.2311707023869, 785.2897527045824, 787.2641934678799, 792.2517618415175, 780.7574256310946, 1922.7036983745381, 1739.4317499445892, 1650.0723655414397, 991.7560889940823, 731.5167159787451, 636.447762510207, 547.4501814103576, 422.7789606902431, 416.4498941591654, 387.1981101993457, 379.499540804581, 375.58587627320964, 367.20041382279595, 358.34125915189844, 336.63319207372535, 339.1156618638296, 319.30599131607863, 313.9476048481791, 308.7295821527545, 288.7933809740476, 277.717733077703, 277.4370492393613, 269.8807667078356, 247.39002354197905, 243.08946811415794, 233.723622733529, 232.5868794122102, 233.1149645066922, 230.14225954487205, 232.01773195925392, 695.5324097868616, 26651.464545295028, 1651.7548951335918, 2509.5320478159365, 955.4002329252537, 6038.672133335946, 500.52842761749497, 3578.2799496828247, 2322.4327991125674, 870.2102841251007, 376.54130273009986, 969.9296207140925, 1746.8625726570615, 2618.649791208722, 813.044837724407, 1663.1353966226543, 1414.9652538295757, 1105.776052984202, 1133.6554494441884, 882.1201600535891, 1034.4611166337952, 977.9035417409893, 771.7611489857952, 2452.20174008883, 1597.44733643478, 1214.3666946811918, 1141.3390711789232, 1050.1699709535415, 1439.0609692112005, 1100.3946331337415, 1108.792945326988, 911.3420486933487, 895.6073200615036, 8471.702096511777, 1661.502282637707, 1535.8893832271115, 1486.9998242180175, 1234.2405692994164, 1068.0685958939328, 939.3920542346387, 821.0654122708986, 849.023080031164, 764.9625750670409, 764.5084241408377, 650.7254466308912, 571.6611592321823, 563.0576337167703, 526.2902480429992, 521.7498163768493, 521.5852043163779, 511.32467076200544, 520.848314526038, 489.89489305758894, 485.62270844889764, 481.71534578370677, 459.2311962472649, 449.7351983913566, 412.1165119714463, 430.46600042872376, 402.30414682821237, 401.81636747882044, 548.8421374860413, 1055.7325011969544, 1517.8706423884018, 6124.758315383927, 6896.035156412991, 21836.569406395753, 2442.542588252086, 1398.504380508665, 6576.7831820719375, 7665.62648884996, 2976.223806334809, 26057.95094306078, 1365.183332255329, 682.328138196996, 2424.710977511916, 3804.1824879822366, 10594.994048128043, 11673.0179949911, 5009.996226569805, 3491.675223420024, 17065.962962755988, 9274.758057563631, 3268.205916355624, 2893.0339988426863, 5742.735266209262, 3278.9256915477763, 6768.997749564421, 11938.411578556417, 2907.905713806581, 9285.603577047576, 4536.6117745435695, 3013.9164752857346, 2578.7157786644175, 5930.056210695916, 5954.218734396549, 5888.955960617799, 6102.627320028685, 4583.214154874079, 3274.6976512117353, 4364.905120058385, 3752.227503117468, 3684.0952029825485, 3279.701263314403, 11202.20620124658, 5443.403564193197, 4240.489587528357, 2531.416242580314, 2219.458839455959, 793.1949259656174, 709.5773660950741, 1195.7292781166782, 549.7069528193092, 535.1675753604919, 418.4494568663397, 396.9583662113469, 389.981894716484, 352.4563448238657, 345.7448936122655, 339.933016104501, 331.59896456493857, 332.023826731753, 332.5677772026486, 321.6893445909781, 327.9453185352363, 311.94935002182484, 307.2642856923192, 297.1864823291561, 295.33000925498965, 281.1713682854871, 305.7581558554946, 249.15087934969384, 232.0165837180424, 215.6359963656115, 1368.1227317086868, 415.72906115105343, 421.4961474356548, 2543.4455811232674, 629.670666996451, 7859.392891236537, 671.7677613132129, 1189.7141651480924, 5214.959540858169, 632.1320767091584, 577.1560082552362, 835.1284735279665, 430.29288632058194, 767.2121119964073, 1122.6904334606115, 948.1192257177403, 427.7573791906558, 649.9571200002496, 461.82342272365656, 464.95326213121615, 471.7002534812549, 424.27311453235075], \"Total\": [37204.0, 24016.0, 17305.0, 14513.0, 36688.0, 32335.0, 12651.0, 16847.0, 17422.0, 33752.0, 11202.0, 16889.0, 23396.0, 34317.0, 9972.0, 24485.0, 14484.0, 38410.0, 14124.0, 10301.0, 9012.0, 7994.0, 29583.0, 6492.0, 17728.0, 17423.0, 11474.0, 18413.0, 8771.0, 5443.0, 6492.836753413492, 3381.446726663003, 2627.860890182235, 1544.2530640612388, 1061.7733406962727, 908.8569937939137, 734.1283163364548, 682.633197361693, 664.3392438687364, 623.8925176228842, 611.0664700308515, 560.2739394456504, 524.5783556932477, 488.2753725890563, 474.8894161612567, 460.01885364813666, 453.946194899232, 437.0271576867232, 430.18999409805826, 441.5355246081272, 427.5042760626454, 397.63581362444967, 377.1230597224718, 376.97033453341146, 361.3002710326766, 359.45863238902984, 326.16354818679446, 326.70872168500364, 317.36417674124584, 300.65029937052225, 302.8571094086788, 601.7643792750677, 859.6074353989733, 1089.7556934320423, 706.8377609433562, 892.9425271838194, 855.8445562101998, 4520.08274203754, 979.3139910700381, 1765.6943528615302, 5580.534003783581, 3476.282849414512, 7735.882504179963, 3646.438458698626, 11474.106104853116, 1090.1912614242135, 832.5134193951717, 772.6406978662013, 17728.658456679088, 923.7146608471619, 11352.79110513091, 1661.7011929600753, 3263.4934717881033, 19044.102033789397, 4387.5347038580785, 5097.8826541262815, 5871.995189424549, 2373.6428056132763, 2258.7152878787447, 2204.2288085072896, 1865.5456533205809, 1551.0304867198338, 1866.440726947238, 1533.6734960856636, 1252.1531592931474, 1229.880123009396, 1122.765982453707, 980.3757996919352, 895.2743834929422, 848.8378684053046, 817.4904313249478, 786.2712065745234, 759.8844597204229, 750.0859187827725, 683.4252795226453, 672.108667592644, 1171.6929423938464, 641.1604322220371, 607.7910247107109, 682.6270599230278, 532.9782940091578, 522.7278203848316, 530.7605743515619, 453.19119918671123, 428.61424829814564, 375.99004838921803, 377.2387040649498, 1578.5540886595033, 1860.7698109591875, 6718.310779991281, 6293.1163464822075, 2805.666166113393, 3861.5578747299555, 1781.2107250277747, 1848.659899708286, 4685.027251118636, 11215.982738065923, 5251.433680185682, 17728.658456679088, 1017.8634294870498, 19044.102033789397, 10848.087511812133, 19197.299039147907, 13185.195204331476, 13121.677069785233, 6035.263472115067, 3831.863976701474, 2206.4953885765412, 1858.143774165402, 1580.5213580665504, 1545.827352219452, 1550.1588090457747, 1502.8249963876874, 1414.606545306881, 1375.3558199834151, 1770.2835025250154, 1009.3626043868182, 968.9221624456057, 1114.2551619644564, 858.8931117456978, 1564.8707208975393, 734.8605220953755, 709.0518617885571, 662.3327519271762, 662.2713430469825, 621.8367634758156, 593.6411964446528, 597.2107782071431, 574.7094180176599, 601.2089134106988, 627.1344845473435, 1033.5288335751302, 538.7045631770663, 524.9479658816344, 1686.2959843369465, 4567.909418717067, 4780.700009530535, 1419.5114478378746, 862.6925088241262, 1090.854416700688, 644.145095648309, 3319.1345013745477, 1155.9328685246362, 33752.59790663783, 12220.363555537711, 2375.496292611203, 3690.592659345363, 3905.4564778906515, 1723.4344418288538, 2816.1876736496356, 7212.159306886209, 1812.3610560194818, 4265.118323448507, 48830.22772604206, 2787.8375821838354, 39161.48625094998, 10137.497210218973, 18586.675541485263, 7704.270817519505, 28938.299435662757, 38410.44758934336, 10417.283206566823, 5193.328416271212, 17154.90656961664, 4900.654338985021, 8613.233420612434, 13458.179682514561, 12203.196191886282, 11524.911565016593, 24741.219669053662, 18783.62676682526, 32801.96652761704, 10398.43568882945, 15111.665774537616, 34897.71887544617, 16889.246997596903, 13075.800838369054, 13370.886399247078, 32335.165599979584, 28874.443658451306, 29583.61525780788, 18413.751310453023, 17305.339775714638, 4373.186644524999, 1931.1589739566932, 1575.1067729585848, 1370.7217188419547, 1263.6969404062959, 1028.7334764363748, 984.9719792483207, 840.2268129849646, 810.8841390445231, 714.0840798994204, 699.9045935896465, 702.0000340523335, 648.9637432270033, 691.5128059593462, 571.6047031190487, 565.564333009405, 560.3847143583758, 555.1091834038448, 555.1625790077766, 621.458075339206, 526.481419699006, 531.8470040223821, 494.60893939702646, 472.12316468195723, 465.7532969605686, 461.4618981266088, 425.7135561954707, 676.3571086498872, 401.35685322965895, 1407.3827055844563, 732.5730134101058, 4653.860954196116, 1432.9137778738177, 713.5372789910673, 4106.225143861086, 4711.034525140697, 1911.8056784857565, 1478.4858850888916, 1383.7700134445486, 1511.9833431832717, 1746.6538468255817, 8115.975647240342, 5303.252122509774, 17423.65905041461, 2789.3667092107603, 2046.8252440850533, 5102.2855334929145, 4050.997676675965, 3710.425710871108, 34317.6213563764, 3411.426295293485, 7808.528083891838, 19197.299039147907, 19044.102033789397, 8005.793770549496, 18586.675541485263, 17818.374979084892, 9972.211730832723, 2761.8382593581487, 2591.0944867726353, 1365.465644452023, 1124.5283111445594, 1076.850303300596, 974.4033375976863, 1390.9824262072025, 819.7877661801516, 778.9122591438788, 768.6205079848381, 709.1582119691775, 692.2299095154132, 610.0304494796096, 563.4552561912957, 527.2177968851353, 481.43844163324167, 457.5077243987109, 387.8825324480024, 361.4469842756701, 357.1116679766542, 354.91981021470843, 311.72110294105875, 310.01642533208155, 305.9311839585563, 306.2120287173423, 331.44357178231996, 297.493416034347, 288.13801349789173, 275.62214449765423, 4472.526791931702, 1723.770961174893, 24016.916963480275, 984.0874883465796, 3466.4721426432784, 7188.295262658432, 4117.50136423238, 1470.7771380305562, 1154.5415957773325, 674.4057272307407, 482.54591255741815, 1052.6685124847716, 3916.143799423095, 4987.490184234341, 2289.7581369959335, 1826.0743941705066, 2379.4915450112762, 28874.443658451306, 21320.55895199926, 4041.7835939716383, 3961.807925698946, 3619.8086950504357, 10583.292850331953, 23396.240824052846, 17728.658456679088, 17423.65905041461, 13458.179682514561, 4143.411105161977, 3147.8568491411174, 1169.5213200000255, 1116.1796875371986, 955.2733536217493, 863.7162511244323, 843.2954520889881, 769.5303689829717, 769.9696957476503, 666.5462217538014, 664.5238615777866, 665.0034726973423, 659.8942059187111, 613.2588217563787, 592.3126795111722, 569.0519169054743, 568.9832443580392, 640.3315476642917, 533.711835341327, 516.833973073244, 496.6387923788902, 495.28036352623377, 490.9805261172099, 475.49814493832434, 471.7379854325781, 507.9810163749797, 453.2480965398993, 436.24432266065725, 436.53070357878954, 429.404133585794, 972.4376933965235, 760.5965749224687, 1209.8676945035497, 1398.6796677095012, 2345.070101860786, 1053.7770767776747, 4874.920401564917, 14484.586059020792, 3405.7018150356257, 1628.4356718318504, 4232.378133519625, 1915.5747490077492, 5956.661647204489, 2919.8996122705225, 17728.658456679088, 1640.8642446509532, 1138.9455737435699, 12203.196191886282, 4306.460601938273, 1094.2644679951293, 5193.328416271212, 3271.289856922238, 3049.0064015342696, 13336.72517755152, 5097.8826541262815, 3619.8086950504357, 28874.443658451306, 3999.0026978531205, 9012.36744473092, 3346.351595957246, 2664.01777682539, 3005.3674503434468, 3633.6561119405983, 1296.2852186982198, 1319.0744478793674, 1208.9163081999245, 944.4045966679995, 886.9530150060783, 792.21577530077, 719.9695016814301, 665.1408404788846, 669.9269416165639, 671.471053423996, 657.6849837287796, 652.2813028807161, 615.9078996420893, 634.3652632218424, 671.6514977887272, 634.4242231727017, 532.2162534180944, 523.2727018434408, 504.3102322503114, 505.20976091255613, 494.1316874799203, 496.58256553797935, 466.85752932606954, 456.5064731665408, 474.791576450784, 1369.2058913713058, 2812.5054384252558, 833.0127485287304, 1151.8857417099255, 1796.1829529384943, 3937.6074576397305, 1976.64712397146, 14124.387326206099, 2008.7950664695986, 10540.211786137716, 2008.295359052005, 1323.3633895281673, 5790.562499602003, 1781.905767965676, 8129.676766134834, 5097.8826541262815, 2590.3206063947046, 1893.2553433278442, 10110.463146066992, 5303.252122509774, 8093.546973851285, 5294.046618803373, 5791.419588536389, 8966.231232377502, 8115.975647240342, 34317.6213563764, 34897.71887544617, 24856.254082418203, 48830.22772604206, 4337.953849671659, 3033.6393494509903, 2747.596785052675, 2138.481334764435, 1952.4546678087095, 1465.0637358468796, 1312.4896718616528, 1196.7301218215582, 938.9944694879895, 918.7640557006803, 880.2086847279015, 814.7534549189741, 792.9213436912744, 752.7023245386397, 683.0284346246804, 669.7475695522667, 601.2542992367825, 1332.1913924365374, 521.1100118798934, 478.84550804467136, 472.7827621028829, 467.2401844042162, 311.3583509272812, 298.1926995127431, 285.9825346865552, 270.01399291864294, 270.46318702929904, 264.3147953171848, 265.8591562682005, 260.70075458210636, 3986.2562933848058, 3215.2319270469484, 7994.437550678329, 514.1489631629784, 880.6825554672045, 1296.7157223373983, 399.7567574734963, 4678.402765071015, 1096.1840621884617, 5312.010833719203, 4722.670732455318, 7059.956373039095, 1688.7552017367007, 4987.490184234341, 33752.59790663783, 8613.233420612434, 2830.2702292138, 6148.104529441986, 16402.431148538264, 8771.814735604152, 14740.117425385572, 21320.55895199926, 28874.443658451306, 24741.219669053662, 4700.757399862068, 2205.150791333453, 1835.4620257622964, 1611.7456166854886, 1073.6545598452985, 1011.669181613044, 927.820194863255, 887.1135110779347, 798.419214056212, 745.6591656898283, 750.9312415845257, 684.4799745663826, 667.6140640957935, 683.4124948844883, 662.0969255370109, 652.9842278538677, 632.734667693895, 555.5395527960015, 549.9569405802062, 527.236984409587, 483.50726687395115, 423.87679197826213, 423.2069259124577, 419.3471736498392, 414.4137639612134, 408.2009227233046, 405.2268848289746, 406.1824052481242, 401.00766173457953, 381.43860982520613, 4636.9185966420255, 1311.1459856188287, 2329.4367864670485, 4069.932805605605, 7474.900004768319, 1932.45145749564, 1069.9877856037838, 1491.3866771604978, 3749.804217539933, 3750.7115384579874, 1135.261393285356, 2264.294853927605, 2638.429011544179, 4963.2365594881885, 5106.251916000201, 1459.5805619371033, 1658.356816499327, 4775.917897235625, 5294.046618803373, 29583.61525780788, 3147.677402799681, 28874.443658451306, 5277.539646584203, 32335.165599979584, 6583.7851424878445, 21320.55895199926, 18413.751310453023, 9921.738388631802, 34897.71887544617, 5365.716561547267, 2430.1434024819355, 2364.8545225006314, 1135.371228089317, 1012.2369588017617, 871.5990760254098, 762.7963755046407, 746.6649952261398, 730.785666284552, 688.5846263240521, 658.399445609886, 619.3918480402372, 581.6623674143872, 583.5917425919243, 567.1305756173718, 564.5984500752778, 568.0138745014207, 695.7736630473973, 532.0671073723065, 698.5212248950587, 523.7118781947187, 537.5037686559633, 505.98714374297646, 494.65256971571887, 489.31979160325494, 785.213525673213, 502.5670528572956, 500.22789680065006, 601.2828018812667, 446.89800632507206, 696.8912522719288, 892.4351818676327, 530.8601542255639, 1000.5429555268087, 567.1049686884498, 17818.374979084892, 4922.912070671594, 2474.7205399649406, 8314.47864961383, 3050.5970892991527, 2593.8189761913045, 13185.195204331476, 7808.528083891838, 16019.68055185445, 6541.73059283855, 1566.340443531202, 22648.531673665155, 8980.467142060688, 7085.844593393051, 17787.45454373506, 4437.663236929734, 5021.107875799358, 38410.44758934336, 11804.861933093702, 12918.6281287167, 11226.439875923468, 9688.964318729655, 32801.96652761704, 24485.155689645442, 7465.831491714066, 14878.606061838454, 34317.6213563764, 16549.60935505613, 9843.904490035116, 17423.65905041461, 12761.41302727066, 34897.71887544617, 39161.48625094998, 18783.62676682526, 24729.10626197528, 24856.254082418203, 36688.07799926823, 48830.22772604206, 17359.88940533325, 28874.443658451306, 18586.675541485263, 3444.243511646501, 1944.1732582181098, 2137.907190147023, 1851.8834151421356, 1663.323758701906, 1626.5455658140856, 1613.7080380063449, 1400.7752108330587, 898.8811760518356, 892.4893796711625, 850.6943334073703, 1046.5401606130713, 752.2367352503313, 663.9461992061865, 649.3404160339827, 604.5363192064145, 599.0121121442719, 604.4369356124131, 604.0835756037271, 603.3247691113738, 552.3854154629273, 522.775789409409, 502.9419384982812, 498.75879813161947, 504.9727596515893, 467.8134692946814, 460.49465766737217, 455.59182878417755, 433.7491330896708, 410.6632334885038, 2123.7023163066315, 7770.519251646097, 2538.1398246050862, 2623.2325207110966, 2639.8937829901183, 5076.252284905476, 2773.549927418725, 3215.2988536096273, 7677.487047540461, 32335.165599979584, 1058.4356704693496, 4748.939230904101, 1568.0455272942127, 2798.215076804546, 4722.670732455318, 1588.6657902429881, 7104.371155327433, 10137.497210218973, 17728.658456679088, 2232.080534459868, 4306.460601938273, 4661.264450163032, 6996.651521850844, 13121.677069785233, 11352.79110513091, 48830.22772604206, 28874.443658451306, 24016.916963480275, 1106.4900455719621, 923.0882757185019, 950.0482231115295, 744.638362485794, 744.6838431363105, 711.4752792119916, 719.6865064219988, 665.370499012556, 658.291136755311, 631.1706133962535, 609.6073888117762, 601.3089246604893, 585.6865696076086, 573.7593766678226, 543.2010564163514, 519.4265433181898, 504.7327610927959, 516.3223517082732, 469.3361760666815, 707.0137809721987, 419.6246098063237, 404.9214721865649, 398.28129573663387, 407.02084190375285, 387.4428564856711, 379.33496904520416, 376.4808639027697, 371.83329021348555, 373.33130400037106, 367.72688269312073, 870.8127463637885, 2035.9636610881344, 523.650673556123, 2970.2813273174515, 1353.6774368362508, 7160.082491632105, 2690.951415707271, 1386.8830684835798, 1931.5204234574069, 2029.9090881653597, 2401.286732871188, 666.1911419952191, 1588.0815031937157, 3754.4305090334165, 2557.8203950760735, 6984.362456550049, 24485.155689645442, 3203.2141108684928, 3282.9429587964037, 8015.909631165696, 32335.165599979584, 2240.3926569370938, 7036.266672566623, 2615.1556840838116, 7077.443856380423, 2349.784252482145, 1574.6751740580955, 19197.299039147907, 4647.817619788007, 11352.79110513091, 21320.55895199926, 9278.58510559783, 3491.0436256654407, 13336.72517755152, 24856.254082418203, 28874.443658451306, 14740.117425385572, 13121.677069785233, 13370.886399247078, 33752.59790663783, 3179.9874793667573, 2536.4254779608955, 1725.8056534110958, 1345.7179693549283, 1188.2272100334853, 872.6368392065092, 849.4025093521344, 632.0357133678116, 679.2258253947864, 563.8984224184803, 553.4205919137952, 547.9257737434796, 464.12763526740736, 441.34734473453545, 428.97206417645, 395.86779956054073, 387.79964963014066, 355.6403053601826, 351.68789874184006, 331.18709919301864, 329.8980553673719, 380.4688349956474, 322.7861454976487, 294.57283376043137, 293.97929854780915, 286.2297467118297, 282.4137350014879, 313.99065412214827, 273.455319731812, 259.07877417528454, 524.4041899669456, 5277.539646584203, 3878.107060658999, 920.8689530680429, 2821.21302020049, 2034.2240385485782, 484.26818634512415, 2714.251769077862, 1469.9224712763446, 2973.873011228767, 6793.469887988802, 1899.2996906770675, 5791.419588536389, 1647.4288352478209, 8093.546973851285, 8540.562252616839, 2912.2167909043465, 9971.014901692439, 10345.045107254116, 2638.429011544179, 11352.79110513091, 1676.3275658280381, 3411.426295293485, 6583.7851424878445, 17423.65905041461, 7474.900004768319, 5115.7140521249985, 33752.59790663783, 32335.165599979584, 10319.384166356489, 48830.22772604206, 12651.014002404298, 3287.5519982361807, 3061.9527763724395, 2348.714635129378, 2337.877822964886, 2217.9113934908646, 2172.2317847501236, 1628.9032259432292, 1225.1727742134115, 1196.5008271914207, 1017.8564831955202, 704.7816112610128, 670.6090335535627, 585.4848530582418, 536.3141721739464, 510.17892184384357, 547.3195021976634, 491.7321131077973, 485.4223231138697, 469.4556825855079, 447.8656490886723, 482.7460498988426, 386.81856483092423, 368.34961416653636, 371.91764451565433, 284.5643548204807, 277.7544917289867, 268.9624104655037, 254.37288676802743, 251.78759098315575, 5033.985829803762, 969.8335823974419, 2124.4612869669663, 881.777349308932, 1384.3943156941993, 3581.073207213944, 5500.974155046522, 2564.548618285252, 9971.014901692439, 3204.874398451885, 7465.831491714066, 5115.7140521249985, 1452.6628934171808, 15111.665774537616, 24856.254082418203, 3856.7054329283606, 4050.997676675965, 5518.4865049113205, 3706.1222484423715, 2602.987817838665, 2395.5324494167103, 2315.4138572797788, 2153.1794779249167, 1499.726897847253, 1198.9314804351725, 1092.9757044058515, 1061.46728227571, 871.1986951370726, 836.5218294522152, 803.4986425749067, 763.7972292602548, 664.5584193468823, 652.5340913276159, 631.16880990537, 595.0781729614035, 582.0617523467504, 566.2747192235742, 554.4020386626898, 551.763952421299, 548.4962740230922, 541.1563771466816, 518.3688287053541, 494.63526900062004, 476.41466307276795, 458.41574740546844, 439.2168401179923, 449.24925112190294, 1502.1917925900852, 2585.1806502522236, 1901.21626313059, 2804.5255952713724, 2066.03850153586, 1079.4018759029075, 2093.470089958057, 1328.4750202836003, 4534.216198907574, 5837.378425921913, 5580.534003783581, 4685.027251118636, 3187.274678058719, 37204.7021760091, 10301.313013486271, 10157.476211605073, 7735.882504179963, 1984.9080530506083, 4301.68251410374, 14740.117425385572, 2824.5085685556155, 7059.956373039095, 3631.178773351412, 24016.916963480275, 6984.362456550049, 4874.920401564917, 24485.155689645442, 16847.994661483513, 5633.327458303573, 3542.170009269646, 3474.0538862605204, 1915.9368249577403, 1139.893108905954, 1096.0381531888931, 1084.619253750481, 1030.8617958757166, 954.5281128849471, 908.3037419846554, 795.2869217379371, 781.7450603242794, 775.8293161951187, 716.0802008775677, 713.3923009067148, 668.1945706247918, 659.2209448366814, 630.9323829744625, 601.9632958184587, 565.4079747194899, 568.6090247996052, 566.1116239153657, 565.1868859719423, 544.6765925244133, 541.8082552150101, 523.7691205680293, 489.7637720682227, 471.589116307832, 469.54413565410675, 5617.476058431053, 770.6764227446063, 615.3996738864486, 985.5419796572945, 2910.0469620284057, 940.7769197919833, 1534.3795177431978, 11215.982738065923, 14484.586059020792, 11474.106104853116, 7780.786294308813, 4041.7835939716383, 10157.476211605073, 3235.5122734537595, 19197.299039147907, 5312.010833719203, 3924.567458374905, 5931.4021884905715, 2153.573664842849, 17728.658456679088, 33752.59790663783, 19044.102033789397, 10848.087511812133, 14740.117425385572, 7735.882504179963, 11352.79110513091, 16402.431148538264, 24856.254082418203, 4872.709741531822, 48830.22772604206, 5593.144625244928, 28938.299435662757, 7021.392644623712, 39161.48625094998, 14513.901666463818, 1895.529996475297, 1686.781456347789, 1015.4620683581323, 1003.4290870750168, 930.6936449932673, 869.5054325461379, 868.7650379356915, 862.6923625874995, 775.1396846296292, 679.5605574596317, 645.4133602717075, 616.0375525197976, 744.1028611357026, 516.3550409155481, 504.51400033277787, 475.63767229118224, 476.994653740752, 461.7731771051061, 443.405483723706, 436.95655250786933, 431.97788941802975, 421.59001571400063, 410.11170873686143, 400.1054572194703, 380.2711947807946, 368.07109559301045, 365.9865458609538, 348.63999163382823, 346.299797937483, 3461.64325919647, 681.1898323999617, 3694.888651338454, 8771.814735604152, 3596.1244184144184, 970.1631522875443, 5251.433680185682, 3508.5955721489945, 3874.1487152039736, 1675.5522550816604, 11804.934743544987, 6148.104529441986, 3263.4934717881033, 2812.2853673194327, 11215.982738065923, 9971.014901692439, 10540.211786137716, 2534.975058781548, 1605.8808520508978, 5791.419588536389, 5039.194980287149, 15111.665774537616, 24741.219669053662, 28938.299435662757, 1922.8495605619046, 1739.5768759923476, 1650.2191462281137, 991.9005890146245, 731.662580610378, 636.5930853086297, 547.5935704972371, 422.9219925625799, 416.5934645303491, 387.3415335240041, 379.643111880975, 375.7282046018582, 367.34317400619915, 358.4838367602356, 336.77732743236163, 339.26145569482725, 319.4491886401422, 314.0900202321534, 308.8720489340796, 288.9359050670776, 277.86020657414804, 277.5798643576868, 270.0234332219799, 247.5320427981779, 243.23212405672479, 233.86556634992033, 232.72896522702823, 233.25763013533088, 230.2840832352828, 232.16188769698974, 717.0639051459, 37204.7021760091, 1965.164054229809, 3152.00789510371, 1164.8760485125658, 10301.313013486271, 567.8618587719513, 5956.661647204489, 3967.0710079465457, 1171.061944886874, 416.2997611235815, 1550.6324572171898, 5102.2855334929145, 9921.738388631802, 1489.0340637809024, 4942.660351942519, 4647.817619788007, 3035.3162228899296, 3313.7783199750065, 2046.8252440850533, 2824.5085685556155, 3049.0064015342696, 1812.3183259742702, 32335.165599979584, 13121.677069785233, 7770.519251646097, 7077.443856380423, 8093.546973851285, 48830.22772604206, 11524.911565016593, 13336.72517755152, 7160.082491632105, 9278.58510559783, 8471.85494280414, 1661.6523831008358, 1536.0380161807363, 1487.154029198943, 1234.3870665906002, 1068.212954151367, 939.5371703170833, 821.209378740467, 849.1737274211295, 765.106806055169, 764.6598011131956, 650.8696672997592, 571.8052182773051, 563.2013146318496, 526.4340991522711, 521.8935981555694, 521.7317513447912, 511.4688780375728, 520.9961341998542, 490.0394792761689, 485.766402101423, 481.863200037761, 459.37582666811653, 449.88449383867123, 412.2598293025912, 430.6172436221846, 402.44819957952546, 401.9604664573868, 549.0450604561858, 1056.1295758866454, 1521.3742360137726, 6244.050272586501, 7215.291602861796, 23396.240824052846, 2506.2817318799734, 1468.4633799340706, 7516.630674467091, 8961.382075724337, 3306.3712810361867, 36688.07799926823, 1529.501623617122, 704.2214743809847, 2934.339183882041, 4953.76586566026, 16402.431148538264, 18413.751310453023, 6980.113685488555, 4612.606875927561, 29583.61525780788, 15198.737939440816, 4536.475421859707, 4121.319868744775, 10583.292850331953, 5307.87711483515, 14740.117425385572, 34317.6213563764, 4523.095880806546, 24729.10626197528, 8966.231232377502, 5111.977168608166, 4036.397938333235, 21320.55895199926, 24741.219669053662, 24856.254082418203, 28938.299435662757, 15111.665774537616, 7021.392644623712, 34897.71887544617, 22648.531673665155, 48830.22772604206, 13075.800838369054, 11202.356640283762, 5443.551711108809, 4240.638401752882, 2531.5618660631976, 2219.6112366517896, 793.3386346711856, 709.7203320798311, 1195.9952680226854, 549.8489136099794, 535.3292036930565, 418.5918869556512, 397.1007748313304, 390.1238854698898, 352.59803441892933, 345.8891898752341, 340.07738483697165, 331.7406672915425, 332.1659215534827, 332.71029122854156, 321.83132726517226, 328.0942194563531, 312.0911805818714, 307.4090560589779, 297.3280116541242, 295.4717424897722, 281.3138016241111, 305.9155380567742, 249.29299515134014, 232.15810530347696, 215.77757514095813, 1661.8208278668153, 447.7657350915608, 466.055075793384, 4135.552702432262, 760.6671894056814, 17422.518018412367, 858.1489041615874, 1947.1589302138846, 16889.246997596903, 1166.4010282957015, 998.2527543141515, 3503.353934893394, 645.7288634662302, 2982.964201904039, 28938.299435662757, 24741.219669053662, 1112.5584630504145, 16402.431148538264, 2638.7822808192996, 4518.059270344682, 6655.8730997668135, 4872.709741531822], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.9367001056671143, -3.589099884033203, -3.841200113296509, -4.372900009155273, -4.747499942779541, -4.90310001373291, -5.116600036621094, -5.189300060272217, -5.2164998054504395, -5.279300212860107, -5.300099849700928, -5.386899948120117, -5.4527997970581055, -5.524499893188477, -5.552299976348877, -5.584099769592285, -5.597400188446045, -5.63539981842041, -5.651199817657471, -5.625199794769287, -5.65749979019165, -5.729899883270264, -5.782899856567383, -5.783299922943115, -5.825799942016602, -5.830900192260742, -5.928100109100342, -5.926499843597412, -5.95550012588501, -6.0096001625061035, -6.002299785614014, -5.324699878692627, -4.981400012969971, -4.767099857330322, -5.18779993057251, -5.0528998374938965, -5.136099815368652, -3.882999897003174, -5.053899765014648, -4.683000087738037, -3.902600049972534, -4.26170015335083, -3.9052000045776367, -4.380000114440918, -3.7925000190734863, -5.117800235748291, -5.270100116729736, -5.32420015335083, -4.1545000076293945, -5.258900165557861, -4.51170015335083, -5.088500022888184, -5.174200057983398, -5.078999996185303, -5.20550012588501, -5.2154998779296875, -3.283400058746338, -4.189199924468994, -4.238900184631348, -4.263299942016602, -4.430099964141846, -4.614799976348877, -4.429699897766113, -4.625999927520752, -4.828800201416016, -4.846799850463867, -4.937900066375732, -5.073599815368652, -5.164400100708008, -5.217599868774414, -5.255300045013428, -5.2941999435424805, -5.328400135040283, -5.341300010681152, -5.4344000816345215, -5.451099872589111, -4.895400047302246, -5.498300075531006, -5.551799774169922, -5.435699939727783, -5.68310022354126, -5.702600002288818, -5.687300205230713, -5.845300197601318, -5.901100158691406, -6.032199859619141, -6.028800010681152, -4.713699817657471, -4.580399990081787, -3.4791998863220215, -3.6068999767303467, -4.325200080871582, -4.072400093078613, -4.829100131988525, -4.811600208282471, -4.36460018157959, -4.021299839019775, -4.400899887084961, -4.246799945831299, -5.238500118255615, -4.388700008392334, -4.578400135040283, -4.969299793243408, -5.024499893188477, -5.071700096130371, -5.122099876403809, -5.576399803161621, -6.128399848937988, -6.30019998550415, -6.462100028991699, -6.484300136566162, -6.481500148773193, -6.512499809265137, -6.572999954223633, -6.601099967956543, -6.348700046539307, -6.910600185394287, -6.951499938964844, -6.811699867248535, -7.072000026702881, -6.472099781036377, -7.228000164031982, -7.263800144195557, -7.331900119781494, -7.331999778747559, -7.395100116729736, -7.441500186920166, -7.435500144958496, -7.473899841308594, -7.428800106048584, -7.386600017547607, -6.88700008392334, -7.538599967956543, -7.564499855041504, -6.397500038146973, -5.402900218963623, -5.3703999519348145, -6.574100017547607, -7.067800045013428, -6.836599826812744, -7.359899997711182, -5.751500129699707, -6.807400226593018, -3.7298998832702637, -4.66379976272583, -6.1605000495910645, -5.767600059509277, -5.744999885559082, -6.469699859619141, -6.063499927520752, -5.274499893188477, -6.437600135803223, -5.7393999099731445, -3.7711000442504883, -6.097300052642822, -4.05019998550415, -5.118599891662598, -4.678599834442139, -5.34250020980835, -4.3917999267578125, -4.19350004196167, -5.137499809265137, -5.642899990081787, -4.810500144958496, -5.6855998039245605, -5.309800148010254, -5.018599987030029, -5.105400085449219, -5.153800010681152, -4.718400001525879, -4.906000137329102, -4.611999988555908, -5.287499904632568, -5.122600078582764, -4.7378997802734375, -5.0883002281188965, -5.256199836730957, -5.254899978637695, -4.971499919891357, -5.091800212860107, -5.1082000732421875, -5.28410005569458, -2.40339994430542, -3.778899908065796, -4.59630012512207, -4.80019998550415, -4.939199924468994, -5.020500183105469, -5.226200103759766, -5.269700050354004, -5.428599834442139, -5.464200019836426, -5.591300010681152, -5.611400127410889, -5.608399868011475, -5.686999797821045, -5.623499870300293, -5.813899993896484, -5.8246002197265625, -5.833799839019775, -5.843200206756592, -5.843100070953369, -5.730299949645996, -5.896200180053711, -5.886099815368652, -5.958700180053711, -6.005199909210205, -6.018799781799316, -6.02810001373291, -6.108699798583984, -5.6458001136779785, -6.167600154876709, -4.9197001457214355, -5.575099945068359, -3.7920000553131104, -5.019400119781494, -5.647600173950195, -4.237199783325195, -4.161300182342529, -4.930600166320801, -5.127699851989746, -5.176599979400635, -5.1641998291015625, -5.070300102233887, -4.115900039672852, -4.481200218200684, -3.8887999057769775, -4.934500217437744, -5.102200031280518, -4.679599761962891, -4.809800148010254, -4.908299922943115, -3.9904000759124756, -4.996200084686279, -4.7393999099731445, -4.5258002281188965, -4.874800205230713, -5.05109977722168, -4.985599994659424, -5.12939977645874, -2.799999952316284, -4.083899974822998, -4.147799968719482, -4.788400173187256, -4.982500076293945, -5.025899887084961, -5.125899791717529, -4.769899845123291, -5.298699855804443, -5.349800109863281, -5.363100051879883, -5.443699836730957, -5.467800140380859, -5.594299793243408, -5.673699855804443, -5.740200042724609, -5.831099987030029, -5.8821001052856445, -6.0472002029418945, -6.117800235748291, -6.129899978637695, -6.136099815368652, -6.265900135040283, -6.271399974822998, -6.284599781036377, -6.283699989318848, -6.204599857330322, -6.312600135803223, -6.344600200653076, -6.388999938964844, -3.6861000061035156, -4.651700019836426, -2.2795000076293945, -5.220600128173828, -4.140900135040283, -3.552299976348877, -4.054999828338623, -4.94350004196167, -5.153500080108643, -5.620100021362305, -5.895100116729736, -5.296299934387207, -4.359899997711182, -4.35860013961792, -4.92579984664917, -5.089900016784668, -5.028500080108643, -3.927999973297119, -4.197700023651123, -4.909900188446045, -4.945099830627441, -5.069900035858154, -4.90310001373291, -4.976399898529053, -5.005000114440918, -5.015100002288818, -5.117000102996826, -3.9228999614715576, -4.197700023651123, -5.187900066375732, -5.234600067138672, -5.3902997970581055, -5.491000175476074, -5.514999866485596, -5.606500148773193, -5.605899810791016, -5.750199794769287, -5.753200054168701, -5.752500057220459, -5.760200023651123, -5.833499908447266, -5.868299961090088, -5.908400058746338, -5.9085001945495605, -5.79040002822876, -5.972499847412109, -6.004700183868408, -6.04449987411499, -6.047299861907959, -6.056000232696533, -6.0879998207092285, -6.0960001945495605, -6.021999835968018, -6.136000156402588, -6.174200057983398, -6.173600196838379, -6.190000057220459, -5.376999855041504, -5.627699851989746, -5.1774001121521, -5.058599948883057, -4.654799938201904, -5.382500171661377, -4.081299781799316, -3.351099967956543, -4.528600215911865, -5.150199890136719, -4.449900150299072, -5.06220006942749, -4.478000164031982, -4.918900012969971, -4.127099990844727, -5.358500003814697, -5.54010009765625, -4.615600109100342, -5.101099967956543, -5.578800201416016, -5.0630998611450195, -5.246099948883057, -5.29010009765625, -4.964300155639648, -5.270899772644043, -5.330699920654297, -5.008399963378906, -5.449100017547607, -3.447000026702881, -4.437699794769287, -4.665800094604492, -4.545199871063232, -4.355400085449219, -5.386099815368652, -5.36870002746582, -5.455900192260742, -5.702899932861328, -5.765699863433838, -5.878699779510498, -5.974299907684326, -6.053500175476074, -6.046299934387207, -6.044000148773193, -6.064799785614014, -6.072999954223633, -6.13040018081665, -6.100900173187256, -6.043799877166748, -6.100800037384033, -6.276500225067139, -6.293499946594238, -6.330399990081787, -6.32859992980957, -6.350800037384033, -6.345799922943115, -6.407599925994873, -6.429999828338623, -6.390699863433838, -5.3354997634887695, -4.6305999755859375, -5.835400104522705, -5.522500038146973, -5.103899955749512, -4.4629998207092285, -5.096499919891357, -3.374000072479248, -5.104700088500977, -3.7021000385284424, -5.114799976348877, -5.504700183868408, -4.384099960327148, -5.299300193786621, -4.240099906921387, -4.69189977645874, -5.1691999435424805, -5.422699928283691, -4.5467000007629395, -4.984899997711182, -4.86460018157959, -5.135300159454346, -5.104300022125244, -5.033400058746338, -5.118800163269043, -5.068299770355225, -5.154799938201904, -5.197700023651123, -5.166800022125244, -3.54229998588562, -3.899899959564209, -3.999000072479248, -4.249599933624268, -4.34060001373291, -4.627900123596191, -4.737800121307373, -4.8302001953125, -5.072800159454346, -5.0945000648498535, -5.137400150299072, -5.214700222015381, -5.2418999671936035, -5.293900012969971, -5.39109992980957, -5.410699844360352, -5.518599987030029, -4.723100185394287, -5.6616997718811035, -5.746300220489502, -5.759099960327148, -5.770899772644043, -6.1768999099731445, -6.220200061798096, -6.26200008392334, -6.319499969482422, -6.317800045013428, -6.340799808502197, -6.335000038146973, -6.354599952697754, -3.680500030517578, -3.891400098800659, -3.1001999378204346, -5.71019983291626, -5.211999893188477, -4.883900165557861, -5.969799995422363, -3.8966000080108643, -5.131400108337402, -3.8559999465942383, -4.133600234985352, -3.892400026321411, -4.88730001449585, -4.230000019073486, -3.66510009765625, -4.420899868011475, -4.951000213623047, -4.723599910736084, -4.708799839019775, -4.8317999839782715, -4.894700050354004, -4.9095001220703125, -4.953700065612793, -5.0721001625061035, -3.887399911880493, -4.644400119781494, -4.827899932861328, -4.957900047302246, -5.364099979400635, -5.423600196838379, -5.510200023651123, -5.554999828338623, -5.660399913787842, -5.728799819946289, -5.721700191497803, -5.8144001960754395, -5.839300155639648, -5.815999984741211, -5.847599983215332, -5.861499786376953, -5.89300012588501, -6.023200035095215, -6.033299922943115, -6.075500011444092, -6.162099838256836, -6.293700218200684, -6.295300006866455, -6.304500102996826, -6.316299915313721, -6.331399917602539, -6.338699817657471, -6.336400032043457, -6.3491997718811035, -6.3993000984191895, -3.9052999019622803, -5.16480016708374, -4.660299777984619, -4.1508002281188965, -3.6078999042510986, -4.880499839782715, -5.432499885559082, -5.265699863433838, -4.551300048828125, -4.585700035095215, -5.511199951171875, -5.0493998527526855, -5.0243000984191895, -4.632900238037109, -4.635499954223633, -5.489500045776367, -5.475200176239014, -5.119500160217285, -5.145299911499023, -4.62470006942749, -5.342400074005127, -4.767099857330322, -5.208799839019775, -5.069300174713135, -5.304200172424316, -5.228499889373779, -5.246699810028076, -5.368299961090088, -5.345099925994873, -5.134900093078613, -5.927000045776367, -5.95419979095459, -6.688000202178955, -6.802800178527832, -6.952400207519531, -7.0858001708984375, -7.1072001457214355, -7.128699779510498, -7.188199996948242, -7.232999801635742, -7.294099807739258, -7.35699987411499, -7.353700160980225, -7.382299900054932, -7.38670015335083, -7.38070011138916, -7.177800178527832, -7.446100234985352, -7.173900127410889, -7.461900234222412, -7.4359002113342285, -7.496399879455566, -7.519000053405762, -7.529900074005127, -7.057000160217285, -7.503200054168701, -7.507900238037109, -7.32390022277832, -7.62060022354126, -7.17710018157959, -6.933599948883057, -7.448400020599365, -6.833099842071533, -7.386899948120117, -4.12939977645874, -5.343800067901611, -6.023799896240234, -4.913899898529053, -5.839099884033203, -5.990300178527832, -4.519000053405762, -5.009500026702881, -4.387599945068359, -5.186299800872803, -6.474299907684326, -4.109300136566162, -4.933000087738037, -5.145699977874756, -4.344699859619141, -5.562900066375732, -5.476900100708008, -3.734800100326538, -4.747200012207031, -4.685500144958496, -4.803599834442139, -4.9328999519348145, -3.9179999828338623, -4.17110013961792, -5.18179988861084, -4.619200229644775, -3.9941000938415527, -4.633999824523926, -5.095200061798096, -4.713200092315674, -4.928800106048584, -4.316699981689453, -4.259399890899658, -4.732600212097168, -4.58650016784668, -4.708199977874756, -4.55019998550415, -4.504000186920166, -4.94290018081665, -4.967100143432617, -5.064700126647949, -4.25600004196167, -4.827899932861328, -4.732900142669678, -4.876500129699707, -4.98390007019043, -5.00629997253418, -5.014200210571289, -5.155700206756592, -5.599400043487549, -5.606599807739258, -5.6545000076293945, -5.447400093078613, -5.777599811553955, -5.902400016784668, -5.924699783325195, -5.996200084686279, -6.00540018081665, -5.996399879455566, -5.9969000816345215, -5.998199939727783, -6.086400032043457, -6.141499996185303, -6.180200099945068, -6.188600063323975, -6.176199913024902, -6.252699851989746, -6.268400192260742, -6.279099941253662, -6.3282999992370605, -6.382999897003174, -4.7555999755859375, -3.665800094604492, -4.704699993133545, -4.714399814605713, -4.713799953460693, -4.1616997718811035, -4.725800037384033, -4.650000095367432, -4.013899803161621, -2.9052999019622803, -5.579800128936768, -4.573500156402588, -5.34089994430542, -4.970099925994873, -4.651400089263916, -5.3821001052856445, -4.577000141143799, -4.387599945068359, -4.202099800109863, -5.229400157928467, -5.021200180053711, -4.994100093841553, -4.887800216674805, -4.766499996185303, -4.833899974822998, -4.520100116729736, -4.774700164794922, -4.85699987411499, -5.70989990234375, -5.89109992980957, -5.862299919128418, -6.105999946594238, -6.105899810791016, -6.151500225067139, -6.140100002288818, -6.218500137329102, -6.2291998863220215, -6.271299839019775, -6.306099891662598, -6.319799900054932, -6.346099853515625, -6.366700172424316, -6.421500205993652, -6.46619987487793, -6.494900226593018, -6.4721999168396, -6.567699909210205, -6.157899856567383, -6.679599761962891, -6.7153000831604, -6.731900215148926, -6.71019983291626, -6.759500026702881, -6.780600070953369, -6.7881999015808105, -6.800600051879883, -6.796599864959717, -6.811699867248535, -5.950200080871582, -5.133699893951416, -6.46619987487793, -4.816400051116943, -5.579899787902832, -4.016200065612793, -4.954100131988525, -5.592899799346924, -5.300300121307373, -5.2855000495910645, -5.163700103759766, -6.270199775695801, -5.5808000564575195, -4.939799785614014, -5.249899864196777, -4.574999809265137, -3.6963999271392822, -5.223100185394287, -5.2245001792907715, -4.696899890899658, -3.924099922180176, -5.5524001121521, -4.964600086212158, -5.495800018310547, -5.072500228881836, -5.594799995422363, -5.786399841308594, -4.723800182342529, -5.323400020599365, -4.992400169372559, -4.770400047302246, -5.133299827575684, -5.485599994659424, -5.198599815368652, -5.134900093078613, -5.17609977722168, -5.319699764251709, -5.380000114440918, -5.40339994430542, -5.380199909210205, -4.059000015258789, -4.285099983215332, -4.670199871063232, -4.919000148773193, -5.043499946594238, -5.352200031280518, -5.379199981689453, -5.674900054931641, -5.60290002822876, -5.789000034332275, -5.807700157165527, -5.817699909210205, -5.983699798583984, -6.03410005569458, -6.0625, -6.142899990081787, -6.16349983215332, -6.250100135803223, -6.261300086975098, -6.321300029754639, -6.325200080871582, -6.182600021362305, -6.3470001220703125, -6.438600063323975, -6.4405999183654785, -6.467299938201904, -6.4807000160217285, -6.37470006942749, -6.513000011444092, -6.566999912261963, -5.861999988555908, -3.823699951171875, -4.144999980926514, -5.444900035858154, -4.48360013961792, -4.803400039672852, -6.0183000564575195, -4.6778998374938965, -5.201600074768066, -4.7129998207092285, -4.1194000244140625, -5.101200103759766, -4.3572001457214355, -5.218400001525879, -4.323500156402588, -4.3491997718811035, -5.002699851989746, -4.360499858856201, -4.342199802398682, -5.093500137329102, -4.408199787139893, -5.344099998474121, -5.066100120544434, -4.958099842071533, -4.685699939727783, -4.986299991607666, -5.128799915313721, -4.833099842071533, -4.846199989318848, -5.036300182342529, -4.943900108337402, -2.036900043487549, -3.384500026702881, -3.4556000232696533, -3.7207999229431152, -3.725399971008301, -3.77810001373291, -3.7988998889923096, -4.0868000984191895, -4.371600151062012, -4.395299911499023, -4.557000160217285, -4.924699783325195, -4.974400043487549, -5.110099792480469, -5.19789981842041, -5.247900009155273, -5.177599906921387, -5.2846999168396, -5.297599792480469, -5.331099987030029, -5.378200054168701, -5.303199768066406, -5.524799823760986, -5.573699951171875, -5.5640997886657715, -5.831900119781494, -5.856100082397461, -5.888299942016602, -5.9440999031066895, -5.9542999267578125, -2.9791998863220215, -4.6479997634887695, -3.973099946975708, -4.8404998779296875, -4.638400077819824, -4.431700229644775, -4.357100009918213, -4.738900184631348, -4.523399829864502, -4.872000217437744, -4.703499794006348, -4.841899871826172, -5.0833001136779785, -4.688499927520752, -4.707200050354004, -4.957699775695801, -5.1097002029418945, -3.675100088119507, -4.073200225830078, -4.426599979400635, -4.5096001625061035, -4.543700218200684, -4.616300106048584, -4.978000164031982, -5.201900005340576, -5.294400215148926, -5.323699951171875, -5.521200180053711, -5.5619001388549805, -5.602099895477295, -5.6528000831604, -5.791999816894531, -5.810299873352051, -5.843599796295166, -5.902500152587891, -5.924600124359131, -5.952099800109863, -5.973299980163574, -5.978099822998047, -5.984000205993652, -5.997499942779541, -6.040500164031982, -6.087399959564209, -6.125, -6.16349983215332, -6.206299781799316, -6.183700084686279, -4.987199783325195, -4.471399784088135, -4.851200103759766, -4.5065999031066895, -4.787700176239014, -5.400199890136719, -4.840099811553955, -5.2718000411987305, -4.294400215148926, -4.203000068664551, -4.248899936676025, -4.392499923706055, -4.709099769592285, -3.0267999172210693, -3.9333999156951904, -3.982300043106079, -4.288899898529053, -5.172599792480469, -4.817299842834473, -4.384200096130371, -5.0746002197265625, -4.853000164031982, -5.054500102996826, -4.668900012969971, -5.0157999992370605, -5.091599941253662, -4.9857001304626465, -2.7771999835968018, -3.87280011177063, -4.336699962615967, -4.356200218200684, -4.951300144195557, -5.470600128173828, -5.509900093078613, -5.520299911499023, -5.571199893951416, -5.648099899291992, -5.697800159454346, -5.830699920654297, -5.847799777984619, -5.855400085449219, -5.9355998039245605, -5.9394001960754395, -6.004799842834473, -6.018400192260742, -6.06220006942749, -6.1092000007629395, -6.171899795532227, -6.166299819946289, -6.1707000732421875, -6.172299861907959, -6.2093000411987305, -6.2144999504089355, -6.2484002113342285, -6.3155999183654785, -6.353400230407715, -6.357699871063232, -3.9291999340057373, -5.891200065612793, -6.104800224304199, -5.682600021362305, -4.758399963378906, -5.7393999099731445, -5.401700019836426, -3.974900007247925, -3.794800043106079, -3.9876999855041504, -4.286799907684326, -4.857800006866455, -4.347400188446045, -5.138999938964844, -4.3165998458862305, -5.07889986038208, -5.245500087738037, -5.099999904632568, -5.507500171661377, -4.843900203704834, -4.663899898529053, -4.86299991607666, -5.049499988555908, -4.994100093841553, -5.211699962615967, -5.167200088500977, -5.122900009155273, -5.073400020599365, -5.357399940490723, -5.142899990081787, -5.344099998474121, -5.251399993896484, -5.3354997634887695, -5.330699920654297, -2.1768999099731445, -4.212600231170654, -4.3292999267578125, -4.8368000984191895, -4.848700046539307, -4.923999786376953, -4.992000102996826, -4.992800235748291, -4.999899864196777, -5.106900215148926, -5.238500118255615, -5.29010009765625, -5.336699962615967, -5.147799968719482, -5.513199806213379, -5.536399841308594, -5.595399856567383, -5.59250020980835, -5.625, -5.665599822998047, -5.680200099945068, -5.691699981689453, -5.716000080108643, -5.74370002746582, -5.768400192260742, -5.819200038909912, -5.851900100708008, -5.857500076293945, -5.906099796295166, -5.912799835205078, -3.7318999767303467, -5.294400215148926, -3.9386000633239746, -3.242000102996826, -4.031199932098389, -5.153500080108643, -4.131999969482422, -4.4369001388549805, -4.405700206756592, -4.988500118255615, -4.223700046539307, -4.533400058746338, -4.814700126647949, -4.929999828338623, -4.463600158691406, -4.570499897003174, -4.714799880981445, -5.039100170135498, -5.151500225067139, -5.062399864196777, -5.093699932098389, -5.09119987487793, -5.08489990234375, -5.0995001792907715, -4.581200122833252, -4.681399822235107, -4.734099864959717, -5.243199825286865, -5.547599792480469, -5.686800003051758, -5.837399959564209, -6.095799922943115, -6.110899925231934, -6.183800220489502, -6.203800201416016, -6.214200019836426, -6.236800193786621, -6.261199951171875, -6.323699951171875, -6.316400051116943, -6.376500129699707, -6.393499851226807, -6.410200119018555, -6.4770002365112305, -6.51609992980957, -6.517099857330322, -6.5447001457214355, -6.631700038909912, -6.6493000984191895, -6.688600063323975, -6.693399906158447, -6.691199779510498, -6.703999996185303, -6.695899963378906, -5.5980000495910645, -1.9521000385284424, -4.733099937438965, -4.314799785614014, -5.280600070953369, -3.436800003051758, -5.927000045776367, -3.960099935531616, -4.392300128936768, -5.374000072479248, -6.211699962615967, -5.265500068664551, -4.67710018157959, -4.272299766540527, -5.44189977645874, -4.726200103759766, -4.887800216674805, -5.134399890899658, -5.109499931335449, -5.360400199890137, -5.201099872589111, -5.257299900054932, -5.49399995803833, -4.3379998207092285, -4.766499996185303, -5.0406999588012695, -5.102700233459473, -5.185999870300293, -4.870999813079834, -5.1392998695373535, -5.131700038909912, -5.3277997970581055, -5.345200061798096, -4.322199821472168, -5.951200008392334, -6.029799938201904, -6.06220006942749, -6.248499870300293, -6.393099784851074, -6.521500110626221, -6.656099796295166, -6.622600078582764, -6.726900100708008, -6.727499961853027, -6.888599872589111, -7.018099784851074, -7.033299922943115, -7.100800037384033, -7.109499931335449, -7.109799861907959, -7.129700183868408, -7.111199855804443, -7.172500133514404, -7.181300163269043, -7.189300060272217, -7.237100124359131, -7.257999897003174, -7.345399856567383, -7.301799774169922, -7.369500160217285, -7.370699882507324, -7.058899879455566, -6.404699802398682, -6.041600227355957, -4.646599769592285, -4.5279998779296875, -3.3752999305725098, -5.565899848937988, -6.123499870300293, -4.575399875640869, -4.4222002029418945, -5.368299961090088, -3.1986000537872314, -6.147600173950195, -6.84119987487793, -5.573200225830078, -5.122799873352051, -4.098499774932861, -4.001699924468994, -4.847499847412109, -5.208499908447266, -3.621799945831299, -4.231599807739258, -5.274700164794922, -5.396599769592285, -4.710999965667725, -5.271399974822998, -4.546599864959717, -3.9791998863220215, -5.391499996185303, -4.230500221252441, -4.946700096130371, -5.3557000160217285, -5.511600017547607, -4.678899765014648, -4.674799919128418, -4.6859002113342285, -4.650199890136719, -4.936500072479248, -5.27269983291626, -4.985300064086914, -5.136600017547607, -5.154900074005127, -5.271200180053711, -2.140700101852417, -2.8624000549316406, -3.1122000217437744, -3.6280999183654785, -3.7595999240875244, -4.78849983215332, -4.899899959564209, -4.3780999183654785, -5.155200004577637, -5.182000160217285, -5.428100109100342, -5.480800151824951, -5.498499870300293, -5.599699974060059, -5.618899822235107, -5.635900020599365, -5.660699844360352, -5.65939998626709, -5.657800197601318, -5.690999984741211, -5.671800136566162, -5.721799850463867, -5.7368998527526855, -5.770199775695801, -5.776500225067139, -5.8256001472473145, -5.741799831390381, -5.946599960327148, -6.0177998542785645, -6.091000080108643, -4.2434000968933105, -5.434599876403809, -5.42080020904541, -3.623300075531006, -5.019400119781494, -2.4951000213623047, -4.954699993133545, -4.3831000328063965, -2.9052999019622803, -5.015500068664551, -5.106500148773193, -4.736999988555908, -5.400100231170654, -4.821800231933594, -4.441100120544434, -4.610099792480469, -5.406099796295166, -4.98769998550415, -5.329400062561035, -5.322700023651123, -5.308300018310547, -5.4141998291015625], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 3.8626, 3.8626, 3.8626, 3.8625, 3.8625, 3.8625, 3.8624, 3.8624, 3.8624, 3.8624, 3.8624, 3.8624, 3.8623, 3.8623, 3.8623, 3.8623, 3.8623, 3.8623, 3.8623, 3.8623, 3.8623, 3.8623, 3.8622, 3.8622, 3.8622, 3.8622, 3.8622, 3.8622, 3.8622, 3.8621, 3.8621, 3.8532, 3.8398, 3.8169, 3.8291, 3.7303, 3.6895, 3.2784, 3.637, 3.4184, 3.0481, 3.1623, 2.7189, 2.9962, 2.4374, 3.4658, 3.5832, 3.6037, 1.6403, 3.4904, 1.7288, 3.0736, 2.313, 0.6442, 1.9857, 1.8256, 3.6163, 3.6163, 3.6163, 3.6163, 3.6163, 3.6163, 3.6163, 3.6162, 3.6162, 3.6162, 3.6162, 3.6162, 3.6162, 3.6162, 3.6162, 3.6162, 3.6162, 3.6162, 3.6161, 3.6161, 3.6161, 3.6161, 3.6161, 3.6161, 3.6161, 3.6161, 3.6161, 3.616, 3.616, 3.616, 3.616, 3.4998, 3.4685, 3.2859, 3.2236, 3.3131, 3.2465, 3.2635, 3.2439, 2.761, 2.2313, 2.6106, 1.548, 3.4138, 1.3345, 1.7076, 0.7459, 1.0664, 1.024, 1.7502, 1.7502, 1.7501, 1.7501, 1.7501, 1.7501, 1.7501, 1.7501, 1.7501, 1.7501, 1.7501, 1.7501, 1.7501, 1.7501, 1.75, 1.75, 1.75, 1.75, 1.75, 1.75, 1.75, 1.75, 1.75, 1.75, 1.75, 1.75, 1.7499, 1.7499, 1.7499, 1.7499, 1.748, 1.735, 1.7455, 1.7498, 1.7464, 1.7499, 1.7187, 1.7177, 1.421, 1.503, 1.6443, 1.5966, 1.5626, 1.6559, 1.5711, 1.4197, 1.6377, 1.4801, 1.0105, 1.5474, 0.952, 1.2351, 1.0689, 1.2857, 0.913, 0.8281, 1.189, 1.3797, 1.0172, 1.395, 1.2069, 1.0518, 1.0629, 1.0716, 0.7431, 0.831, 0.5675, 1.0408, 0.8319, 0.3796, 0.7549, 0.843, 0.8219, 0.2222, 0.2151, 0.1745, 0.4728, 3.4156, 3.4155, 3.4155, 3.4155, 3.4155, 3.4155, 3.4154, 3.4154, 3.4154, 3.4154, 3.4154, 3.4154, 3.4154, 3.4153, 3.4153, 3.4153, 3.4153, 3.4153, 3.4153, 3.4153, 3.4153, 3.4153, 3.4153, 3.4153, 3.4153, 3.4153, 3.4153, 3.4152, 3.4152, 3.4152, 3.4085, 3.406, 3.3402, 3.2909, 3.3599, 3.0203, 2.9588, 3.0913, 3.1513, 3.1685, 3.0924, 3.042, 2.4602, 2.5204, 1.9233, 2.7097, 2.8515, 2.3607, 2.4612, 2.4505, 1.1439, 2.4466, 1.8754, 1.1894, 0.8484, 1.5387, 0.7619, 0.6603, 3.5702, 3.5701, 3.5701, 3.5701, 3.57, 3.57, 3.57, 3.57, 3.57, 3.57, 3.57, 3.57, 3.57, 3.5699, 3.5699, 3.5699, 3.5699, 3.5699, 3.5698, 3.5698, 3.5698, 3.5698, 3.5697, 3.5697, 3.5697, 3.5697, 3.5697, 3.5697, 3.5697, 3.5696, 3.4859, 3.4738, 3.2117, 3.4654, 3.2859, 3.1452, 3.1997, 3.3407, 3.3728, 3.4438, 3.5035, 3.3223, 2.9449, 2.7044, 2.9157, 2.9779, 2.7746, 1.379, 1.4126, 2.3633, 2.3482, 2.3137, 1.4076, 0.541, 0.7898, 0.7971, 0.9533, 3.3256, 3.3256, 3.3255, 3.3255, 3.3255, 3.3254, 3.3254, 3.3254, 3.3254, 3.3254, 3.3254, 3.3254, 3.3254, 3.3254, 3.3254, 3.3254, 3.3253, 3.3253, 3.3253, 3.3253, 3.3253, 3.3253, 3.3253, 3.3253, 3.3253, 3.3253, 3.3253, 3.3253, 3.3253, 3.3253, 3.3209, 3.3159, 3.3021, 3.2758, 3.1629, 3.2351, 3.0045, 2.6458, 2.9159, 3.0321, 2.7773, 2.9578, 2.4074, 2.6795, 1.6677, 2.8162, 2.9998, 1.5526, 2.1088, 3.0011, 1.9595, 2.2386, 2.265, 1.1151, 1.7703, 2.0529, 0.2986, 1.8348, 3.0244, 3.0244, 3.0244, 3.0244, 3.0243, 3.0243, 3.0243, 3.0243, 3.0243, 3.0242, 3.0242, 3.0242, 3.0242, 3.0242, 3.0242, 3.0242, 3.0242, 3.0242, 3.0242, 3.0242, 3.0242, 3.0241, 3.0241, 3.0241, 3.0241, 3.0241, 3.0241, 3.0241, 3.0241, 3.0241, 3.0202, 3.0053, 3.0172, 3.006, 2.9803, 2.8364, 2.8921, 2.6481, 2.8677, 2.6126, 2.8578, 2.885, 2.5296, 2.7929, 2.3344, 2.3492, 2.5489, 2.6089, 1.8097, 2.0168, 1.7143, 1.8681, 1.8093, 1.443, 1.4573, 0.066, -0.0373, 0.2591, -0.3852, 3.6603, 3.6602, 3.6602, 3.6602, 3.6602, 3.6602, 3.6602, 3.6602, 3.6601, 3.6601, 3.6601, 3.6601, 3.6601, 3.6601, 3.6601, 3.6601, 3.66, 3.66, 3.66, 3.66, 3.66, 3.66, 3.6598, 3.6598, 3.6598, 3.6598, 3.6598, 3.6598, 3.6597, 3.6597, 3.6066, 3.6107, 3.491, 3.625, 3.585, 3.5263, 3.6171, 3.2304, 3.4467, 3.144, 2.984, 2.8231, 3.2587, 2.833, 1.4858, 2.0957, 2.6786, 2.1302, 1.1637, 1.6666, 1.0847, 0.7008, 0.3533, 0.3894, 3.2348, 3.2348, 3.2348, 3.2348, 3.2347, 3.2347, 3.2347, 3.2347, 3.2347, 3.2347, 3.2347, 3.2347, 3.2347, 3.2347, 3.2347, 3.2347, 3.2346, 3.2346, 3.2346, 3.2346, 3.2346, 3.2345, 3.2345, 3.2345, 3.2345, 3.2345, 3.2345, 3.2345, 3.2345, 3.2345, 3.2306, 3.2342, 3.164, 3.1156, 3.0505, 3.1307, 3.1698, 3.0045, 2.797, 2.7623, 3.0319, 2.8033, 2.6755, 2.435, 2.404, 2.8023, 2.6889, 1.9868, 1.8581, 0.658, 2.1809, 0.5399, 1.7977, 0.1245, 1.4812, 0.3818, 0.5102, 1.0069, -0.2276, 1.8551, 1.855, 1.855, 1.855, 1.8549, 1.8549, 1.8549, 1.8549, 1.8549, 1.8549, 1.8549, 1.8549, 1.8549, 1.8549, 1.8548, 1.8548, 1.8548, 1.8548, 1.8548, 1.8548, 1.8548, 1.8548, 1.8548, 1.8548, 1.8548, 1.8548, 1.8548, 1.8548, 1.8548, 1.8548, 1.854, 1.8502, 1.8548, 1.8363, 1.8502, 1.6603, 1.7322, 1.7401, 1.638, 1.7155, 1.7265, 1.5719, 1.6052, 1.5085, 1.6055, 1.7469, 1.4406, 1.5419, 1.5661, 1.4467, 1.617, 1.5794, 1.2868, 1.4542, 1.4258, 1.4481, 1.4661, 1.2614, 1.3008, 1.4778, 1.3509, 1.1402, 1.2296, 1.2879, 1.0989, 1.1948, 0.8008, 0.7429, 1.0043, 0.8755, 0.7486, 0.5173, 0.2776, 0.8729, 0.3399, 0.6829, 3.1772, 3.1772, 3.1772, 3.1772, 3.1772, 3.1772, 3.1772, 3.1772, 3.1771, 3.1771, 3.1771, 3.1771, 3.1771, 3.1771, 3.1771, 3.177, 3.177, 3.177, 3.177, 3.177, 3.177, 3.177, 3.177, 3.177, 3.177, 3.177, 3.177, 3.177, 3.177, 3.1769, 3.1612, 2.9538, 3.0339, 2.9911, 2.9854, 2.8837, 2.924, 2.852, 2.6178, 2.2885, 3.0333, 2.5385, 2.8793, 2.6709, 2.4661, 2.825, 2.1322, 1.9661, 1.5926, 2.6376, 2.1886, 2.1366, 1.8367, 1.3292, 1.4066, 0.2615, 0.5323, 0.6342, 2.8589, 2.8589, 2.8589, 2.8588, 2.8588, 2.8588, 2.8588, 2.8588, 2.8588, 2.8588, 2.8588, 2.8588, 2.8588, 2.8588, 2.8588, 2.8588, 2.8588, 2.8587, 2.8587, 2.8587, 2.8587, 2.8587, 2.8587, 2.8587, 2.8587, 2.8587, 2.8587, 2.8587, 2.8587, 2.8586, 2.8581, 2.8253, 2.8506, 2.7649, 2.7872, 2.6853, 2.726, 2.75, 2.7114, 2.6764, 2.6303, 2.8059, 2.6266, 2.4072, 2.4809, 2.1513, 1.7755, 2.2826, 2.2567, 1.8917, 1.2697, 2.3109, 1.7543, 2.2128, 1.6406, 2.2208, 2.4295, 0.9914, 1.8101, 1.2481, 0.8399, 1.3089, 1.9342, 0.8808, 0.322, 0.1309, 0.6596, 0.7157, 0.6735, -0.2293, 3.4541, 3.4541, 3.454, 3.454, 3.454, 3.4539, 3.4539, 3.4539, 3.4539, 3.4539, 3.4539, 3.4538, 3.4538, 3.4538, 3.4538, 3.4538, 3.4537, 3.4537, 3.4537, 3.4537, 3.4537, 3.4537, 3.4537, 3.4536, 3.4536, 3.4536, 3.4536, 3.4536, 3.4536, 3.4536, 3.4535, 3.1828, 3.1696, 3.3075, 3.1492, 3.1564, 3.3768, 2.9936, 3.0831, 2.8671, 2.6346, 2.9272, 2.5563, 2.9523, 2.2554, 2.1759, 2.5983, 2.0098, 1.9913, 2.6062, 1.8323, 2.8093, 2.3767, 1.8273, 1.1264, 1.6721, 1.9089, 0.3178, 0.3476, 1.2997, -0.1623, 4.0954, 4.0953, 4.0953, 4.0953, 4.0953, 4.0953, 4.0953, 4.0953, 4.0952, 4.0952, 4.0952, 4.0952, 4.0952, 4.0951, 4.0951, 4.0951, 4.0951, 4.0951, 4.0951, 4.0951, 4.095, 4.095, 4.095, 4.095, 4.095, 4.0949, 4.0949, 4.0948, 4.0948, 4.0948, 4.0746, 4.0526, 3.9433, 3.9553, 3.7063, 2.9626, 2.6079, 2.9893, 1.8469, 2.6332, 1.9561, 2.1957, 3.2132, 1.266, 0.7496, 2.3624, 2.1613, 3.2867, 3.2867, 3.2867, 3.2867, 3.2867, 3.2867, 3.2867, 3.2866, 3.2866, 3.2866, 3.2866, 3.2866, 3.2866, 3.2866, 3.2866, 3.2865, 3.2865, 3.2865, 3.2865, 3.2865, 3.2865, 3.2865, 3.2865, 3.2865, 3.2865, 3.2865, 3.2865, 3.2865, 3.2864, 3.2864, 3.2758, 3.2487, 3.1763, 3.1321, 3.1566, 3.1934, 3.091, 3.1141, 2.8639, 2.7027, 2.7018, 2.7331, 2.8017, 2.0267, 2.4043, 2.3694, 2.3352, 2.8118, 2.3936, 1.5951, 2.557, 1.8625, 2.3259, 0.8223, 1.7105, 1.9942, 0.4862, 3.0685, 3.0685, 3.0685, 3.0685, 3.0684, 3.0684, 3.0684, 3.0684, 3.0684, 3.0684, 3.0684, 3.0683, 3.0683, 3.0683, 3.0683, 3.0683, 3.0683, 3.0683, 3.0683, 3.0683, 3.0683, 3.0683, 3.0683, 3.0683, 3.0683, 3.0682, 3.0682, 3.0682, 3.0682, 3.0682, 3.0149, 3.0392, 3.0506, 3.0019, 2.8433, 2.9916, 2.8401, 2.2777, 2.2021, 2.2422, 2.3315, 2.4154, 2.0044, 2.3568, 1.3986, 1.9211, 2.0571, 1.7897, 2.3954, 0.9509, 0.4869, 0.8602, 1.2365, 0.9853, 1.4124, 1.0733, 0.7496, 0.3834, 1.7289, -0.3613, 1.6044, 0.0534, 1.3855, -0.3284, 3.818, 3.8179, 3.8179, 3.8178, 3.8178, 3.8178, 3.8178, 3.8178, 3.8178, 3.8178, 3.8178, 3.8177, 3.8177, 3.8177, 3.8177, 3.8177, 3.8177, 3.8177, 3.8177, 3.8176, 3.8176, 3.8176, 3.8176, 3.8176, 3.8176, 3.8176, 3.8176, 3.8176, 3.8176, 3.8176, 3.6963, 3.7595, 3.4244, 3.2564, 3.3589, 3.5467, 2.8795, 2.9778, 2.9099, 3.1653, 1.9777, 2.3204, 2.6725, 2.706, 1.789, 1.7997, 1.5999, 2.7006, 3.0447, 1.8511, 1.959, 0.8633, 0.3766, 0.2053, 3.4349, 3.4349, 3.4349, 3.4349, 3.4348, 3.4348, 3.4347, 3.4347, 3.4347, 3.4346, 3.4346, 3.4346, 3.4346, 3.4346, 3.4346, 3.4346, 3.4346, 3.4346, 3.4345, 3.4345, 3.4345, 3.4345, 3.4345, 3.4344, 3.4344, 3.4344, 3.4344, 3.4344, 3.4344, 3.4344, 3.4045, 3.1014, 3.2613, 3.2071, 3.2368, 2.9009, 3.3088, 2.9254, 2.8996, 3.1381, 3.3346, 2.9658, 2.3631, 2.1029, 2.8299, 2.3458, 2.2457, 2.4252, 2.3624, 2.5933, 2.4306, 2.2978, 2.5813, 0.8558, 1.3291, 1.5789, 1.6103, 1.3929, -0.0894, 1.0862, 0.9478, 1.3736, 1.097, 2.211, 2.2109, 2.2109, 2.2109, 2.2109, 2.2109, 2.2109, 2.2108, 2.2108, 2.2108, 2.2108, 2.2108, 2.2108, 2.2108, 2.2107, 2.2107, 2.2107, 2.2107, 2.2107, 2.2107, 2.2107, 2.2107, 2.2107, 2.2107, 2.2107, 2.2107, 2.2107, 2.2107, 2.2107, 2.2106, 2.2087, 2.1917, 2.1658, 2.142, 2.1853, 2.1622, 2.0774, 2.0548, 2.1058, 1.8689, 2.0974, 2.1794, 2.0203, 1.947, 1.774, 1.7552, 1.8794, 1.9326, 1.6609, 1.7171, 1.8831, 1.8572, 1.5997, 1.7293, 1.4328, 1.1551, 1.7693, 1.2315, 1.5297, 1.6827, 1.763, 0.9314, 0.7867, 0.771, 0.6546, 1.018, 1.4483, 0.1322, 0.4133, -0.3733, 0.828, 4.1131, 4.1131, 4.1131, 4.113, 4.113, 4.1129, 4.1129, 4.1129, 4.1128, 4.1128, 4.1128, 4.1127, 4.1127, 4.1127, 4.1127, 4.1127, 4.1127, 4.1127, 4.1127, 4.1127, 4.1126, 4.1126, 4.1126, 4.1126, 4.1126, 4.1126, 4.1126, 4.1125, 4.1125, 4.1124, 3.9186, 4.0389, 4.0126, 3.627, 3.9241, 3.317, 3.8682, 3.6204, 2.938, 3.5005, 3.5652, 2.6792, 3.7072, 2.7552, 0.8637, 0.8514, 3.1572, 0.8848, 2.3702, 1.8392, 1.4662, 1.6721]}, \"token.table\": {\"Topic\": [3, 19, 19, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 1, 2, 5, 6, 9, 10, 15, 16, 2, 2, 6, 12, 15, 15, 10, 6, 1, 6, 1, 5, 6, 8, 9, 12, 15, 18, 19, 6, 5, 14, 7, 9, 7, 17, 4, 10, 19, 8, 1, 2, 3, 4, 5, 6, 7, 9, 10, 13, 15, 16, 18, 15, 3, 10, 14, 17, 18, 20, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 19, 3, 5, 6, 7, 8, 9, 11, 12, 15, 16, 17, 18, 19, 5, 8, 9, 8, 1, 3, 4, 6, 9, 10, 14, 15, 17, 3, 5, 7, 8, 10, 11, 15, 19, 3, 5, 9, 11, 19, 4, 7, 10, 11, 14, 14, 3, 12, 15, 3, 19, 3, 6, 7, 11, 20, 20, 1, 3, 1, 13, 2, 3, 4, 5, 6, 8, 9, 10, 12, 14, 15, 16, 18, 4, 9, 18, 1, 5, 6, 18, 2, 1, 3, 5, 9, 19, 13, 15, 2, 8, 14, 2, 15, 1, 3, 5, 6, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 1, 2, 3, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 10, 10, 10, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 8, 20, 2, 3, 6, 11, 12, 13, 18, 17, 20, 17, 12, 19, 17, 2, 3, 6, 10, 12, 14, 15, 19, 14, 13, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 12, 5, 7, 10, 11, 13, 17, 13, 18, 1, 10, 16, 17, 19, 3, 10, 12, 16, 17, 20, 20, 10, 13, 10, 14, 4, 7, 10, 13, 14, 5, 10, 20, 8, 13, 1, 15, 5, 16, 16, 18, 3, 6, 8, 8, 20, 12, 13, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 16, 17, 18, 19, 4, 5, 15, 16, 16, 5, 11, 18, 2, 3, 7, 10, 11, 13, 14, 16, 1, 16, 1, 12, 15, 16, 13, 18, 13, 6, 18, 1, 11, 3, 5, 6, 9, 10, 12, 18, 16, 9, 9, 17, 14, 20, 19, 7, 10, 2, 3, 4, 5, 7, 9, 10, 11, 13, 14, 16, 17, 19, 1, 7, 10, 11, 13, 17, 5, 11, 13, 19, 5, 19, 3, 4, 1, 9, 13, 13, 6, 18, 19, 17, 20, 9, 16, 2, 16, 17, 4, 2, 2, 6, 6, 6, 8, 14, 14, 14, 10, 1, 6, 8, 15, 16, 17, 18, 3, 6, 18, 6, 6, 1, 2, 3, 4, 9, 10, 13, 18, 4, 13, 3, 7, 9, 12, 18, 3, 4, 10, 13, 14, 16, 17, 19, 8, 8, 2, 8, 8, 7, 1, 3, 7, 10, 12, 13, 19, 1, 3, 7, 10, 12, 13, 19, 1, 3, 5, 12, 3, 4, 7, 10, 12, 13, 15, 3, 9, 11, 13, 2, 7, 8, 11, 12, 13, 15, 16, 11, 15, 4, 14, 4, 18, 4, 18, 14, 2, 4, 7, 10, 13, 15, 16, 4, 7, 10, 14, 16, 1, 1, 3, 4, 7, 9, 10, 13, 17, 6, 20, 19, 5, 6, 9, 3, 8, 12, 15, 13, 8, 17, 7, 16, 15, 18, 2, 15, 1, 3, 4, 9, 12, 9, 17, 17, 2, 2, 5, 11, 12, 16, 3, 6, 12, 4, 19, 20, 1, 1, 16, 16, 13, 13, 4, 17, 6, 3, 4, 15, 17, 17, 9, 3, 5, 6, 11, 12, 15, 19, 5, 20, 5, 5, 20, 3, 20, 15, 3, 6, 10, 11, 13, 19, 3, 6, 9, 16, 17, 4, 7, 19, 19, 1, 3, 4, 9, 11, 13, 4, 7, 10, 14, 16, 17, 18, 17, 18, 15, 16, 14, 1, 2, 3, 8, 9, 11, 12, 15, 16, 17, 18, 19, 11, 12, 14, 16, 17, 7, 11, 19, 3, 8, 15, 16, 17, 19, 5, 8, 18, 19, 3, 3, 1, 3, 8, 12, 15, 13, 8, 9, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 7, 18, 7, 17, 7, 12, 4, 11, 17, 2, 7, 11, 12, 16, 20, 3, 7, 9, 11, 13, 17, 18, 12, 4, 4, 11, 15, 17, 18, 2, 1, 2, 3, 8, 10, 15, 16, 18, 19, 11, 16, 17, 18, 11, 6, 12, 16, 6, 9, 1, 2, 3, 6, 10, 13, 16, 1, 2, 3, 10, 13, 16, 19, 16, 3, 5, 7, 8, 9, 19, 20, 1, 2, 12, 15, 18, 13, 1, 2, 3, 4, 5, 6, 9, 10, 12, 15, 16, 18, 19, 1, 6, 4, 18, 6, 8, 9, 11, 12, 16, 18, 5, 8, 15, 19, 2, 6, 12, 15, 16, 19, 1, 10, 15, 17, 19, 7, 18, 20, 18, 20, 4, 9, 18, 20, 10, 1, 2, 5, 9, 10, 13, 16, 17, 8, 12, 19, 15, 15, 15, 15, 3, 9, 1, 11, 12, 10, 7, 2, 13, 18, 17, 8, 11, 14, 16, 17, 19, 17, 14, 17, 8, 11, 14, 19, 8, 11, 16, 16, 19, 14, 14, 4, 1, 3, 4, 6, 8, 10, 12, 15, 16, 17, 18, 8, 10, 3, 6, 9, 12, 3, 4, 6, 10, 13, 14, 15, 12, 1, 3, 9, 15, 16, 17, 18, 19, 3, 5, 12, 19, 5, 9, 5, 9, 3, 4, 5, 6, 5, 4, 6, 10, 12, 14, 15, 16, 19, 4, 16, 16, 1, 15, 3, 5, 9, 18, 19, 1, 6, 8, 16, 3, 5, 6, 7, 11, 12, 17, 20, 3, 8, 6, 4, 7, 10, 11, 13, 16, 17, 13, 17, 1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 7, 13, 4, 4, 12, 15, 18, 12, 2, 1, 2, 3, 4, 6, 7, 9, 10, 11, 13, 16, 18, 7, 10, 13, 2, 9, 15, 18, 10, 9, 13, 11, 8, 9, 8, 16, 8, 16, 18, 20, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 8, 9, 2, 7, 10, 11, 14, 19, 11, 2, 12, 17, 2, 3, 14, 16, 14, 20, 2, 7, 14, 2, 12, 12, 12, 8, 2, 3, 4, 7, 9, 10, 11, 13, 16, 17, 6, 12, 11, 9, 4, 11, 4, 12, 15, 1, 6, 7, 17, 18, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 17, 13, 16, 8, 18, 1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 20, 14, 19, 1, 6, 11, 18, 3, 5, 8, 10, 12, 15, 16, 17, 19, 17, 10, 5, 15, 20, 2, 3, 6, 9, 10, 11, 13, 18, 1, 3, 5, 6, 8, 9, 10, 11, 12, 15, 16, 18, 19, 20, 4, 3, 5, 6, 12, 18, 1, 10, 19, 1, 2, 4, 6, 10, 16, 5, 19, 11, 6, 12, 15, 16, 18, 8, 1, 3, 9, 12, 19, 6, 2, 3, 5, 6, 9, 11, 12, 16, 18, 7, 11, 18, 9, 11, 4, 10, 11, 13, 16, 17, 6, 12, 18, 19, 1, 2, 3, 5, 6, 9, 11, 16, 18, 1, 5, 7, 8, 9, 10, 16, 3, 9, 10, 13, 19, 18, 3, 7, 3, 6, 20, 6, 3, 6, 12, 18, 18, 3, 16, 16, 16, 6, 15, 18, 19, 4, 7, 7, 15, 3, 6, 15, 19, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 15, 13, 2, 7, 11, 16, 19, 1, 6, 5, 10, 1, 3, 5, 6, 8, 10, 15, 18, 19, 1, 3, 6, 9, 10, 11, 16, 19, 1, 3, 4, 7, 10, 11, 13, 14, 16, 17, 18, 19, 11, 9, 9, 13, 3, 4, 5, 6, 8, 10, 11, 12, 16, 17, 18, 19, 11, 2, 3, 6, 10, 12, 13, 20, 11, 20, 17, 1, 6, 7, 8, 11, 13, 18, 12, 15, 16, 18, 20, 17, 17, 18, 19, 19, 19, 4, 10, 17, 18, 10, 2, 3, 5, 6, 8, 9, 12, 13, 15, 16, 18, 3, 15, 7, 8, 10, 13, 14, 16, 17, 9, 2, 6, 15, 16, 18, 12, 15, 1, 4, 7, 10, 12, 13, 18, 19, 2, 10, 14, 10, 9, 13, 1, 2, 3, 4, 6, 10, 12, 15, 17, 18, 5, 8, 12, 15, 16, 17, 19, 17, 17, 14, 19, 14, 15, 16, 17, 14, 10, 15, 9, 19, 5, 4, 5, 7, 10, 11, 13, 17, 20, 6, 2, 11, 11, 7, 9, 16, 9, 7, 4, 14, 4, 10, 11, 14, 15, 16, 17, 19, 14, 19, 17, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 16, 18, 19, 5, 6, 11, 18, 1, 8, 3, 6, 9, 12, 15, 18, 3, 5, 6, 12, 15, 1, 10, 12, 17, 20, 1, 2, 16, 17, 18, 17, 5, 7, 11, 19, 3, 18, 16, 14, 14, 2, 4, 10, 14, 15, 16, 17, 19, 5, 10, 19, 14, 15, 15, 15, 13, 1, 3, 9, 11, 12, 13, 18, 1, 19, 11, 11, 11, 11, 3, 4, 5, 6, 9, 10, 15, 18, 19, 20, 4, 1, 2, 3, 5, 12, 13, 15, 16, 19, 2, 3, 5, 8, 9, 10, 12, 15, 16, 18, 19, 16, 16, 15, 1, 7, 16, 7, 8, 11, 2, 2, 3, 4, 7, 9, 10, 11, 13, 18, 9, 5, 10, 10, 15, 18, 18, 18, 12, 1, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 15, 18, 8, 11, 16, 17, 1, 12, 14, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 20, 8, 11, 17, 1, 10, 11, 19, 1, 2, 3, 6, 9, 10, 11, 13, 16, 18, 19, 1, 4, 7, 9, 11, 13, 1, 3, 5, 8, 9, 12, 15, 16, 19, 20, 4, 4, 4, 14, 3, 4, 6, 8, 10, 12, 14, 15, 16, 18, 19, 5, 13, 5, 19, 2, 3, 6, 8, 10, 11, 12, 18, 19, 1, 16, 14, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 6, 10, 19, 18, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 18, 19, 9, 6, 7, 12, 13, 19, 18, 8, 2, 7, 8, 10, 14, 15, 16, 17, 19, 16, 19, 19, 14, 18, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 3, 6, 18, 3, 5, 13, 1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 18, 19, 16, 16, 11, 16, 7, 3, 5, 8, 9, 10, 11, 12, 16, 17, 19, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 19, 3, 15, 7, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 3, 4, 12, 13, 16, 17, 4, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 17, 17, 9, 13, 4, 19, 1, 6, 4, 9, 17, 5, 8, 4, 15, 18, 2, 5, 9, 10, 12, 18, 20, 2, 7, 5, 19, 5, 6, 8, 12, 15, 16, 17, 19, 12, 8, 12, 16, 12, 14, 1, 12, 2, 11, 4, 3, 4, 4, 4, 12, 3, 6, 12, 2, 3, 4, 5, 7, 10, 11, 12, 15, 16, 19, 12, 18, 17, 17, 4, 4, 7, 10, 4, 10, 3, 6, 12, 10, 7, 8, 10, 11, 12, 13, 15, 16, 18, 16, 15, 18, 16, 12, 6, 11, 12, 18, 19, 6, 9, 1, 3, 4, 5, 7, 9, 10, 11, 12, 13, 15, 17, 19, 2, 3, 7, 1, 5, 6, 1, 6, 11, 13, 10, 11, 14, 15, 16, 17, 10, 2, 3, 4, 7, 10, 14, 19, 3, 11, 12, 13, 18, 3, 5, 8, 9, 12, 12, 9, 14, 3, 7, 9, 14, 19, 3, 5, 7, 1, 4, 13, 14, 1, 3, 4, 7, 8, 9, 10, 11, 13, 17, 18, 1, 9, 15, 16, 18, 19, 1, 5, 8, 15, 16, 17, 19, 20, 13, 1, 15, 1, 2, 4, 7, 10, 13, 14, 6, 6, 8, 8, 9, 3, 13, 16, 1, 7, 14, 5, 9, 10, 18, 19, 2, 8, 19, 8, 10, 11, 16, 17, 18, 10, 13, 7, 6, 11, 2, 5, 8, 11, 12, 15, 16, 17, 18, 19, 8, 10, 14, 15, 16, 7, 2, 13, 12, 3, 4, 5, 7, 10, 11, 12, 15, 18, 19, 12, 15, 3, 6, 18, 19, 9, 16, 1, 3, 6, 7, 8, 10, 11, 14, 18, 19, 20, 20, 1, 3, 4, 7, 8, 10, 11, 13, 14, 16, 17, 18, 19, 20, 5, 6, 1, 2, 4, 8, 13, 2, 4, 5, 7, 16, 18, 1, 5, 11, 14, 4, 13, 17, 18, 19, 6, 9, 11, 13, 18, 3, 20, 20, 10, 16, 9, 2, 16, 9, 4, 5, 7, 9, 11, 3, 5, 6, 20, 1, 3, 6, 9, 15, 8, 2, 6, 8, 11, 12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 5, 6, 9, 13, 3, 6, 13, 8, 1, 6, 14, 5, 3, 13, 1, 15, 18, 18, 15, 15, 10, 5, 6, 9, 11, 13, 18, 20, 10, 5, 5, 8, 11, 19, 8, 10, 19, 10, 17, 4, 5, 12, 16, 18, 19, 18, 5, 12, 15, 9, 1, 2, 7, 8, 15, 16, 17, 19, 6, 10, 19, 2, 5, 1, 1, 1, 5, 2, 11, 16, 19, 9, 9, 13, 14, 8, 8, 9, 5, 8, 10, 11, 17, 3, 6, 15, 5, 3, 4, 5, 7, 9, 10, 11, 13, 19, 7, 12, 19, 4, 4, 3, 16, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 1, 2, 4, 7, 10, 13, 14, 15, 16, 17, 18, 19, 2, 3, 4, 7, 8, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 1, 2, 3, 6, 7, 9, 13, 2, 8, 16, 8, 1, 5, 5, 9, 11, 18, 19, 18, 8, 12, 15, 16, 17, 18, 19, 16, 1, 2, 3, 5, 8, 9, 10, 11, 12, 15, 16, 18, 19, 7, 4, 10, 12, 14, 17, 18, 20, 15, 5, 15, 7, 16, 6, 18, 6, 18, 19, 3, 3, 4, 3, 7, 10, 15, 19, 10, 2, 3, 5, 9, 15, 2, 3, 5, 7, 10, 11, 12, 13, 16, 17, 19, 10, 10, 7, 8, 11, 11, 5, 8, 16, 18, 17, 3, 9, 13, 7, 15, 2, 9, 10, 12, 15, 19, 7, 12, 7, 12, 9, 7, 15, 1, 2, 3, 11, 12, 13, 16, 18, 19, 15, 2, 5, 6, 11, 16, 5, 9, 11, 12, 18, 14, 11, 1, 3, 10, 15, 2, 3, 6, 12, 15, 18, 19, 8, 15, 20, 15, 3, 5, 7, 8, 9, 10, 11, 12, 13, 17, 18, 19, 6, 2, 3, 4, 7, 10, 11, 12, 13, 14, 16, 17, 18, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 4, 18, 17, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 3, 5, 6, 7, 9, 10, 11, 13, 15, 18, 19, 2, 7, 8, 10, 15, 16, 7, 2, 7, 10, 16, 17, 16, 1, 20, 19, 17, 3, 6, 11, 12, 18, 18, 12, 9, 10, 13, 16, 17, 7, 1, 12, 1, 9, 3, 7, 8, 9, 12, 13, 15, 16, 3, 5, 9, 19, 15, 3, 1, 3, 5, 8, 9, 10, 14, 15, 16, 17, 19, 20, 3, 6, 15, 12, 5, 6, 9, 11, 4, 9, 3, 12, 19, 20, 20, 5, 9, 20, 1, 2, 6, 8, 9, 10, 12, 14, 16, 17, 18, 19, 20, 1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 1, 4, 7, 13, 14, 1, 3, 7, 9, 11, 13, 1, 4, 17, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 9, 15, 16, 18, 14, 4, 8, 10, 12, 15, 16, 11, 9, 3, 3, 9, 18, 3, 6, 10, 12, 15, 18, 1, 18, 8, 2, 2, 15, 18, 7, 12, 8, 7, 7, 9, 2, 15, 2, 16, 3, 10, 7, 1, 12, 13, 13, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2, 3, 5, 6, 7, 9, 10, 11, 13, 17, 18, 12, 11, 4, 10, 3, 5, 9, 1, 14, 14, 6, 1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 15, 16, 17, 19, 1, 3, 5, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 3, 5, 6, 15, 16, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 12, 7, 10, 11, 13, 19, 7, 16, 19, 5, 1, 3, 5, 9, 4, 12, 15, 12, 20, 13, 9, 5, 18, 1, 3, 4, 5, 6, 7, 10, 12, 13, 14, 17, 20, 10, 11, 7, 2, 7, 10, 13, 16, 1, 9, 15, 16, 18, 19, 6, 4, 10, 17, 18, 19, 1, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 15, 16, 17, 18, 19, 1, 2, 3, 4, 6, 7, 9, 10, 11, 12, 14, 15, 16, 18, 19, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2, 1, 2, 4, 6, 10, 14, 4, 10, 3, 6, 3, 12, 15, 15, 15, 9, 13, 1, 2, 3, 5, 7, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 14, 3, 3, 5, 6, 9, 18, 19, 10, 10, 3, 6, 20], \"Freq\": [1.000099122430693, 0.9996864301311345, 1.0004808852517721, 0.0002662285351797952, 0.013229510286626747, 0.4772658471050098, 0.0022117447538013758, 0.0031128259497945287, 0.005795590419683234, 0.03305329659847611, 0.0026213271156164454, 0.010956328178553111, 0.2064909477090673, 0.05416726735004295, 0.009502310794109613, 0.026889082053159315, 0.0001843120628167813, 0.009051770196113038, 0.032397964819572, 0.007802543992577075, 0.029469450932594253, 0.07544507104633581, 0.00012287470854452086, 0.04695837020461444, 0.05369991840230662, 0.04114669072384533, 0.17179324545153501, 0.007206482556153701, 0.020689578951538046, 0.4093747026253764, 0.24873988177691808, 0.9997638676970155, 0.9997497783487962, 0.6922204422912007, 0.307479517729651, 1.0000222288510627, 0.9997110314997928, 0.9996730337354579, 0.9987842697559675, 0.9988974846427215, 0.9994526253021397, 0.45435364865754174, 0.007221514945550332, 0.05656853374014427, 0.05115239753098152, 0.0024071716485167772, 0.08786176517086237, 0.001805378736387583, 0.05777211956440265, 0.27983370414007536, 0.9999007809865972, 0.9999500853119125, 1.0001214983150162, 0.8697535454795815, 0.12997185909859948, 0.9570294591582524, 0.04286868432529694, 0.027311324404074414, 0.26242857421400045, 0.7102579753706298, 1.0002255129820172, 0.0066074470368293866, 0.008640507663546121, 0.14798987145308895, 0.08072944905254366, 8.471085944653059e-05, 0.010080592274137141, 0.00016942171889306119, 0.0019483497672702036, 0.6697240547842709, 0.01287605063587265, 0.010927700868602447, 0.045066177225554276, 0.005082651566791835, 1.0000046800685165, 0.012130185413054818, 0.8976337205660565, 0.045328587596152214, 0.02170664758125599, 0.01851449352518893, 0.00446901567849388, 0.9992629022658432, 0.013652160706000211, 0.02309922549833791, 0.26584270741852734, 0.018433297155780876, 0.0008640608041772285, 0.008986232363443177, 0.0517860441970219, 0.0018433297155780878, 0.0036866594311561755, 0.3744839525304109, 0.008871024256219547, 0.003974679699215252, 0.030702960575097523, 0.02165912415804253, 0.018721317423839954, 0.04297262399441417, 0.02505776332113963, 0.025749011964481414, 0.05881373873766336, 0.0006912486433417828, 0.9999179294024642, 0.3952617531996683, 0.034552683061163054, 0.00396383593558797, 0.05526933502640584, 0.02812079833549201, 0.035001419204814525, 0.0995446345333507, 0.1124084039846928, 0.0007478935727524472, 0.03432831498933732, 0.0037394678637622356, 0.040909778429558855, 0.15601059927616046, 1.0003028431088563, 0.9988090136354, 1.000024153946542, 0.9997827974410505, 0.04257633159193231, 0.04798857713327964, 0.07504980484001628, 0.0008419048619873621, 0.00024054424628210347, 0.8048610480599182, 0.016236736624041983, 0.006975783142181001, 0.004931157048783121, 0.7809914947804556, 0.005891805073783823, 0.06980152399913334, 0.005809974447759047, 0.006137296951858148, 0.0007364756342229778, 0.01464768205843478, 0.11595399707710662, 0.2787590596537559, 0.00906930897373412, 0.06554883791195858, 0.012599279532373149, 0.6339284050922058, 0.126523044897693, 0.23868499705556168, 0.3155804683080389, 0.09325620981683407, 0.225959978172173, 0.9980167761319344, 0.8575858384114945, 0.0048772654317241395, 0.13737630966022993, 0.025136838847220663, 0.9747507508533346, 0.8996014881803742, 0.06861724032447403, 0.031993314507116725, 0.998700967078894, 1.0000039565184253, 0.9997462235338795, 0.9988524957511422, 0.9998398547325268, 0.9904208699059059, 0.008308899915318002, 0.056674639374075825, 0.17018019010579571, 0.10793184998445322, 0.0016148104968716458, 0.01432493182708718, 0.0016148104968716458, 0.00020836264475763172, 0.2754033257083997, 0.15450090108778392, 0.0004688159507046714, 0.025784877288756926, 0.18825564953852025, 0.002917077026606844, 0.9999322122408348, 0.9995509277463341, 0.9999132178207637, 1.000052936522738, 0.8211051065351425, 0.13511856183489687, 0.044173375984485515, 1.0001910041961253, 0.9998252126588781, 0.11698326805778758, 0.27979503288048163, 0.5794892814615148, 0.023517254918833583, 0.9998322529226297, 0.9990952098553886, 0.07267090690362071, 0.9276895459415332, 0.999129988272561, 0.010651103327100953, 0.9892212215045009, 0.02146458417831158, 0.20687126798624703, 0.0231885114115303, 0.0169350498792663, 0.026298340930277806, 0.07602181073546888, 0.0015211122646047574, 0.001656322243680736, 0.00020281496861396765, 0.025622291034897913, 0.010242155915005368, 0.012371713085452027, 0.0006760498953798922, 0.5768733757276621, 0.0280286430161104, 6.579493665753615e-05, 0.14303819229348358, 0.017698837960877224, 0.01776463289753476, 0.0013816936698082592, 0.024015151880000696, 0.060728726534905866, 0.016711913911014183, 0.0009211291132055061, 0.01283001264821955, 0.0034871316428494157, 0.027962848079452863, 0.026186384789699386, 0.008948111385424916, 0.6102480374986478, 1.000702372342836, 1.0000615164687656, 1.0005804614575868, 0.003827083755222468, 0.0009632795846478321, 0.3976782609593415, 0.0005987954174837875, 2.6034583368860328e-05, 0.0064826112588462215, 0.0013537983351807371, 0.001900524585926804, 0.5664864995230319, 0.0012496600017052957, 0.00015620750021316197, 0.0009372450012789718, 2.6034583368860328e-05, 0.015074023770570131, 0.0008070720844346701, 0.00041655333390176524, 0.0020046629194022452, 0.9997629144866186, 0.9999681638163099, 0.04182130493203745, 0.1397862794988649, 0.11887562703284618, 0.0684609032791572, 0.3964430549721906, 0.022056441642238928, 0.21197099760073776, 0.17631262954870255, 0.8231934376198808, 1.0004911998057486, 0.0019719014092551266, 0.9977821130830942, 1.0000367612940921, 0.039152588297454466, 0.030336773713921676, 0.04070832028278379, 0.3277408715760427, 0.0064822166055388195, 0.176834868999099, 0.015557319853293167, 0.36274484124595235, 1.0005447821792839, 0.9992129900889188, 0.02232946279974223, 0.07483799477592788, 0.141750173404507, 0.06317789986684746, 0.009831060413538388, 0.033151250231699216, 0.015546793212107219, 0.0003048390825903376, 0.06035813835288685, 0.041839164085523836, 0.15752559592855697, 0.1172868370266324, 0.0605867676648296, 0.018137925414125088, 0.028197615139606228, 0.031169796194862022, 0.0004572586238855064, 0.1217070037241923, 0.0016766149542468568, 7.62097706475844e-05, 0.9999492414065345, 0.999192027785182, 0.9997334971966848, 0.2922590760815224, 0.05005388553251573, 0.025583097049952486, 0.6317912662770875, 0.029286092702891186, 0.9706247867243937, 0.2123491301547779, 0.1801750195252661, 0.2892605755643728, 0.3180640650803167, 1.0005141505275794, 0.04492692897250567, 0.08714741644064353, 0.022734108636689617, 0.16319842271337903, 0.6747158670388954, 0.007307392061793091, 0.9997724493294115, 0.3095401348650178, 0.6898323005563255, 1.00002540826814, 0.9999988931792902, 0.14310510527399914, 0.03704355586111694, 0.3883724382912892, 0.10021256690849531, 0.33105240974829775, 0.9999470178650568, 0.9997280667407888, 1.0003203630758333, 1.0003954756769786, 1.0000297648281216, 0.6723590859116015, 0.3274654756759096, 0.9988902386306632, 1.0005937605544748, 0.9814759832184247, 0.017874562608282567, 1.0000826132796365, 0.999839015582164, 0.9999481770611527, 1.000256806192902, 1.0007817332453535, 1.0004355974097108, 1.000112612094253, 0.9991169571156403, 0.01091397979747916, 0.00600573748632233, 0.3064450416878785, 6.0971954175861224e-05, 0.0007011774730224041, 0.0007011774730224041, 0.0017072147169241143, 0.009054335195115391, 0.01097495175165502, 0.552283960924951, 0.001097495175165502, 0.004054634952694772, 0.0012804110376930858, 3.0485977087930612e-05, 0.005609419784179233, 0.01899276372578077, 0.0038107471359913265, 0.01591368003989978, 0.050393320126349304, 3.0485977087930612e-05, 0.0022487759505807675, 5.6219398764519186e-05, 0.26771677691664036, 5.6219398764519186e-05, 0.00016865819629355755, 0.010681685765258644, 0.004047796711045381, 0.013211558709662008, 0.6647381709916749, 0.003316944527106632, 5.6219398764519186e-05, 0.004497551901161535, 0.011918512538078067, 0.003935357913516343, 0.0004497551901161535, 0.012818022918310374, 0.9998033118400685, 1.0002249396107754, 0.05215865576502949, 0.9477565982696826, 0.9996693377419384, 0.9977427630178695, 0.9998616489388185, 0.9985754348522531, 0.04512863085702224, 0.14289442978055414, 0.06409349288098527, 0.6509979168225679, 0.0010837064013693163, 7.74076000978083e-05, 0.017184487221713445, 0.07849130649917763, 0.9552599782447636, 0.044046569602064024, 1.0008915535327434, 0.5238693850381466, 0.11777501503047384, 0.35791368204066076, 0.15927423429423126, 0.8406422845177958, 1.0003339509796099, 0.9996496458171852, 0.9989160382275889, 0.9995110615961873, 0.9998053543693991, 0.3244040525122165, 0.0115749802774312, 0.04873675906286821, 0.0012184189765717052, 0.04477689738901017, 0.5473747252248385, 0.02132233209000484, 1.0000003168636145, 0.9991259664206745, 0.23707352671319643, 0.7627583033381102, 0.9990508632204559, 0.9997780555669092, 0.9998006444777332, 0.00448211823252984, 0.9950302476216245, 0.010655036203514292, 0.0003512649297861855, 0.07762954948274699, 0.02482272170489044, 0.10725289189471529, 0.0019905012687883843, 0.3287839742798696, 0.06931627947780726, 0.2785530893204451, 0.009835418034013194, 0.003161384368075669, 0.05456315242678748, 0.032784726780043974, 0.42041022147048956, 0.15796235327266928, 0.1105187992515377, 0.058687402083943095, 0.23447536813911843, 0.01755137258585214, 0.7526383864174276, 0.05250294608201297, 0.014423886286267298, 0.18029857857834122, 0.794817902571799, 0.20465371144064284, 1.0001898018745474, 0.9999999514924048, 0.9984010151936411, 1.0003217423626005, 1.0000651227105049, 1.0000039373215537, 0.9994822250043729, 0.17346324610183902, 0.8264211626659325, 1.0000067751276287, 0.9986693428481839, 0.028546351426778447, 0.9705759485104671, 0.36580486720191746, 0.24298126525228875, 0.39113128434812, 0.9997071506367249, 0.9999803442162518, 1.0003438275341243, 1.0000396632488546, 0.9999087659597798, 1.0000294483925967, 0.9647009632163249, 0.03500930914897953, 1.0000594105624137, 0.9995814234474067, 0.9993673664878268, 0.31864496373465806, 0.07096798583786096, 0.004524370681830845, 0.38612272076082094, 0.19092844277326165, 0.008790205896128498, 0.019907231000055717, 0.05710645594498979, 0.14657323692547378, 0.7963178023440243, 0.999058850266719, 1.000037370737111, 0.002051927667221604, 0.00967337328833042, 0.09292301007274979, 0.37960661843599675, 0.017587951433328034, 0.1533083099938427, 0.3406199927587863, 0.0043969878583320085, 0.07433897376513564, 0.9251072290772435, 0.4809151005218907, 0.180469612816797, 0.0002023201937408038, 0.0018208817436672345, 0.33645848219095675, 0.0002005813871224411, 0.011734011146662804, 0.32734882378382385, 0.23588371125599072, 0.10560610031996524, 0.03389825442369254, 0.1328851689686172, 0.15234156351949402, 0.9999564961951346, 1.0000058898238384, 0.9995608608433395, 1.0003026008414415, 1.0004594877701354, 0.9995848043153852, 0.15316118170167228, 0.0036466948024207685, 0.13424395241411455, 0.18826061917497217, 0.06928720124599459, 0.18848853760012346, 0.2627899441994466, 0.005306100209337235, 0.12579879246303693, 0.001989787578501463, 0.008180237822728238, 0.031173338729856257, 0.1846080697831913, 0.6429224753646949, 0.004217967061654839, 0.9689272907344259, 0.007230800677122581, 0.019282135138993548, 0.7009268074008717, 0.057135227386388376, 0.04427980122445099, 0.12610560901710005, 0.006325685889207284, 0.05631900985229711, 0.008570284107958256, 0.8288403720090393, 0.06119643154468965, 0.00025605201483133743, 0.10959026234781243, 0.07633109909967806, 0.6096126240313655, 0.030394283804396693, 0.051117659125576254, 0.09360057853399437, 0.04144675064235913, 0.03367548489691679, 0.06372437911262716, 0.9994838605976145, 0.9991815119934512, 0.7811991801362436, 0.21896702273939112, 0.5686855794669061, 0.4309112380496659, 0.2570316637085128, 0.7429154399548378, 1.0001409990571846, 0.09217744317690553, 0.0003057294964408144, 0.010241938130767281, 0.7791516216794154, 0.0022929712233061075, 0.0015286474822040718, 0.11418996692064416, 0.00502642614614514, 0.05054350735845946, 0.5593295317071508, 0.3222497651473051, 0.06283032682681425, 0.999558348402648, 0.016530830871588697, 0.0407570485282273, 0.02593630360887192, 0.08635934058778232, 0.06156309428039928, 0.18041406796061454, 0.15675787895472038, 0.4315116886135394, 0.9989523724884585, 1.000276095630063, 1.0002091995309605, 0.12579581299762463, 0.8498679840822573, 0.024306309630049507, 0.2135990536370485, 0.4330055085997727, 0.11260692814419998, 0.24065304517861102, 0.9991973346080587, 0.9996269137409987, 1.000099432064541, 0.9998949315554078, 0.9998880001465347, 0.17941823103571647, 0.8198297159765991, 0.8900550257312474, 0.10959396402242405, 1.0004718086083573, 0.006876350628241374, 0.008349854334293097, 0.017682044472620676, 0.9666184311699303, 0.9990802109649604, 0.9986004988448283, 0.9998617648969316, 0.9998776832594234, 0.02000183631767578, 0.03191782391118476, 0.30300654166351393, 0.5281335929837371, 0.11618087903671251, 0.9991972703865597, 0.9991805193158785, 0.9999805081986101, 0.9994720116853654, 0.9991818753920022, 0.9996824458216893, 1.0001185274849147, 0.9994360301491427, 1.0001340665885925, 1.0001071700032558, 0.9996959450825901, 0.998535003966837, 0.9926226849717152, 0.007105387866655084, 0.9999947779260036, 0.2255315850782269, 0.7235529445031679, 0.012566276001426133, 0.03703744505683492, 0.9995449673872314, 0.9995505163397208, 0.007494717172637313, 0.6987574643955521, 0.025606950339844153, 0.07861125567744026, 0.010908977217949867, 0.0850650399094335, 0.09355905270508912, 0.9990893090469588, 0.9984034260406862, 0.9999635340304579, 1.000012634086863, 0.9997078399277372, 0.33295708487598663, 0.6659141697519733, 1.0004278053643505, 0.0455130136130314, 0.2960667977378318, 0.014164764440790385, 0.3719992235105934, 0.05503359299126756, 0.21711565167441, 0.009203302027377055, 0.9900123466592746, 1.0001578309330443, 0.11439653665869691, 0.8854176385325909, 0.1168645618120634, 0.8762312599934796, 0.006576793521891013, 0.9998773106164207, 0.004212078820035051, 0.2922129681399317, 0.010530197050087628, 0.08740063551572731, 0.01526878572262706, 0.5902175446574115, 0.34827529512710437, 0.09211558171622906, 0.003135849590339713, 0.0654608601983415, 0.1254339836135885, 0.023126890728755383, 0.3423955771452174, 0.09368249430347998, 0.9055974449336398, 0.8568294060327448, 0.1433397508219573, 0.9991718777083486, 0.016499568625016888, 0.01067619146324622, 0.006308658591918221, 0.03469762225555022, 0.011646754323541331, 0.09026234600744532, 0.06769675950558399, 0.002911688580885333, 0.02377879007723022, 0.0007279221452213332, 0.032513855819886216, 0.701959588708439, 0.4978352728277289, 0.13096775798637558, 0.0055227367825580066, 0.03826467627915191, 0.32702491376718484, 0.9988905454877175, 0.9999797798007314, 0.999860403731448, 0.5808503909840943, 0.2092129531387843, 0.08301179883142662, 0.07651017542644775, 0.04133174878879423, 0.008939732181845943, 0.4206524569475572, 0.4372940937095435, 0.13874714023246404, 0.0030075247160216193, 0.9989198922707977, 1.0000354979454786, 0.01819736478919545, 0.22966329354639775, 0.010353673069714653, 0.125812815180472, 0.615572926144853, 1.0002095763387977, 0.8073461661476393, 0.19248592209847673, 0.02741886549127243, 0.5073357801502212, 0.002516288288756014, 0.07505480585427421, 0.003904585275655884, 0.000607379931768693, 0.0007809170551311768, 0.007809170551311768, 0.03019545946507217, 0.015705109664304776, 0.08243013359717978, 0.0013882969868998698, 0.02793947686135988, 0.017440480897929614, 0.0002603056850437256, 0.09544541784936605, 0.10325458840067782, 0.00034707424672496745, 0.999779972266824, 0.9990657945199947, 0.9809758809016867, 0.01884440800572287, 0.9998194347730259, 1.000419380217496, 0.8828165515143758, 0.1172436210706839, 0.9981643195009584, 0.05173104814484942, 0.6215446829343848, 0.1965007724308086, 0.004246578579054803, 0.12585314697926053, 1.0002747780095238, 0.8164033710375299, 0.06743577932998929, 0.00035870095388292175, 0.04340281541983353, 0.060261760252330855, 0.009326224800955966, 0.002510906677180452, 0.9994862463405749, 0.999313481705481, 0.6334065233603614, 0.13882301148715695, 0.07344459017516256, 0.1271482933957294, 0.027382520614439215, 1.000097470467537, 0.06766736215797362, 0.08034428570149271, 0.1486968869699268, 0.039229939073863185, 0.047795427954619336, 0.5576133261372256, 0.024839917754192843, 0.012505613765903983, 0.021071102646660136, 0.7998178498410415, 0.007850183240595903, 0.03603362798962054, 0.1562315156407119, 1.0003593142455827, 0.13555968233069965, 0.06843157040732434, 0.7957614044508858, 0.09883818776360179, 0.9009281931750299, 0.0370419287412225, 0.002950242112132766, 0.06424971710866913, 0.002950242112132766, 0.8696658137209142, 0.0013112187165034515, 0.021307304143181088, 0.04283311925050806, 0.006061290459977556, 0.023436989778579883, 0.8914137836473659, 0.0020204301533258517, 0.033539140545209144, 0.0004040860306651704, 0.999446728830908, 0.31616958927916483, 0.0023032221735568297, 0.09526964445166887, 0.01968208039221291, 0.28706523635876485, 0.27952741833621525, 0.9993189757330666, 1.0001573473132328, 1.0001520497992809, 0.8404931098256421, 0.03212253493850078, 0.12723317099554005, 0.999724999638658, 0.0003134449133063988, 0.06833099110079494, 0.019198500940016926, 0.04200161838305743, 0.04051275504485204, 0.020060474451609522, 0.00752267791935357, 0.5166355783572718, 0.015437161980340139, 0.05587155579686558, 0.09129083100048864, 0.0496026575307376, 0.07303266480039092, 0.9998912229125447, 1.0003212384158278, 0.9274020093162675, 0.07241299284976417, 0.0428826687862841, 0.007191503461053855, 0.029831421764371546, 0.03356034948491799, 0.6365812322932857, 0.11746122319721296, 0.1321105820993597, 0.052304619207142654, 0.02876754056392846, 0.02680611734366061, 0.8924475652218716, 0.01762513056908265, 0.022582198541637143, 0.06306492031749884, 0.3825204118821218, 0.03745340245930062, 0.47670470336065723, 0.029942205731477507, 0.09111599447473538, 0.15314936807152849, 0.007736263681817155, 0.7177533527019249, 1.0001090542548712, 0.9979109999241891, 0.9988845139403065, 1.0011645940706495, 0.9988246956110328, 0.17029755166245278, 0.20035006077935621, 0.05108926549873583, 0.5780099253484426, 0.9992538166680089, 0.0031135560235458406, 0.07285721095097267, 0.030512849030749238, 0.2266668785141372, 0.030512849030749238, 0.07783890058864602, 0.0958975255252119, 0.4614290026894936, 1.0003769038652908, 0.0442116573463885, 0.9557479280899533, 0.9993794108060857, 1.0002654771868467, 0.9991597136826119, 0.9987156819571246, 1.000116449761438, 1.0002906694210902, 0.9988204186697504, 1.0000434115444323, 1.000535150383594, 0.9999755736575399, 0.9999933270620247, 0.9998961956642584, 0.9998087823342482, 0.9993026947764957, 1.0003291684738376, 0.13623178738027636, 0.17704432284650143, 0.03465645469757658, 0.08002904999243014, 0.5703494830657093, 0.0017100224357356867, 0.9997276138806046, 0.9994142012457494, 0.9989811970878135, 0.2447989097329301, 0.6025269515470366, 0.0014294826845718544, 0.15081042322233065, 0.5083987718008279, 0.4910357150379508, 0.00042348918933846557, 0.04766887683855132, 0.9526965528161898, 1.000052259803277, 0.9998932964926898, 0.9992584288317917, 0.042139294943295165, 0.12371375895117137, 0.0020280944090355964, 0.0006760314696785321, 0.0038308449948450153, 0.7880273498219422, 0.014872692332927706, 0.0018027505858094189, 0.00428153264129737, 0.00022534382322617736, 0.018478193504546544, 0.003526683965801645, 0.9945248783560638, 0.00041644339524764403, 0.00416443395247644, 0.19989282971886912, 0.795406884923, 0.01541568552388964, 0.49366044107897755, 0.042303509112069246, 0.39686427616153097, 0.03549192713639708, 0.004302051774108737, 0.011472138064289964, 0.9999043691477576, 0.009780951352256031, 0.30379634900107233, 0.017605712434060856, 0.05457770854558866, 0.014475808001338927, 0.0054773327572633776, 0.004694856649082895, 0.5895957475139936, 0.013626010329078545, 0.1268457688816039, 0.2207413673310724, 0.6389360116126103, 0.8807754383093624, 0.1186229546544596, 0.9003264552104185, 0.09958464177270995, 0.007541605174239285, 0.015663333823420056, 0.9078932382834217, 0.06845457004309505, 0.9996873023575878, 0.0720179559155121, 0.2253061745829042, 0.45136253620659494, 0.11052755734255677, 0.09527375417989623, 0.014753678468802827, 0.016254052550375996, 0.014253553774945103, 1.000136313450758, 1.000032973447473, 0.9989289216789694, 0.15807598697276942, 0.8415664449312201, 0.11755221079879452, 0.6538406991175553, 0.055924247030905795, 0.03839575169286069, 0.13410690084028157, 0.9999590154881977, 0.06288558308091445, 0.13848573760441815, 0.798268904354996, 0.27484548730858566, 0.0611208737119454, 0.00972377536326404, 0.269487488639032, 0.03155265883181597, 0.19447550726528082, 0.15577885020739332, 0.0027782215323611547, 1.0000803341665732, 0.9997671301586635, 0.9994339296550389, 0.0006906769469643768, 0.2966457487211998, 0.014158877412769723, 0.02935377024598601, 0.4074993987089823, 0.11154432693474685, 0.13986208176028628, 1.0006625268938405, 0.9991751177235371, 0.007267875562237217, 0.032947702548808716, 0.10804908335859328, 0.0009690500749649622, 0.007655495592223202, 0.0006783350524754736, 0.017152186326879832, 0.042444393283465345, 0.3692080785616506, 0.0436072533734233, 0.11599529397330598, 0.01928409649180275, 0.000872145067468466, 0.045545353523353226, 0.0015504801199439397, 0.0022288151724194133, 0.18450713427332882, 9.690500749649623e-05, 0.13574135557892325, 0.8633150214819519, 1.0002876691538372, 0.08757456169761203, 0.684958178992037, 0.19743372168434856, 0.029712797718832656, 0.9994431688613999, 1.0000407258439719, 0.0009444571157044633, 0.03267821620337443, 0.15111313851271413, 0.0047222855785223165, 0.006988982656213028, 0.3146931109527272, 0.2523589413162326, 0.05081179282490012, 0.03985609028272835, 0.030222627702542824, 0.08821229460679687, 0.02701147350914765, 0.09684282373369248, 0.16025766770144034, 0.7422977859790642, 0.8625462378781051, 0.10587016128472693, 0.0311698952005795, 0.9986503247549228, 1.0003253025583223, 0.9988501168630854, 0.9992400139786257, 1.0004288848013492, 0.874517043686264, 0.12493100624089486, 0.06392421763901643, 0.9355258517963992, 0.9517198352812072, 0.04820803087208729, 0.07146594188020332, 0.929057244442643, 0.9992937259679403, 0.008762073582877467, 0.009627891130592632, 0.2154500385734416, 0.014511102099706161, 0.11179436176098208, 0.04845114997014062, 0.03411321137997749, 0.03664139861930577, 0.06753376872178285, 0.21977912631201743, 0.07099703891264351, 0.06535190850154064, 0.002458921835511068, 0.00045022512481188566, 0.0003116943171774593, 0.009212298707689352, 0.020779621145163955, 0.028952938795595108, 0.03463270190860659, 0.00020779621145163954, 0.9580826160903427, 0.042525860244218866, 0.019753069181439757, 0.6863306546411363, 0.15809535298263433, 0.10131412902738457, 0.03079779603557812, 0.0036107760869298483, 0.9996645862092326, 0.7385055374817742, 0.20209104235143144, 0.05952240577193836, 1.0000008192403598, 0.21886827803685527, 0.6775526230975916, 0.10329426983257525, 1.0002214347330924, 0.9995731524264844, 0.6909128612209592, 0.30868370711221266, 0.0005179256830741823, 0.9995781048108296, 0.9985115033967813, 0.999331980708426, 0.9992837201054927, 0.9982874304100807, 0.003229230678232353, 0.018039150685297975, 0.0905298117725139, 0.08540758380014535, 0.03618965415260396, 0.731142366664608, 0.012916922712929413, 0.009576339252689048, 0.005567639100400609, 0.0073492836125288044, 0.9994399407672124, 0.9991788187883796, 1.0001809261568877, 0.9993964188720927, 0.9999803658455112, 1.0003987288044525, 0.1356599272004359, 0.04203547040013506, 0.8220800518026414, 0.13044631371844972, 0.21106802039255923, 0.5090348633073338, 0.01451583039874478, 0.1324079124209828, 0.002353918443039694, 0.0055101105304380124, 0.010446251213955399, 0.17362587869348944, 0.048730040003561174, 0.0001721909540761879, 0.033692030014240766, 0.00011479396938412525, 0.0006887638163047516, 0.0004017788928444384, 0.21345938606978093, 0.0011479396938412526, 0.0006887638163047516, 0.00011479396938412525, 0.005739698469206263, 0.019342783841225106, 5.739698469206263e-05, 0.006313668316126889, 0.028468904407263063, 0.4510829026949202, 0.9998986486878257, 0.9991342820894827, 0.9999434946996566, 1.0000609741188478, 1.0003226342374172, 0.9988955125061443, 0.0005920927085395137, 0.00023683708341580548, 0.3696434779412184, 0.005684090001979332, 0.00023683708341580548, 0.027946775843065045, 0.0008881390628092705, 0.0018354873964724924, 0.19953524277781612, 0.00029604635426975687, 0.0006513019793934651, 0.016756223651668237, 0.0012433946879329787, 0.018414083235578877, 0.03736104990884331, 0.009828738961755927, 0.30877634750335636, 0.999849456215692, 0.999029338439364, 0.9998964268690945, 0.08314156680016041, 0.0009447905318200046, 0.8663729176789443, 0.04912910765464024, 0.04665721261950054, 0.068488796064454, 0.07759568515863459, 0.030314713012135376, 0.38011905575298965, 0.0520215445516891, 0.06561950224026011, 0.05701162076767846, 0.2219336397061269, 0.9995723792736888, 1.0005501532756418, 0.9993075754788914, 0.9993761914706315, 1.0005241029090022, 1.0002084294946143, 0.6284825799463457, 0.03777125790259946, 0.01427779508345684, 0.2580386965992018, 0.010903043518276133, 0.0038939441136700476, 0.046727329364040567, 0.0018029189890084317, 0.417525989204536, 0.0007512162454201799, 0.026442811838790332, 0.0022536487362605395, 0.00015024324908403597, 0.17323046619389348, 0.00045072974725210793, 0.0019531622380924677, 0.018930649384588532, 0.019982352128176784, 0.05033148844315205, 0.21499808943925547, 0.07091481356766498, 0.9997391259502376, 0.2975295356002215, 0.28454542401878197, 0.28012530092722804, 0.08287730796663552, 0.05442276556475732, 0.756744558493364, 0.24383991329230617, 1.0002038765081744, 0.005250669467985731, 0.00012806510897526174, 0.21438099242458816, 0.0007683906538515704, 0.778891992787542, 0.0003841953269257852, 0.9999787679164424, 0.999919436539629, 0.9996852915588434, 0.5239906172014823, 0.2205555277632383, 0.1130175841022805, 0.10514060096787912, 0.036987572978928164, 1.000529768219295, 0.0009378403356382973, 0.7634020332095741, 0.049236617621010614, 0.0030479810908244664, 0.18334778561728715, 1.000039357720852, 0.03771720516629012, 0.004263684062276275, 0.05280408723280617, 0.3463423361356728, 0.018694614734595973, 0.045260646199548143, 0.1505408449680623, 0.023286274493970423, 0.3207602317620151, 0.9954675250739022, 0.0036517517427509254, 1.0005031070392394, 0.16963803112633377, 0.8302733298722583, 0.051595551917854796, 0.12018728564394411, 0.1383974804384811, 0.6051854736717792, 0.07344778567129918, 0.010319110383570959, 0.263257912988671, 0.17729614548216618, 0.5459915389280345, 0.012759949864246809, 0.10835563247462096, 0.1264055035791908, 0.1196932077621789, 0.06199002607475712, 0.1905389518476156, 0.03829957025000918, 0.20503525457847327, 0.12031367208139848, 0.029274634697724244, 1.000172277073502, 0.053107172636384904, 0.0059007969595983225, 0.08193678063899384, 0.039619636728731596, 0.5408501898968977, 0.27834902229419517, 0.0007710638322712664, 0.038167659697427685, 0.8793983007053794, 0.0030842553290850658, 0.07864851089166917, 1.000414252653686, 1.0005484208657733, 0.9995687399294234, 0.9997710022146036, 0.2167456010233122, 0.7830808811164828, 0.9987137686610618, 0.35383463241844465, 0.1568205633437427, 0.12486343173798, 0.3643771912986962, 1.000574833021286, 0.9995712268482758, 0.9999418712464353, 1.000440803825396, 1.0003261161325596, 0.7455007409868111, 0.162732863559724, 0.09149885535999576, 1.0002838979242, 1.0000558687189771, 1.0000692287791204, 0.9995715854524353, 0.9994451829996811, 0.8358817922632749, 0.039414986805957314, 0.10084555182785473, 0.023435938100839483, 0.011950516816471623, 0.015474387159790179, 0.45013613342043113, 0.021296433813968663, 0.0001532117540573285, 0.001813005756345054, 0.01933021630356628, 0.0033961938816041153, 0.0053879466843493855, 0.32881795949936987, 0.009243775828125486, 0.004545282037034079, 0.015474387159790179, 0.00010214116937155233, 0.004826170252805848, 0.03347676826152628, 0.002068358679773935, 0.0075329112411519844, 0.0629955662099049, 0.0020172880950881586, 0.9997719290235606, 1.0003090185921666, 0.1239799707615219, 0.0608291242313085, 0.2572468307186634, 0.510314561299298, 0.04736313489766005, 0.9676902364230279, 0.032539291575628126, 0.9997769017315076, 0.9999409901153203, 0.5575119182141447, 0.3050829108005181, 0.002433583769982378, 0.003982227987243891, 0.009955569968109727, 0.00575210709268562, 0.03296399833885221, 0.01039803974447016, 0.07212257354675047, 0.0031334137569407317, 0.27436954209212283, 0.09400241270822195, 0.4357403505745705, 0.012925331747380519, 0.06364746693785861, 0.04680536799430218, 0.0689351026526961, 0.017010831297351224, 0.0022770404098816596, 0.0346913803623147, 0.035628985236971854, 0.6856570504814244, 0.0020091533028367588, 0.024377726741086004, 0.11773638354623406, 0.03254828350595549, 0.01915392815371043, 0.00013394355352245056, 0.028529976900281973, 1.0008200551791195, 1.0000915641961163, 0.8317168117344859, 0.16829656573298749, 0.0974286477638289, 0.0017244008453775024, 0.0406311949192074, 0.0003233251585082817, 0.0007544253698526574, 0.17825993739089932, 0.0005388752641804696, 0.21220907903426892, 0.06541945707150901, 0.019399509510496904, 0.09656644734114014, 0.2865738654911737, 1.0004836042377279, 0.0035953166802873385, 0.3784070806002424, 0.03415550846272972, 0.12583608381005684, 0.06831101692545943, 0.0044941458503591734, 0.3846988847907452, 1.000132190940616, 0.9988968020459983, 0.999720396682573, 0.05739593517842519, 0.01418775925758825, 0.003224490740360966, 0.09286533332239581, 0.14381228702009907, 0.06255512036300274, 0.6255512036300274, 0.05947937346350876, 0.48185373383235375, 0.09205141131257309, 0.3660813819123099, 0.9985860047122368, 0.9994187126069382, 0.9993595418112612, 0.9983060093523397, 0.9985666072798371, 1.0000171222473517, 1.000340643485699, 0.12389818648836459, 0.45480959290103834, 0.4034434697527372, 0.01781036430770241, 1.000263432418732, 0.008953611756306481, 0.41996702761723254, 0.08910975509847878, 0.020891760764715123, 0.017622981869555614, 0.06267528229414536, 0.3312836349833398, 0.0002842416430573486, 0.04064655495720085, 0.007816645184077086, 0.0005684832861146972, 0.9996407590441311, 0.9990930778276674, 0.6624155322175398, 0.008254103595377536, 0.14819436570091624, 0.003320616388944986, 0.0010436222936684241, 0.06783544908844756, 0.10882134280342567, 0.9995110526322046, 0.03377806944508455, 0.007562254353377139, 0.2001476652193816, 0.1731756246923365, 0.5853184869513905, 0.10466983891265565, 0.8952164112027131, 0.015430481484082156, 0.055770168792468364, 0.018957448680443793, 0.012344385187265725, 0.0198391904795342, 0.0008817417990904089, 0.15584786298922979, 0.7203830498568641, 0.9996166779187601, 0.1407415620300024, 0.8590413067048641, 0.9995296691001608, 0.23761072089939295, 0.7622870256604927, 0.013836860205737777, 0.006248904609042867, 0.019639414485563295, 0.004017152962956128, 0.04017152962956129, 0.22897771888849935, 0.5780236763364652, 0.08927006584346953, 0.0093733569135643, 0.010712407901216343, 0.005855463228968137, 0.21648948771546084, 0.11450683647759911, 0.07205472806758012, 0.07953670886015052, 0.2236461649953108, 0.2875683052448796, 0.9992868384865414, 0.9997364264406611, 0.031240172020227223, 0.9684453326270439, 0.9793432414552873, 0.011720334938308713, 0.0017878477024538713, 0.007151390809815485, 0.9998320944470303, 1.00029329217216, 0.9991296173167856, 1.0003270025349873, 0.9994282607074481, 0.9995860671016575, 0.011791638410955868, 0.5197055447791661, 0.3026520525478673, 0.019216003336372526, 0.04804000834093132, 0.018779275987818606, 0.0746803766027205, 0.004367273485539211, 0.9995542449794541, 0.016009776765290723, 0.984130395278165, 1.0000810318575177, 0.18321771640455822, 0.8165520341683917, 0.9987507847669507, 0.9995077847400144, 0.9999592288338027, 0.04124418944239841, 0.957896299799703, 0.385090322066058, 0.06788451190267047, 0.13601587657589612, 0.1446557235453269, 0.04221182376493328, 0.13601587657589612, 0.07282156731377379, 0.015304871774420253, 1.0008839038731112, 1.0000074200169484, 1.0000511845224302, 0.00514881750576511, 0.09375138541747305, 0.00042906812548042586, 0.0008581362509608517, 0.028318496281708107, 0.005792419693985749, 0.00042906812548042586, 0.031965575348291725, 0.35312306727039044, 0.13022217608330924, 0.04869923224202833, 0.08474095478238411, 0.015231918454555118, 0.20123295085031973, 0.03565622625538407, 0.08313219602084021, 0.7456288197603795, 0.13533606319032518, 0.05217928419333601, 0.9477564215501127, 0.16539164930849015, 0.5779256774408099, 0.020083271701745235, 0.0829320984389715, 0.1415279970511223, 0.01204996302104714, 1.0002625070336337, 0.023158527662404765, 0.6009028493455553, 0.22975697180859464, 0.1456549502977563, 0.028280149502156036, 0.013130069411715304, 0.9100148107658068, 0.04848025628941035, 1.0008707538633346, 0.49650735419607733, 0.01409551584913545, 0.26954078266612075, 0.19359759523404405, 0.026465050165723706, 0.9993124093164297, 0.04834109926058117, 0.016455635026811452, 0.0017951601847430673, 0.9333550703389134, 0.9998244766401061, 0.9992293386400416, 0.9999520042038634, 1.0003098672489432, 1.0002999803883175, 0.0013475542672504105, 0.38108834677841613, 0.1568553167079478, 0.09594586382822924, 0.06683869165562037, 0.11076896076798376, 0.1595504252424486, 0.027490107051908377, 0.9995301931135716, 0.9988716871627942, 0.999795415925482, 1.0005260531934141, 0.9999670144603506, 0.9992884820904929, 0.9995597770336282, 1.0001354677222305, 0.002597790932607843, 0.21697739503781696, 0.044595411009767966, 0.41116226725025323, 0.20408121862237089, 0.0447500414224232, 0.07583075436612417, 0.9987871313217606, 0.9993697438262885, 0.9994516689135922, 1.0001154437466324, 0.9992771196022785, 0.9994617010141119, 0.3213922408874887, 0.15301418386598276, 0.024981907569956368, 0.05408582988895554, 0.00012490953784978184, 0.2643085820901384, 0.004621652900441928, 0.04596670992871972, 0.0929326961602377, 0.038347228119883024, 1.0002030179825854, 0.020223908159975865, 0.07847446053624438, 0.09285907126974834, 0.0025635939921096165, 0.031190393570667, 0.005269609872669768, 0.11707079230633916, 0.1858605644279472, 0.46643168467549967, 0.043054774585575335, 0.054236163806306845, 0.0363716453961726, 0.021848691580739724, 0.006554607474221917, 0.038299471123884925, 0.020434952713750683, 0.04601077403473424, 0.47848634561819997, 0.019920865853027395, 0.2346806519201808, 1.0002200017469285, 0.999639222361019, 0.9997325439680783, 0.9994985700035959, 1.0004389790374422, 0.9994500909160132, 0.9993848384774445, 1.0011478502176694, 1.0000539441938008, 0.999655072483571, 0.9998383184180123, 0.025415565117583052, 0.0428887661359214, 0.0752936116608398, 0.3485109366748576, 0.289419747776477, 0.0670335529976253, 0.12231240712836844, 0.028910205321250722, 1.0000782959839518, 0.9987633476135764, 1.0004486681122085, 0.999873874232448, 0.28364694199339524, 0.7163341846930709, 0.9998672017418931, 1.0001002227304596, 0.9995577386067418, 0.024087351151804944, 0.39916181908705334, 6.617404162583775e-05, 6.617404162583775e-05, 0.00019852212487751327, 0.06657108587559278, 0.0006617404162583776, 0.04890261676149411, 0.002382265498530159, 6.617404162583775e-05, 0.034145805478932284, 0.059027245130247284, 0.001058784666013404, 0.05207897075953432, 0.007146796495590478, 0.30327563277121444, 0.0009926106243875663, 0.4137336662249051, 0.5862359479897236, 0.5967608311108291, 0.07850134592215008, 0.3173939309945924, 0.007153599868205522, 0.2712260372213209, 0.3145946675384357, 0.4137229654061265, 0.025221396519228296, 0.07230133668845445, 0.009989651170361012, 0.008011502423754872, 9.890743733030705e-05, 0.29682121942825146, 0.005242094178506273, 0.0308591204470558, 0.24637842638979485, 0.041442216241398655, 0.04084877161741681, 0.07635654161899703, 0.0033628528692304397, 9.890743733030705e-05, 0.0519264045984112, 0.02136400646334632, 0.005439909053166887, 0.06419092682736928, 9.890743733030705e-05, 0.9995004859237013, 0.6691319137539403, 0.29962898084910955, 0.03138406321146799, 0.9991689155620659, 0.13092747466299137, 0.7031057173007758, 0.16554772036714774, 0.025540026963590822, 0.009275062423619826, 0.29512173262401925, 0.023994183226320853, 0.003562161655448194, 0.6039544270916504, 6.721059727260743e-05, 0.005914532559989454, 0.01619775394269839, 0.015122384386336672, 0.0011425801536343262, 0.04607946974197699, 0.060612225583677425, 0.0747905239658242, 0.022685277411434827, 0.05813102336680174, 0.7372715158716319, 0.006863465275113145, 0.02341652858568014, 0.06540478673931349, 0.055109588826643775, 0.019782929322384946, 0.019581062696646324, 0.011910130918578692, 0.0294725273578388, 0.7679006443097177, 0.0002018666257386219, 0.9999176795080896, 0.999002177159224, 0.9997300574303755, 1.0008436039918205, 0.0018520207391939621, 0.06358604537899269, 0.0032550667537348424, 0.005107087492928804, 0.8230267921296804, 0.0033111885943164776, 0.0008979494493061634, 0.03597409981282817, 0.05034129100172679, 0.01055090602934742, 0.002076508101520503, 0.9191672160390666, 0.08071499999759256, 0.9983414220021258, 0.9996425529795128, 0.04211317582353572, 0.05779361363017136, 0.013440375262830548, 0.15859642810140048, 0.09453063934857486, 0.5828642738980848, 0.024640687981856008, 0.02374466296433397, 0.0013440375262830549, 0.9999378581256437, 0.9996655942603608, 0.9994162418909239, 0.038671607665740536, 0.03389808109450069, 0.24351027952020995, 0.00743219959825951, 0.001933580383287027, 0.0012689121265321115, 0.02954752523210488, 0.00012084877395543919, 0.0013897609004875505, 0.5349975223007293, 0.0006042438697771959, 0.011722331073677601, 0.02477399866086503, 6.042438697771959e-05, 0.0006646682567549155, 0.02084641350731326, 0.0007250926437326351, 0.014924823583496739, 0.03129983245445875, 0.0017523072223538682, 0.6638866591367596, 0.08427044280064132, 0.25163682745696725, 1.0007233830061542, 0.029105277997037122, 0.014139798175865552, 0.12085915083166833, 0.0019609939076017917, 0.00041284082265300885, 0.019919569693007677, 0.005882981722805376, 0.003096306169897566, 0.6777814205905772, 0.008566447070049932, 0.0018577837019385396, 0.00020642041132650442, 0.06915083779437897, 0.02291266565724199, 0.024151188125201017, 1.0001937930837683, 0.0257535772179618, 0.4398710988827875, 0.0872187815114973, 0.4251057146111561, 0.021976385892660735, 1.0004611680282194, 1.0000991981226781, 0.14822889271948633, 0.005623110980030265, 0.013182047051546358, 0.47980807624684474, 0.015855329320741074, 0.05632329194751626, 0.16012038971004214, 0.01115403981284692, 0.10969675518419697, 0.019058142520480718, 0.9809338062012134, 0.9999752504948862, 0.8698340920200712, 0.13041841014642527, 0.002874844175213927, 0.015918118673869705, 0.3988047725282875, 0.005749688350427854, 0.008251867539965901, 0.02560740830144257, 0.002981319885407035, 0.009423100352090093, 0.003939601277145011, 0.4270740735845578, 0.018207346443021535, 0.019964195661207825, 0.0007453299713517588, 5.32378550965542e-05, 0.0006388542611586504, 0.009423100352090093, 5.32378550965542e-05, 0.043388851903691676, 0.006867683307455492, 5.32378550965542e-05, 0.0022232865842094804, 0.14093703651206183, 0.00028999390228819305, 0.11667421335394967, 0.0005799878045763861, 0.03180266461760517, 0.1353304877344901, 0.005799878045763861, 0.07820168898371606, 0.2316084632941702, 9.666463409606436e-05, 0.008119829264069406, 0.04852564631622431, 0.011696420725623788, 9.666463409606436e-05, 0.18781938404865303, 0.18086904655408959, 0.721720176055639, 0.09658055883956239, 0.9680492963473085, 0.032008779235791256, 0.9994350649724143, 0.023858525000849454, 0.0001617527118701658, 0.10954702411406977, 0.0008087635593508289, 0.01957207813629006, 0.00024262906780524868, 0.03332105864525415, 0.3754280442506548, 8.08763559350829e-05, 0.002547605211955111, 0.003518121483176106, 0.02232187423808288, 0.0006065726695131217, 0.03247185690793578, 0.37550892060658986, 0.9999651899080501, 0.9998028234880717, 0.9991128420421149, 0.9988411405599843, 0.9995936737807131, 0.018855581101577524, 0.00968259570081008, 0.14039763766174618, 0.044845706403751955, 0.28003085987342835, 0.04662934245390118, 0.02293246350191861, 0.3636069490804206, 0.009427790550788762, 0.05809557420486048, 0.005350908150447676, 0.0031342824677816905, 0.005252040891958508, 0.009402847403345072, 8.471033696707271e-05, 0.024142446035615724, 0.05590882239826799, 0.05658650509400458, 8.471033696707271e-05, 0.019483377502426725, 0.3026700339833508, 0.019822218850295014, 0.046421264657955846, 0.06446456643194233, 8.471033696707271e-05, 0.07014015900873621, 0.09673920481639704, 0.15874717147629427, 0.012028867849324325, 0.05209685723474972, 0.002710730782946327, 0.9990832716168933, 0.9994976061108136, 0.9999166451627666, 1.0001495359256867, 1.0001603197608646, 0.009779427454926349, 0.0009330195805053406, 0.43292108535447804, 0.02432762165465777, 0.007844275732396752, 0.0016241451956944817, 0.046961985552102146, 0.028336150222754788, 0.014790088165047621, 0.04267700673792947, 0.0014168075111377395, 0.0004492316498729418, 0.022599807616684918, 0.0025226084954403654, 0.037078889254897426, 0.04903536239766957, 0.026988455273135963, 0.00010366884227837118, 0.21089698147496644, 0.038806703292870275, 0.9994883223786792, 0.041992582749882115, 0.8755267695462148, 0.025269872805238795, 0.049796514057382335, 0.007432315530952587, 0.06291901003297148, 0.024914238872116225, 0.05081378662618055, 0.08783324890508772, 0.35161451244376457, 0.16384279122679823, 0.0019706177638961985, 0.04053842257157894, 0.023506654755047512, 0.044057382864250726, 0.002955926645844298, 0.1448404056463706, 1.0002704552485984, 0.9990855238859457, 0.9999808937950303, 0.9995261264857324, 0.7676772645900234, 0.23199409846200708, 0.7713805416229961, 0.2277902270564552, 0.014680195628828007, 0.04257256732360122, 0.9439365789336408, 1.000894700603552, 0.9999583697790034, 0.67361138347108, 0.2474291994239397, 0.07890458721787053, 1.0005206908921893, 0.6904672879276669, 0.08646020207606381, 0.0058287776680492455, 0.09544623431430639, 0.12191859955669672, 0.9983039201568016, 0.9998854547450885, 0.999788254651777, 1.0002588887375539, 1.0002567462602305, 0.023143026404626302, 0.9769663289381532, 0.07611879658893903, 0.11085393371330336, 0.1841912056497054, 0.12455803078190023, 0.044979288893463976, 0.45922293592738705, 1.000529466140905, 0.2893968270352871, 0.5619355864762855, 0.1486007439792844, 1.0007427178151325, 0.9985340938935545, 0.051036403603583184, 0.948676678748958, 0.9985668971561618, 0.9989258123647344, 1.000142882256414, 0.9995902841790888, 1.000028448272915, 0.999110882929275, 1.000259079314254, 0.998856975994633, 0.8938616257612777, 0.09490382693267886, 0.011035328713102194, 1.000126050468947, 0.06961578306264579, 0.3846734065868676, 0.022055265784448847, 0.20860092163727317, 0.15451007426647403, 0.0019714204053138634, 0.05285870961747796, 0.03289807801367509, 0.04620516574954367, 0.026490961696405038, 0.1179864415350823, 0.8822568240160632, 1.000356601525459, 1.0000112082162893, 0.9989990546814722, 0.4086171937408216, 0.36505901572784066, 0.22627624941808305, 0.6881729898483028, 0.311452667618533, 0.9996525111221096, 0.06944047188944232, 0.9307978146882694, 0.9997697609281078, 0.030814741130517506, 0.01929613182613876, 0.006989925304366591, 9.844965217417734e-05, 0.08929383452197885, 0.049520175043611205, 0.39960713817498583, 0.3449675812183174, 0.05936514026102894, 0.9996648394769433, 0.9998686341308496, 0.9991182625810952, 0.999429058862509, 0.9997296873576932, 0.053582548400839376, 0.8663825289223955, 0.023639359588605607, 0.05318855907436262, 0.003151914611814081, 0.9954365267547132, 0.004113374077498814, 0.011548049856870888, 0.40364640493089105, 0.014989521668521154, 0.007418283682890571, 0.030284951942522332, 0.08167759766316629, 0.15456032291878188, 0.0009942029678100765, 0.026461094374022037, 0.008106578045220624, 0.0009942029678100765, 0.008412486650700648, 0.2508450564936193, 0.8164160101702257, 0.18273571346770395, 0.9990300061998342, 0.6411075609804445, 0.12176512863144485, 0.2367340640369486, 0.6896068959388295, 0.31070200806035175, 0.825411997270557, 0.17424943494467932, 0.21673758479775937, 0.5715411791421684, 0.020058646669984942, 0.01354609904985996, 0.1394987700230771, 0.03855428191113989, 0.9987211027990045, 0.007168328988928944, 5.827909747096702e-05, 0.10312486297487615, 0.05189753629789613, 0.48922388372003267, 0.0006119305234451538, 0.3478679328042022, 0.597386107677083, 0.2979039044228518, 0.0632305969321351, 0.003945747078448369, 0.0374845972452595, 0.12418572763423429, 0.2945624881080313, 0.20218042242890583, 0.11535137709114851, 0.26351605619947277, 0.9995571170532231, 0.9957043462750349, 0.004097548750103024, 0.040268769044978, 0.04826918673603323, 0.6453670270784554, 0.038402004917065115, 0.22774522360537228, 0.9997754862398055, 0.018230974861123284, 0.9818682175204969, 0.056212991696767564, 0.05131369425530617, 0.7524289439044393, 0.14001676372176508, 0.026317262467020035, 0.053870077162538665, 0.04522121156304851, 0.26972105148124287, 0.004818653691144513, 0.020757277438776367, 0.026070152021320316, 0.08512954854355308, 0.3015982989765066, 0.03657234596355836, 0.12973298399235228, 0.009373554133747878, 0.018970288127823087, 0.06059333207887021, 0.028678612052061958, 0.02678158323927965, 0.8554484046346575, 0.012315247549019685, 0.026032726254610918, 0.08236583880557226, 0.07273312042564596, 0.09840004724810779, 0.022496665077169624, 0.645940830603285, 0.03962827181615245, 0.9992292396310352, 0.4427891664712859, 0.5571151430834593, 0.009773806645668688, 0.008405473715275072, 0.19625803744502723, 0.07838592929826287, 0.3440379939275378, 0.21326446100849075, 0.14953924167873092, 0.9995779567334435, 1.0003285209409898, 1.0000610712589981, 0.9988490723752423, 0.9994401042046597, 0.9999268575525262, 1.0008874381497814, 0.9997088114250765, 1.000025142567526, 0.9927819249593117, 0.007202770918689081, 0.53522038703195, 0.05030458790328919, 0.41443830541643834, 0.9990683447208004, 1.0000983518179327, 0.6891478525612169, 0.3110361186991364, 0.9988863173447073, 0.007146275592524202, 0.5431169450318394, 0.26169661219823626, 0.03573137796262101, 0.028728027881947293, 0.12334471672696773, 0.9989400430072063, 0.9996675253114012, 0.9998777353020827, 0.9138555214588078, 0.08635602539226532, 0.2502678602092818, 0.009629116103527765, 0.0025855959907620848, 0.042706913088794436, 0.07186173684669794, 0.0364658193179894, 0.45346004169020565, 0.13150876159910604, 0.00035663392976028756, 0.0010699017892808627, 0.0873669183838387, 0.27926211411977014, 0.23183435842568628, 0.06677328762193387, 0.33449048752669674, 1.00047897744211, 1.0000264677504753, 1.0005166337051887, 0.9999487940134579, 0.08322213668555033, 0.0016955274027616366, 0.03164984485155055, 0.11911080004400497, 0.001130351601841091, 0.003814936656213682, 0.29572823783167546, 0.020205034882909503, 0.1612163972125856, 0.28216401860958235, 0.7927804696850159, 0.20716820851975395, 0.03641744336747219, 0.05848862116594019, 0.42597373151043233, 0.47949633767171723, 0.9997482782232422, 0.9999844889393531, 0.010275867260067592, 0.3496649275995222, 0.0034252890866891973, 0.08135061580886845, 0.005994255901706096, 0.04738316569920056, 0.008848663473947093, 0.08791575322502274, 0.054804625387027156, 0.11160733607462302, 0.23834303228212333, 0.9993850443973813, 0.039222730170653204, 0.015420902460256816, 0.0026818960800446636, 0.04223986326070345, 0.02313135369038522, 0.10895202825181445, 0.0016761850500279147, 0.04291033728071462, 0.07777498632129524, 0.004022844120066996, 0.06067789881101051, 0.03285322698054713, 0.2906504876748404, 0.2571267866742821, 1.0000585626769791, 0.9992116737891957, 1.0011631474514076, 0.2767017620844153, 0.7228768151241247, 0.9997749174815744, 1.000070418061044, 0.08585318633030083, 0.05962714093833573, 0.2991253667819415, 0.014844931353942506, 0.5203148439556848, 0.020040657327822384, 0.9996736881521847, 1.0002259377554694, 1.0000629547502349, 0.9990918202363971, 0.3292912502618987, 0.524957065634911, 0.07635739136507796, 0.06919888592460191, 0.9997450361066406, 0.030263565276720784, 0.21049990959141346, 0.14089370945495566, 0.5558408155824385, 0.06220843973548162, 0.17221723484925372, 0.8282202897330523, 1.0010308061850104, 0.9814671070098681, 0.017990232104050534, 1.0000516087339326, 0.07334363603994101, 0.9258305360983857, 0.9994749449301423, 0.02518517876425581, 0.14285033395085897, 0.23553179180332035, 0.44930358915432367, 0.1468799625531399, 0.6903087408775922, 0.0051989779647684765, 0.2551350297525271, 0.049101458556146726, 0.023818890688542902, 0.12549026668315658, 0.12681353838807563, 0.06858958337163742, 0.6552400392190829, 0.9995770521107205, 0.03746804482092081, 0.1397113535695352, 0.1346309407124612, 0.03619794160665231, 0.6509278973126073, 0.00024138794124429369, 0.010862457355993215, 0.03749559353994695, 0.013799343974465455, 0.010661300738289638, 0.01878802809351419, 0.06296202134121993, 0.008770428531876004, 0.0019311035299543495, 0.33074171082822307, 0.01017852485580105, 0.0790947820810469, 0.03850137662846484, 0.035242639421666874, 0.011747546473888959, 0.06823232472505368, 0.003419662500960827, 0.0177822450049963, 0.23692226433127425, 0.0026552673536872303, 0.7808726016319325, 0.10639626688902244, 0.11304603356958634, 0.9981995703227897, 0.9998975530475666, 1.0005554239334398, 0.9987677440238889, 0.9997888893374041, 0.999489351454295, 0.9516117455111545, 0.04861727925977348, 0.9995868939052853, 1.0001116863279074, 0.9983349392059422, 0.7985181536572914, 0.20218234581092545, 0.9987663791987198, 0.9990456685866433, 0.9997777323296789, 0.9995148658164524, 0.9990627625603017, 0.05972200146644497, 0.011464491352933632, 0.6233483903060194, 0.1762332275416077, 0.08398406456218824, 0.04452488502185853, 0.0005332321559504015, 0.9993933081011087, 0.9995210160012686, 0.063135655266416, 0.1561285662253243, 0.7221723720621575, 0.05815944598433395, 0.37452254172014154, 0.26993888856055487, 0.35508976832900213, 0.9989860333024998, 0.9998197942481865, 1.0005296860828283, 0.08541643250152052, 0.35027191967877935, 0.017212379345394564, 0.3044439596716663, 0.2424793940282459, 1.0001844487607454, 0.9996678711620911, 0.99911257374664, 0.99982125991063, 0.9989508598759419, 0.24045446109593205, 0.009063886898868044, 0.0017430551728592394, 0.01507742724523242, 0.11408296106363722, 0.437681153904955, 0.03015485449046484, 0.1517329527973968, 0.18492796436905715, 0.05788483761610581, 0.7570556290465973, 0.9994000769842003, 0.9991926991559659, 1.0002134724004077, 0.9998361252652637, 0.9998678888951641, 0.9996589848643098, 0.030244637247351394, 0.009678283919152446, 0.05958193537728225, 0.9000804044811775, 0.9999316185840689, 0.5715522355924297, 0.4282851632754944, 1.0004690446260125, 0.9997892467174432, 1.0000106387319785, 1.0004193421344718, 0.006093954059981278, 0.02803218867591388, 0.8844358659052828, 0.022141366417931976, 0.059111354381818394, 0.9996701353867257, 0.725345176685325, 0.27467115146539883, 0.9986616974348463, 0.0047636377502476976, 0.22486665910205397, 0.06244382978637946, 0.022612931007199914, 0.05636014784027999, 0.4694191946900713, 0.009010736467336007, 0.09751109081531131, 0.05285916105997747, 0.8464890347615339, 0.1518700915307458, 0.0014938041789909421, 0.9998822549027668, 0.9987688467625174, 0.9964666076043898, 0.0036668504419664757, 0.00529835672038428, 0.01726381231391878, 4.4152972669869e-05, 0.008963053451983408, 0.000662294590048035, 0.0032673199775703063, 0.000485682699368559, 0.003134861059560699, 0.6606609300592499, 0.00088305945339738, 0.003929614567618341, 0.040046746211571185, 0.00353223781358952, 0.006093110228441922, 0.038589698113465506, 0.005121744829704804, 0.03642620245264193, 0.1656619534573485, 0.002496928691588021, 0.026405020913543322, 0.016916691885508844, 0.0007490786074764063, 0.7071302054577276, 0.023783245787375902, 0.005056280600465743, 0.0033708537336438285, 0.05437062225932916, 0.006242321728970053, 0.033521267684569186, 0.11985257719622501, 0.037350880650400715, 0.000615673856874737, 0.0020522461895824567, 0.08968315848475336, 0.031194142081653345, 0.0008208984758329827, 0.2413441518948969, 0.0925563031501688, 0.0008208984758329827, 0.06054126259268248, 0.0010261230947912283, 0.2618666137907215, 0.056847219451434054, 0.017444092611450884, 0.01847021570624211, 0.08701523843829617, 0.08533521489863578, 0.7028926911387631, 0.08196671957368963, 0.03986052801186277, 0.05108884576168326, 0.012351149524802547, 0.026386546712078168, 0.9993777234536271, 0.8442119857984689, 0.15573328231131928, 0.9994859508830078, 0.9771902445331073, 0.022103112673963143, 0.5530990430752916, 0.09200063290757325, 0.07666719408964438, 0.2080966696718919, 0.07064334312545803, 0.9978506104011281, 0.10537826531464833, 0.4928152027350809, 0.20674757488363069, 0.09349457506856707, 0.016035822982663876, 0.00014317699091664175, 0.08533348658631848, 0.9992784418725394, 0.013588062725388924, 0.058822008377012576, 0.017700239602809253, 0.03289741501936266, 0.0005363708970548259, 0.0035758059803655063, 0.365626161492373, 0.005363708970548259, 0.18701465277311596, 0.016985078406736152, 0.23135464692964824, 0.01412443362244375, 0.052385557612354666, 0.9994242067732598, 0.03725737934559807, 0.7490991271455855, 0.08975641387803171, 0.05983760925202114, 0.027096275887707688, 0.03697512647176778, 0.9997128280513164, 0.9995063028140404, 0.08893814448830477, 0.9106895420000374, 0.9992984754568437, 1.0000937729101183, 0.3992169004791493, 0.6006720226721599, 0.9994721039714527, 0.999668381432112, 1.0004449022772077, 0.9999563445545858, 1.0005056154871141, 1.0006728557274267, 0.09457708350614807, 0.20566054479402954, 0.13160490393544189, 0.06212197584071283, 0.5060097026738135, 1.000228225844565, 0.718633025191232, 0.15852199085100707, 0.05790145956905328, 0.040039826797108824, 0.024857438940956038, 0.9993672333660952, 0.0004920244820387559, 0.008241410074149162, 0.501495953318002, 0.30444014826148025, 0.00012300612050968897, 0.006765336628032894, 0.013776685497085167, 0.004920244820387559, 0.00602729990497476, 0.15351163839609186, 1.0002669447599626, 0.9993464568391826, 0.24559664007093218, 0.6506494102488404, 0.10366785938590262, 1.0001604748322235, 0.45135693053908726, 0.09287698477573397, 0.26602321883728325, 0.18953629019844354, 0.9999390418333363, 0.18103956816488548, 0.7945625491681085, 0.024809126007780603, 0.7935324220956432, 0.2065204606302664, 0.9997291902506324, 0.9992987748594302, 0.003106361148001762, 0.8625329454284892, 0.051254958942029076, 0.08283629728004699, 1.0003051694895788, 1.0004483455110185, 0.9988268506016754, 0.9991427214632577, 0.999872044471742, 0.8547412469593425, 0.14486296031751233, 0.11838498458696887, 0.001585513186432619, 0.0005285043954775396, 0.17017841534376776, 0.19968657742459706, 0.1975725598426869, 0.1360017977695535, 8.808406591292326e-05, 0.17581579556219484, 1.0001821012566614, 0.9996935202235189, 0.08481896583034938, 0.09502275119339892, 0.7423253851618548, 0.07780386339325282, 0.06237493628283334, 0.06129328998891137, 0.7762614902713305, 0.09698761768833623, 0.003244938881765896, 1.0001397575759052, 0.9999292989460016, 0.07456264776221679, 0.29825059104886714, 0.00453421506662129, 0.6216912658011858, 0.6751821778053017, 0.02526570164063143, 0.028602681102601623, 0.018115031364981028, 0.004131498381486901, 0.011758880008847334, 0.23692554179988343, 0.3043550128884161, 0.15346351354091967, 0.541837656747828, 0.9998939075682238, 0.05583698927546467, 0.03729185204318037, 0.09665644894435128, 0.0004031551572235716, 0.1077432157679995, 0.2156880091146108, 0.0637993036306302, 0.007055215251412503, 0.08274759602013806, 0.010179667719895183, 0.2639658391921335, 0.058558286586723775, 0.9997138477476495, 0.09777237094372755, 0.0007579253561529267, 0.043580707978793286, 0.06897120740991633, 0.18152312279862595, 0.012884731054599755, 0.07048705812222218, 0.07996112507413378, 0.05229684957455195, 0.10194096040256864, 0.03145390228034646, 0.08261386382066901, 0.17508075727132608, 7.49809257285445e-05, 0.04176437563079929, 0.2523857960022808, 0.02984240843996071, 0.00037490462864272253, 0.10962211341513206, 0.05203676245560988, 7.49809257285445e-05, 7.49809257285445e-05, 0.17837962230820736, 0.014321356814152, 0.13833980796916462, 0.04303905136818455, 0.010347367750539141, 0.001649580366027979, 0.028717694554032544, 0.0012746757373852567, 0.08315384663295586, 0.013496566631138011, 0.001049732960199623, 0.9989420956200167, 0.9997133935293874, 1.0001295625176507, 0.0006994257779442127, 0.00016140594875635675, 0.5059538473682597, 0.07037299365777155, 0.0022596832825889945, 0.0004842178462690703, 0.01974532773119431, 0.0003766138804314991, 0.0031743169922083497, 0.30968421368052984, 0.012589664002995828, 5.380198291878559e-05, 0.012858673917589755, 0.008016495454899053, 0.00043041586335028473, 0.00026900991459392795, 0.025179328005991656, 0.027654219220255793, 0.7185088098445355, 0.018718388523545404, 0.0004159641894121201, 0.0011092378384323202, 0.0013865472980404004, 0.024264577715707007, 0.038961979074935246, 0.004159641894121201, 0.005962153381573722, 0.04104180002199585, 0.14531015683463394, 0.037501544760043144, 0.6602384640852667, 0.005281907712682133, 0.2545879517512788, 0.003697335398877493, 0.03855792630257957, 1.0000529734869004, 0.014835363288164018, 0.2661093289814421, 0.22067602891143975, 0.4908032687834262, 0.007417681644082009, 1.0003538978654243, 0.09440944275759053, 0.9033267136578548, 1.0002002439302196, 0.9986593318226655, 0.9954128951564339, 0.004226806348859592, 1.0005783686725602, 0.9911187480681726, 0.007638680139253739, 1.0002218309728848, 1.000424551796851, 0.04058363431744236, 0.010742726731087683, 0.03222818019326305, 0.39509361644333585, 0.5204254283060255, 0.9993313257009953, 0.8412742650233839, 0.15890736117108362, 1.0000786944326143, 0.9991721092410912, 0.7195001720215463, 2.9627349064094967e-05, 0.1136505110098683, 0.0015406221513329383, 0.04556686286057806, 0.04343369372796322, 0.0005925469812818994, 0.07566824950969854, 0.3059603613393822, 0.005651977118338342, 0.07046131474195133, 0.6177610990343807, 0.9992748247036399, 1.0001244488433316, 0.005763801575053901, 0.19927635281620784, 0.11499256584984587, 0.03174815293800182, 0.02740167961910871, 0.0006614198528750379, 0.011433114599697083, 9.44885504107197e-05, 0.026740259766233673, 0.004724427520535985, 0.5426477450087632, 0.03439383234950197, 0.4704566294372806, 0.337175868920936, 0.19227889533206596, 0.9990036393539125, 0.22832715408208482, 0.00397474736313107, 0.6496503745739783, 0.11791750510622176, 1.0002398198365556, 0.9998536082357847, 0.01789361793321556, 0.18062881886637872, 0.1861903487645403, 0.6149117622184753, 0.9997246199506938, 0.06825684256542892, 0.9315556501067973, 1.0003940536962628, 0.005587213900305101, 0.0020317141455654915, 0.03362486910910888, 0.0054856281930268265, 0.0038602568765744335, 0.5671530037346069, 0.06257679568341713, 0.0011174427800610203, 0.030678883598038918, 0.027732898086968955, 0.026615455306907936, 0.23344395532547496, 0.0003047571218348237, 0.0012291861709126065, 0.029500468101902558, 0.502901035392711, 0.007293171280748132, 0.16979158307539471, 0.031303274485907716, 0.0011472404261850995, 0.10120299473847127, 0.00508063617310544, 0.0004916744683650426, 0.024993452141889666, 0.002294480852370199, 0.006965388301838103, 0.023026754268429494, 0.06416351812163806, 0.02851711916517247, 0.004421107922525872, 0.055632274691783896, 0.2284239093305034, 0.6311131559405683, 0.0799483682656762, 0.0057408070754761086, 0.17708181825122457, 0.18326422587096808, 0.0016192019956471075, 0.1915074360306261, 0.4405701429974357, 0.05325580193053336, 0.9459912185028951, 0.9998068427706992, 0.0005829236061076064, 0.00629557494596215, 0.48044563615388924, 0.004838265930693133, 0.002798033309316511, 0.014223335989025598, 0.06598695221138105, 5.8292360610760644e-05, 0.00448851176702857, 0.20530569407109897, 0.03975538993653876, 0.004896558291303894, 0.040396605903257124, 0.00816093048550649, 0.002156817342598144, 0.0006995083273291277, 0.023025482441250453, 0.0503645995676972, 0.04505999475211798, 0.00034975416366456386, 0.011276727814230333, 0.0008892043437744348, 0.3652608933949803, 0.028777886034881708, 0.012933881363991779, 0.00016167351704989724, 0.04401561501683452, 0.03795285812746337, 0.02384684376485984, 0.03783160298967595, 0.0023038476179610356, 0.0003233470340997945, 0.018269107426638388, 0.0014550616534490751, 0.053352260626466086, 0.05007837190620567, 0.03201135637587965, 0.00016167351704989724, 0.24065103012877204, 0.03831662354082564, 0.9990015680047438, 0.8780088070244099, 0.12197255753591582, 1.0006611863373822, 0.9998589797153121, 0.01090456615364353, 0.00420663038885874, 0.5744705150455053, 0.33840912040857785, 0.06077151474390102, 0.011190453655798979, 0.9994757510458661, 1.0004570912903032, 0.9997855570843939, 0.9978306446541031, 0.0021891852669023762, 1.000078237757743, 0.9098112245778773, 0.035394441772481196, 0.012765208508107972, 0.03655491527321829, 0.0011604735007370885, 0.0034814205022112655, 0.8757562510392329, 0.12318821945564658, 0.9998563326278611, 0.9994085972793942, 0.9990814018959364, 0.9627953852111497, 0.0371347356288752, 0.9997276306436992, 0.999629867405491, 0.9993537752163014, 0.9999435605173862, 0.06261753722935495, 0.9373938782245227, 0.42518429311683803, 0.5748098902427936, 0.9997075100683762, 1.000482330350364, 0.9999226248434588, 1.0000528239703834, 0.999478853296799, 1.0002328622937888, 0.9987227401207465, 1.0001801345375005, 0.9980553747841621, 0.9993107887559101, 0.04001238801640558, 0.10207884816783785, 0.05776066511554611, 0.07676917490811674, 0.003623168993611529, 0.00031505817335752425, 0.056710471204354365, 5.250969555958737e-05, 0.026359867170912862, 0.23267046102453165, 0.018535922532534343, 0.0644293964516137, 0.04384559579225546, 0.00010501939111917475, 0.00015752908667876212, 0.10990279280621637, 0.005881085902673786, 0.03817454867182002, 0.122295080958279, 0.0002100387822383495, 0.007898192130302498, 0.35389976276163115, 0.005923644097726873, 0.01473316608921812, 0.11330867940780122, 0.17315267362586245, 0.01291050636684062, 0.024454017941898117, 0.19654347339637368, 0.035693752896559364, 0.061210989009844355, 0.9993756774092644, 0.9999108833446929, 0.9990855903342587, 0.9995444140518599, 0.9996470622854867, 0.9346260910381984, 0.06424259162346818, 0.9990724193254296, 1.0000154227158318, 1.0000399504278645, 1.0005399255545622, 0.013823181835857705, 0.011999289788070924, 0.570494233684044, 0.007391562509451689, 0.011711306833157221, 0.017470965931431263, 0.04972505688176591, 0.09589832398626282, 0.010847357968416115, 0.005567670461664909, 0.00019198863660913477, 0.004607727278619234, 0.009791420467065874, 0.005663664779969476, 0.18469306841798766, 0.004681167994944537, 0.4973926755263291, 0.07304108157191239, 0.006538774342144751, 0.023925969751938746, 0.04057012262285266, 0.04450824807891711, 0.04190759919283681, 0.03952986306842054, 0.00014860850777601706, 0.0002229127616640256, 0.010997029575425263, 0.020433669819202346, 0.16941369886465946, 0.026675227145795063, 0.00034519453849950183, 0.0026234784925962137, 0.5066765436095687, 0.06986737459229916, 0.4204469478923932, 0.026359534065935004, 0.0028141851315944843, 0.13156315490204215, 0.0002345154276328737, 0.11561610582300673, 0.001266383309217518, 0.03414544626334641, 0.05182790950686508, 0.057690795197686925, 0.058863372335851295, 0.030064877822534405, 0.13278263512573307, 0.0022044450197490125, 0.0027203789605413347, 0.019324071236948792, 0.019089555809315917, 0.024905538414611187, 0.0007035462828986211, 0.27813529717258817, 0.00970893870400097, 1.0001939334385284, 0.08907252323788305, 0.3061736377964112, 0.5279073658566733, 0.07664869611959675, 0.9991753969718715, 0.8286757974488138, 0.03377685597937243, 0.1373930758258683, 1.000139013471924, 0.2521272272299951, 0.058235908463449955, 0.039737443422118796, 0.6488165331163189, 0.9999573207045181, 0.8330422332008637, 0.16650992006025542, 0.8969754035285697, 0.10310890892651565, 0.9992702127873856, 0.9990287769911503, 1.0001126453654967, 0.9985938651400107, 0.000885335884426067, 0.3815797661876349, 0.03718410714589482, 0.007304021046515053, 0.0004426679422130335, 0.003762677508810785, 0.08034423151166559, 0.29105417200506956, 0.01704271577520179, 0.07370421237847008, 0.0030986755954912344, 0.10292029656453029, 0.9991509738938362, 0.999302270747673, 1.0000423605701334, 0.09559643247528997, 0.008962165544558434, 0.7589958420069376, 0.00019915923432352076, 0.13602575704296468, 0.0073171082073816745, 0.01303775644224371, 0.054412677396711, 0.026208551215530722, 0.02394689958779457, 0.8749931032718049, 1.000045475657167, 0.37300624331728766, 0.04444783642961007, 0.3289139895791145, 0.0949405786136471, 0.1585898803808487, 0.9987241024482242, 0.0013361315043577985, 0.05282173213894496, 0.05157467606821102, 8.907543362385324e-05, 0.01380669221169725, 0.00017815086724770648, 0.004542847114816515, 0.0016033578052293582, 0.6656607154710552, 0.01710248325577982, 0.05549399514766056, 0.026811705520779824, 0.07241832753619268, 8.907543362385324e-05, 0.02013104799899083, 0.01630080435316514, 0.001820223335951503, 0.07811791816791867, 0.017671334886529177, 0.013120776546650418, 0.01183145168368477, 0.001820223335951503, 0.0003033705559919172, 0.7533449331669284, 0.000530898472985855, 0.0004550558339878758, 0.00424718778388684, 0.009025274040759536, 0.08517128359473075, 0.02244942114340187, 0.0001516852779959586, 0.014327584040222099, 0.026506030474410882, 0.25397075469697694, 0.009857377819672804, 0.002177792774113759, 0.003066102984607529, 0.04679388947536538, 0.004556171724790627, 0.03134875388000595, 0.34844684385820146, 0.019342238454299835, 0.014298928872141655, 0.025359823751193115, 0.0016619997486657634, 0.013152722148923887, 0.032036477913936615, 0.003954413195101299, 0.023182030977079354, 0.1250798086711389, 0.0008883102104937701, 1.0004510991584683, 0.07310846905828262, 0.021932540717484787, 0.03655423452914131, 0.7228599878137694, 0.10417956840805273, 0.041123513845283975, 0.9910274972053521, 0.009555361543302294, 0.9847930199791654, 0.015060555955501254, 0.9997412887790598, 0.9990666806759751, 0.0011483525065241094, 0.9999118408804865, 1.000057150526069, 0.8874839395444356, 0.11228686610515146, 0.009520662815307022, 0.0006731781788600925, 0.4919009121241961, 0.0005770098675943649, 0.011059355795558662, 0.01961833549820841, 0.22368749200408214, 0.000192336622531455, 0.009232157881509839, 0.0057700986759436496, 0.002981217649237552, 0.029331334936046886, 0.004039069073160555, 0.009712999437838477, 0.16627501017844284, 0.015098424868719217, 0.9996492958917297, 0.9997747469486467, 0.21697287222442294, 0.017502679539661378, 0.23900210681744502, 0.016597368528989236, 0.342207562034069, 0.16748253697434595, 0.9997659057993277, 0.9993126701921925, 0.10220018351462505, 0.2865713688500542, 0.6111468260422303], \"Term\": [\"2014\", \"3d\", \"802\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"a\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"access\", \"achievable\", \"achievable_rate\", \"activity\", \"activity\", \"ad\", \"ad_hoc\", \"additive\", \"adoption\", \"adversary\", \"affine\", \"against\", \"against\", \"against\", \"against\", \"against\", \"against\", \"against\", \"against\", \"against\", \"agent\", \"aggregation\", \"al\", \"algebra\", \"algebra\", \"algebraic\", \"algebraic\", \"algorithm\", \"algorithm\", \"algorithm\", \"alignment\", \"all\", \"all\", \"all\", \"all\", \"all\", \"all\", \"all\", \"all\", \"all\", \"all\", \"all\", \"all\", \"all\", \"allocation\", \"almost\", \"almost\", \"almost\", \"almost\", \"almost\", \"almost\", \"alpha\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"alternating\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analytics\", \"android\", \"annotation\", \"antenna\", \"any\", \"any\", \"any\", \"any\", \"any\", \"any\", \"any\", \"any\", \"any\", \"application\", \"application\", \"application\", \"application\", \"application\", \"application\", \"application\", \"application\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation_ratio\", \"architecture\", \"architecture\", \"architecture\", \"art\", \"art\", \"article\", \"article\", \"article\", \"artifact\", \"artificial\", \"artificial_intelligence\", \"arxiv\", \"aspect\", \"asynchronous\", \"asynchronous\", \"at\", \"at\", \"at\", \"at\", \"at\", \"at\", \"at\", \"at\", \"at\", \"at\", \"at\", \"at\", \"at\", \"at_most\", \"atom\", \"attachment\", \"attack\", \"attribute\", \"attribute\", \"attribute\", \"auction\", \"authentication\", \"automatic\", \"automatic\", \"automatic\", \"automatic\", \"automaton\", \"balancing\", \"band\", \"band\", \"bandit\", \"bandwidth\", \"bandwidth\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based_on\", \"based_on\", \"based_on\", \"based_on\", \"based_on\", \"based_on\", \"based_on\", \"based_on\", \"based_on\", \"based_on\", \"based_on\", \"based_on\", \"based_on\", \"based_on\", \"based_on\", \"based_on\", \"bayes\", \"bayesian\", \"bayesian_network\", \"be\", \"be\", \"be\", \"be\", \"be\", \"be\", \"be\", \"be\", \"be\", \"be\", \"be\", \"be\", \"be\", \"be\", \"be\", \"be\", \"be\", \"beamforming\", \"been\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"belief\", \"belief\", \"belief_propagation\", \"benchmark\", \"benchmark\", \"ber\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best_known\", \"beta\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"between\", \"big\", \"big_data\", \"bin\", \"binary\", \"binary\", \"binary\", \"binary\", \"biological\", \"biological\", \"bit\", \"bit\", \"bit\", \"bit\", \"blind\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"board\", \"boolean\", \"boolean\", \"boolean_function\", \"bound\", \"bounded\", \"bounded\", \"bounded\", \"bounded\", \"bounded\", \"bounding\", \"box\", \"bp\", \"brain\", \"branching\", \"broadcast\", \"broadcast\", \"broadcast_channel\", \"bs\", \"buffer\", \"buffer\", \"building\", \"business\", \"buyer\", \"c\", \"ca\", \"cache\", \"calculus\", \"calibration\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can\", \"can_be\", \"can_be\", \"can_be\", \"can_be\", \"can_be\", \"can_be\", \"can_be\", \"can_be\", \"can_be\", \"can_be\", \"can_be\", \"can_be\", \"can_be\", \"can_be\", \"can_be\", \"can_be\", \"cancellation\", \"cancer\", \"capacity\", \"capacity\", \"capacity_region\", \"card\", \"carlo\", \"cascade\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"causal\", \"causal\", \"causality\", \"cell\", \"cell\", \"cell\", \"cellular\", \"cellular\", \"cellular_automaton\", \"cellular_network\", \"centrality\", \"centralized\", \"chain\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"channel\", \"character\", \"check\", \"check\", \"chromatic\", \"circuit\", \"citation\", \"cite\", \"cite\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"classical\", \"classical\", \"classical\", \"classical\", \"classical\", \"classical\", \"classification\", \"classification\", \"classification\", \"classification\", \"classifier\", \"classifier\", \"client\", \"clique\", \"clock\", \"closed_form\", \"closure\", \"cloud\", \"cloud_computing\", \"clustering\", \"clustering\", \"code\", \"codebook\", \"coded\", \"coded\", \"coding\", \"coding\", \"coding\", \"coding_scheme\", \"cognitive\", \"cognitive_radio\", \"collaboration\", \"collaborative\", \"collective\", \"collision\", \"collision\", \"color\", \"coloring\", \"column\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"community\", \"community\", \"community\", \"community_structure\", \"company\", \"complete\", \"complete\", \"complete\", \"complete\", \"complete\", \"complete\", \"complete\", \"complete\", \"completeness\", \"completeness\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"compressed\", \"compressed_sensing\", \"compression\", \"compressive\", \"compressive_sensing\", \"computable\", \"computation\", \"computation\", \"computation\", \"computation\", \"computation\", \"computation\", \"computation\", \"computational\", \"computational\", \"computational\", \"computational\", \"computational\", \"computational\", \"computational\", \"computer\", \"computer\", \"computer\", \"computer\", \"computing\", \"computing\", \"computing\", \"computing\", \"computing\", \"computing\", \"computing\", \"concept\", \"concept\", \"concept\", \"concept\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"conditional\", \"congestion\", \"conjecture\", \"conjecture\", \"connected\", \"connected\", \"connectivity\", \"connectivity\", \"consensus\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constellation\", \"construction\", \"construction\", \"construction\", \"construction\", \"construction\", \"construction\", \"construction\", \"construction\", \"consumer\", \"consuming\", \"consumption\", \"content\", \"content\", \"content\", \"control\", \"control\", \"control\", \"control\", \"controllability\", \"controller\", \"convergence_rate\", \"convex\", \"convolutional\", \"cooperation\", \"cooperation\", \"cooperative\", \"cooperative\", \"copy\", \"core\", \"core\", \"core\", \"core\", \"corpus\", \"correcting\", \"correction\", \"correlated\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"could_be\", \"country\", \"coupling\", \"covering\", \"cpu\", \"cr\", \"cryptographic\", \"cryptography\", \"csi\", \"csit\", \"csp\", \"curvature\", \"curve\", \"curve\", \"customer\", \"cycle\", \"cycle\", \"cycle\", \"cycle\", \"cyclic\", \"d2d\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data_mining\", \"data_stream\", \"database\", \"dataset\", \"db\", \"decade\", \"decade\", \"decentralized\", \"decision\", \"decision\", \"decision\", \"decision\", \"decision\", \"decision\", \"decision_making\", \"decision_making\", \"decoder\", \"decoding\", \"decoding\", \"decomposition\", \"decomposition\", \"decomposition\", \"deep\", \"definition\", \"definition\", \"definition\", \"definition\", \"definition\", \"definition\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree_distribution\", \"degree_distribution\", \"delay\", \"delay\", \"delta\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"density\", \"density\", \"density\", \"density\", \"density\", \"derivative\", \"descent\", \"descriptor\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"detection\", \"detection\", \"detection\", \"detection\", \"developer\", \"development\", \"device\", \"device\", \"device\", \"device\", \"device\", \"diagram\", \"dictionary\", \"dictionary\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"differential\", \"dilemma\", \"dimension\", \"dimension\", \"dimensional\", \"dimensionality\", \"directed\", \"directed\", \"dirichlet\", \"discrete\", \"discrete\", \"discrete\", \"discrete\", \"discrete\", \"discriminative\", \"discus\", \"discus\", \"discus\", \"discus\", \"discus\", \"discus\", \"discus\", \"disease\", \"disjoint\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distortion\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"divergence\", \"diversity\", \"diversity\", \"diversity\", \"document\", \"document\", \"doe\", \"doe\", \"doe\", \"doe\", \"doe\", \"doe\", \"doe\", \"doe_not\", \"doe_not\", \"doe_not\", \"doe_not\", \"doe_not\", \"doe_not\", \"doe_not\", \"dof\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"dominated\", \"downlink\", \"duplex\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamical_system\", \"each\", \"each\", \"each\", \"each\", \"each\", \"each\", \"each\", \"each\", \"each\", \"each\", \"each\", \"each\", \"each\", \"eavesdropper\", \"economic\", \"edge\", \"edge\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effectiveness\", \"effectiveness\", \"effectiveness\", \"effectiveness\", \"efficiency\", \"efficiency\", \"efficiency\", \"efficiency\", \"efficiency\", \"efficiency\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"eigenvalue\", \"election\", \"electric\", \"electricity\", \"email\", \"embedded\", \"embedded\", \"embedded\", \"embedded\", \"embedding\", \"encoding\", \"encoding\", \"encoding\", \"encoding\", \"encoding\", \"encoding\", \"encoding\", \"encoding\", \"encryption\", \"energy\", \"energy\", \"energy_consumption\", \"energy_efficiency\", \"energy_efficient\", \"energy_harvesting\", \"engineering\", \"english\", \"entanglement\", \"entropy\", \"epidemic\", \"epsilon\", \"equation\", \"equilibrium\", \"equivalence\", \"er\", \"erasure\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error_correction\", \"error_probability\", \"error_rate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimation\", \"estimation\", \"estimation\", \"estimator\", \"estimator\", \"et\", \"et_al\", \"euclidean\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even_when\", \"even_when\", \"event\", \"event\", \"event\", \"event\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"every\", \"evolutionary\", \"existing\", \"existing\", \"existing\", \"existing\", \"existing\", \"existing\", \"existing\", \"existing\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"extracted\", \"extracted\", \"extraction\", \"extraction\", \"face\", \"face\", \"face\", \"face\", \"face_recognition\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factorization\", \"fading\", \"fading_channel\", \"fault\", \"fault\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature_selection\", \"feedback\", \"feedback\", \"feedback\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field\", \"file\", \"filter\", \"financial\", \"finite\", \"finite\", \"finite\", \"finite\", \"finite\", \"finite\", \"finite\", \"finite_automaton\", \"finite_field\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first_order\", \"first_order\", \"fixed_point\", \"flow\", \"flow\", \"flow\", \"flow\", \"force\", \"forest\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"form\", \"formula\", \"formula\", \"formula\", \"forward\", \"forward\", \"forward\", \"forwarding\", \"fourier\", \"fpga\", \"fractal\", \"fractional\", \"frame\", \"frame\", \"freedom\", \"freedom\", \"frequency\", \"frequency\", \"frequent\", \"frequent\", \"friend\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"from\", \"full_duplex\", \"full_duplex\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"fuzzy\", \"gain\", \"gain\", \"gain\", \"game\", \"gap\", \"gap\", \"gap\", \"gap_between\", \"gate\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian_noise\", \"gene\", \"genetic\", \"genetic_algorithm\", \"gesture\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"google\", \"gpu\", \"gradient\", \"grammar\", \"graph\", \"graphical_model\", \"grid\", \"grid\", \"grid\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha\", \"ha_been\", \"hamming\", \"hardness\", \"harvesting\", \"hash\", \"hashing\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have\", \"have_been\", \"health\", \"heuristic\", \"hidden\", \"hidden\", \"hidden\", \"hidden\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high_dimensional\", \"high_probability\", \"histogram\", \"hoc\", \"homology\", \"hop\", \"how\", \"how\", \"how\", \"how\", \"how\", \"how\", \"how\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"however\", \"hull\", \"human\", \"human\", \"human\", \"human\", \"human\", \"identity\", \"identity\", \"ieee\", \"if\", \"if\", \"if\", \"if\", \"if\", \"if\", \"image\", \"image_processing\", \"imaging\", \"impact\", \"impact\", \"impact\", \"impact\", \"impact\", \"impairment\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"indicator\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"inequality\", \"inequality\", \"infection\", \"inference\", \"inference\", \"infinite\", \"infinite\", \"infinite\", \"infinite\", \"infinite\", \"infinite\", \"influence\", \"influence\", \"influence\", \"influence\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information_theoretic\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instantaneous\", \"instruction\", \"integral\", \"integration\", \"intelligence\", \"intelligence\", \"intensity\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interconnected\", \"interface\", \"interference\", \"interference_alignment\", \"interference_channel\", \"internet\", \"internet\", \"internet\", \"interpolation\", \"intersection\", \"invariant\", \"inverse\", \"ip\", \"issue\", \"issue\", \"issue\", \"issue\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"it\", \"job\", \"join\", \"joint\", \"joint\", \"joint\", \"joint\", \"joint\", \"jointly\", \"jointly\", \"journal\", \"kernel\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"key\", \"knowledge\", \"knowledge\", \"knowledge\", \"knowledge\", \"knowledge\", \"knowledge\", \"knowledge\", \"knowledge\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"labeling\", \"lambda\", \"language\", \"language\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"lasso\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"latent\", \"latent_variable\", \"lattice\", \"law\", \"law\", \"law\", \"law\", \"law\", \"law\", \"law\", \"layer\", \"layer\", \"layer\", \"layer\", \"layout\", \"ldpc\", \"ldpc_code\", \"leader\", \"learner\", \"learning\", \"least_square\", \"length\", \"length\", \"length\", \"length\", \"let_be\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"library\", \"lifetime\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linguistic\", \"link\", \"link\", \"link\", \"link\", \"link\", \"load\", \"load\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"localization\", \"log\", \"log\", \"logarithmic\", \"logic\", \"logic\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low_density\", \"low_dimensional\", \"low_rank\", \"low_rank\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower_bound\", \"lp\", \"lte\", \"mac\", \"machine_learning\", \"manifold\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"market\", \"markov\", \"markov\", \"markov_chain\", \"massive\", \"massive\", \"massive_mimo\", \"matlab\", \"matrix\", \"max\", \"max\", \"maximum\", \"maximum\", \"maximum\", \"maximum\", \"maximum\", \"maximum\", \"maximum\", \"maximum\", \"maximum_degree\", \"maximum_likelihood\", \"md\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"measure\", \"measure\", \"measure\", \"measure\", \"measurement\", \"measurement\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"medical\", \"medium\", \"medium\", \"medium\", \"medium\", \"memory\", \"memory\", \"memory\", \"memory\", \"merging\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message_passing\", \"method\", \"method\", \"method\", \"method\", \"methodology\", \"migration\", \"mimo\", \"min\", \"minimax\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"mining\", \"mixing\", \"mixture\", \"ml\", \"mobile\", \"mobile_device\", \"mobility\", \"modal\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model_checking\", \"modularity\", \"modulation\", \"molecular\", \"monte\", \"monte_carlo\", \"most\", \"most\", \"most\", \"most\", \"most\", \"most\", \"most\", \"most\", \"most\", \"most\", \"motion\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple_access\", \"multiple_input\", \"multiple_output\", \"multiplex\", \"multiplication\", \"multiuser\", \"multivariate\", \"music\", \"mutual_information\", \"nash\", \"nash_equilibrium\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural\", \"natural_language\", \"navigation\", \"nearest\", \"nearest_neighbor\", \"network\", \"network\", \"neural\", \"neural_network\", \"neuron\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"new\", \"node\", \"node\", \"noise\", \"noise\", \"noise\", \"noise\", \"noisy\", \"noisy\", \"noisy\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non_uniform\", \"nonlinear\", \"nonlinear\", \"nonlinear\", \"nonparametric\", \"norm\", \"norm\", \"norm\", \"not\", \"not\", \"not\", \"not\", \"not\", \"not\", \"not\", \"not\", \"not\", \"not\", \"not\", \"notion\", \"notion\", \"notion\", \"notion\", \"notion\", \"notion\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"np\", \"np_complete\", \"np_hard\", \"nuclear\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"object\", \"object\", \"object_oriented\", \"objective_function\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observer\", \"ofdm\", \"omega\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"online\", \"online\", \"online\", \"online_social\", \"only\", \"only\", \"only\", \"only\", \"only\", \"only\", \"only\", \"only\", \"only\", \"only\", \"only\", \"only\", \"only\", \"only\", \"only\", \"ontology\", \"operator\", \"operator\", \"operator\", \"operator\", \"operator\", \"opinion\", \"optical\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimization\", \"optimization\", \"optimization_problem\", \"optimum\", \"optimum\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"or\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"organization\", \"organization\", \"organization\", \"oriented\", \"oriented\", \"oscillator\", \"our\", \"our\", \"our\", \"our\", \"our\", \"our\", \"our\", \"our\", \"our\", \"our\", \"our\", \"our\", \"our\", \"our\", \"our\", \"outage\", \"outage_probability\", \"outer\", \"outer_bound\", \"outlier\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"over\", \"overlapping\", \"overview\", \"packet\", \"packing\", \"page\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paper\", \"paradigm\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parity\", \"parity_check\", \"parsing\", \"particle\", \"partition\", \"partition\", \"party\", \"party\", \"passing\", \"passing\", \"passing\", \"password\", \"patch\", \"path\", \"path\", \"path\", \"patient\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"payment\", \"payoff\", \"pca\", \"peer\", \"penalty\", \"people\", \"people\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"perturbation\", \"phase\", \"phase\", \"phase\", \"phase_transition\", \"phi\", \"physic\", \"physic\", \"piecewise\", \"pilot\", \"pixel\", \"plan\", \"planar\", \"planar_graph\", \"plane\", \"plant\", \"platform\", \"platform\", \"platform\", \"player\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"poisson\", \"poisson\", \"polar\", \"polar_code\", \"polygon\", \"polynomial\", \"polynomial\", \"polynomial\", \"polynomial_time\", \"polynomial_time\", \"popularity\", \"population\", \"population\", \"posterior\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power\", \"power_allocation\", \"power_consumption\", \"power_law\", \"precoding\", \"predicting\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"preference\", \"preference\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"primary\", \"primary\", \"principal\", \"privacy\", \"privacy\", \"privacy\", \"private\", \"private\", \"probabilistic\", \"probabilistic\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability_distribution\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"process\", \"process\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processor\", \"program\", \"program\", \"programming\", \"programming\", \"programming\", \"programming\", \"programming\", \"project\", \"projection\", \"projection\", \"proof\", \"proof\", \"proof\", \"proof\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"propose\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"propositional\", \"protocol\", \"protocol\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"provider\", \"publication\", \"pulse\", \"pursuit\", \"python\", \"qos\", \"quantifier\", \"quantization\", \"quantum\", \"quasi\", \"quasi\", \"query\", \"query\", \"query\", \"queue\", \"radar\", \"radio\", \"radio\", \"radius\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random_variable\", \"randomness\", \"rank\", \"ranking\", \"ranking\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"ratio\", \"ratio\", \"ratio\", \"ratio\", \"ratio\", \"rational\", \"rayleigh\", \"reachability\", \"reaction\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real_time\", \"real_time\", \"real_world\", \"real_world\", \"real_world\", \"real_world\", \"reasoning\", \"receiver\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent\", \"recent_year\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recently\", \"recognition\", \"recommendation\", \"reconstructed\", \"reconstruction\", \"reconstruction\", \"recovery\", \"recursion\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"register\", \"registration\", \"regression\", \"regret\", \"regular\", \"regular\", \"regular\", \"regular\", \"regularization\", \"relation\", \"relation\", \"relation\", \"relation\", \"relation\", \"relational\", \"relational\", \"relational_database\", \"relaxation\", \"relaxation\", \"relay\", \"relaying\", \"relaying\", \"repair\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"research\", \"research\", \"research\", \"research\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource\", \"resource_allocation\", \"response\", \"response\", \"response\", \"response\", \"response\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"retrieval\", \"retrieval\", \"retrieval\", \"reverse\", \"review\", \"reward\", \"rewriting\", \"rf\", \"ring\", \"risk\", \"risk\", \"road\", \"robot\", \"rough\", \"round\", \"round\", \"rounding\", \"router\", \"routing\", \"routing_protocol\", \"row\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"running_time\", \"salient\", \"sample\", \"sample\", \"sample\", \"sample\", \"sampling\", \"sampling\", \"sampling\", \"sat\", \"sc\", \"scalar\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale_free\", \"scene\", \"scheduler\", \"scheduling\", \"schema\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"search\", \"search\", \"search\", \"secondary\", \"secrecy\", \"secret\", \"secure\", \"security\", \"segmentation\", \"selection\", \"selection\", \"selection\", \"selection\", \"semantic\", \"semantics\", \"semantics\", \"semidefinite\", \"sensing\", \"sensor\", \"sentence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"server\", \"service\", \"service\", \"session\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"shape\", \"shape\", \"shape\", \"shortest\", \"shortest_path\", \"should_be\", \"should_be\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show_that\", \"show_that\", \"show_that\", \"show_that\", \"show_that\", \"show_that\", \"show_that\", \"show_that\", \"show_that\", \"show_that\", \"show_that\", \"show_that\", \"shown\", \"shown\", \"shown\", \"shown\", \"shown\", \"shown\", \"shown\", \"shown\", \"shown\", \"shown\", \"shown\", \"shown\", \"shown\", \"shown\", \"shown\", \"shown\", \"side\", \"side\", \"side\", \"side\", \"side\", \"side\", \"side\", \"side_information\", \"signal\", \"signal\", \"signal_processing\", \"signature\", \"signature\", \"similarity\", \"similarity\", \"similarity\", \"similarity\", \"similarity\", \"similarity_measure\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulator\", \"single\", \"single\", \"single\", \"single\", \"single\", \"single\", \"single\", \"single\", \"single\", \"single\", \"single\", \"single\", \"single\", \"singular\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"sketch\", \"slot\", \"smart\", \"smart\", \"smooth\", \"snr\", \"social\", \"social\", \"social_medium\", \"social_network\", \"soft\", \"software\", \"software_development\", \"software_engineering\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"sorting\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source_coding\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"spanning\", \"spanning_tree\", \"sparse\", \"sparse\", \"sparse\", \"sparsity\", \"spatial\", \"spatial\", \"spatial\", \"spatial\", \"spatially\", \"specification\", \"specification\", \"specification\", \"spectral\", \"spectral\", \"spectrum\", \"speech\", \"speed\", \"speed\", \"speed\", \"speed\", \"sphere\", \"spin\", \"splitting\", \"spread\", \"spreading\", \"stability\", \"stability\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"station\", \"stationary\", \"statistic\", \"statistic\", \"statistic\", \"statistic\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"steiner\", \"stochastic\", \"storage\", \"storage\", \"storage\", \"storage\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"stream\", \"stream\", \"stream\", \"streaming\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"student\", \"studied\", \"studied\", \"studied\", \"studied\", \"studied\", \"studied\", \"studied\", \"studied\", \"studied\", \"studied\", \"studied\", \"studied\", \"studied\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"subgraph\", \"suboptimal\", \"subspace\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such\", \"such_a\", \"such_a\", \"such_a\", \"such_a\", \"such_a\", \"such_a\", \"such_a\", \"such_a\", \"such_a\", \"such_a\", \"such_a\", \"sufficient\", \"sufficient\", \"sufficient\", \"sufficient\", \"sufficient\", \"sufficient\", \"sufficient_condition\", \"sum\", \"sum\", \"sum\", \"sum\", \"sum\", \"sum_rate\", \"super\", \"super\", \"supervised\", \"support_vector\", \"survey\", \"survey\", \"svm\", \"switch\", \"switch\", \"switched\", \"switching\", \"symbol\", \"symbol\", \"symbol\", \"symbol\", \"symbol\", \"symmetry\", \"synchronization\", \"synchronization\", \"synchronous\", \"syntax\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"task\", \"task\", \"task\", \"task\", \"tcp\", \"team\", \"technique\", \"technique\", \"technique\", \"technique\", \"technique\", \"technique\", \"technique\", \"technique\", \"technique\", \"technique\", \"technique\", \"technique\", \"technology\", \"technology\", \"technology\", \"temperature\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"tensor\", \"termination\", \"test\", \"test\", \"test\", \"test\", \"testing\", \"text\", \"text\", \"texture\", \"than\", \"than\", \"than\", \"than\", \"than\", \"than\", \"than\", \"than\", \"than\", \"than\", \"than\", \"than\", \"than\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"their\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"there_exists\", \"there_exists\", \"thermal\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"these\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"this_paper\", \"thread\", \"throughput\", \"throughput\", \"tie\", \"tight\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time_series\", \"time_varying\", \"today\", \"tool\", \"tool\", \"topology\", \"towards\", \"towards\", \"towards\", \"towards\", \"towards\", \"towards\", \"trace\", \"trace\", \"tracking\", \"trade\", \"trade_off\", \"traffic\", \"traffic\", \"trajectory\", \"transaction\", \"transceiver\", \"transform\", \"translation\", \"translation\", \"transmission\", \"transmission\", \"transmit\", \"transmit_power\", \"transmitter\", \"tree\", \"triangle\", \"trust\", \"tuning\", \"turing\", \"turing_machine\", \"twitter\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"uncertain\", \"uncertainty\", \"undirected\", \"uniformly\", \"university\", \"unsupervised\", \"unsupervised\", \"uplink\", \"upper\", \"upper_bound\", \"urban\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"user\", \"user\", \"user\", \"user\", \"user\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"variability\", \"variable\", \"variable\", \"variable\", \"variable\", \"variational\", \"vector\", \"vector\", \"vector\", \"vehicle\", \"verification\", \"verification\", \"verification\", \"verification\", \"vertex\", \"video\", \"video\", \"visual\", \"visual\", \"visualization\", \"voltage\", \"volume\", \"voting\", \"wa\", \"wa\", \"wa\", \"wa\", \"wa\", \"wa\", \"wa\", \"wa\", \"wa\", \"wa\", \"wa\", \"wa\", \"walk\", \"wave\", \"wavelet\", \"we_consider\", \"we_consider\", \"we_consider\", \"we_consider\", \"we_consider\", \"we_propose\", \"we_propose\", \"we_propose\", \"we_propose\", \"we_propose\", \"we_propose\", \"web\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"well_studied\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"when\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"where\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"which\", \"white\", \"who\", \"who\", \"who\", \"who\", \"who\", \"who\", \"width\", \"width\", \"will\", \"will\", \"will_be\", \"window\", \"window\", \"wireless\", \"wireless_sensor\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"workflow\", \"working\", \"world\", \"world\", \"world\", \"world\", \"world\", \"world\", \"worst\", \"worst_case\", \"year\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el581402029456414248214264015\", ldavis_el581402029456414248214264015_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el581402029456414248214264015\", ldavis_el581402029456414248214264015_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el581402029456414248214264015\", ldavis_el581402029456414248214264015_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 203,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics = model_4.top_topics(corpus_2) #, num_words=20)\n",
    "model_4.num_topics\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence = sum([t[1] for t in top_topics]) / NUM_TOPICS\n",
    "print('Average topic coherence: %.4f.' % avg_topic_coherence)\n",
    "\n",
    "lda_display = pyLDAvis.gensim.prepare(model_4, corpus_2, dictionary_2, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QImizXrUWQlm"
   },
   "source": [
    "Like model 2, this model has 20 different topics that again seem to be related to each other because they are pretty close and overlapping one over the other. Even there is a topic (18) embedded in another topic (3), meaning that this is a subtopic of 3. But in this case, we did not remove  stops words from the corpus, and that is why you can see so many of them: \n",
    "- Topic 1: a\n",
    "- Topic 4: From\n",
    "- Topic 19: All words are have or have_been"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7PMClTrhP0GJ",
    "outputId": "7943ddba-a38b-4c47-e2f7-a25a51b12e05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.053*\"quantum\" + 0.028*\"security\" + 0.023*\"scheme\" + 0.021*\"attack\" + 0.021*\"key\"\n",
      "1: 0.037*\"game\" + 0.031*\"source\" + 0.027*\"strategy\" + 0.018*\"rate\" + 0.017*\"gaussian\"\n",
      "2: 0.024*\"system\" + 0.023*\"a\" + 0.017*\"it\" + 0.015*\"be\" + 0.012*\"paper\"\n",
      "3: 0.090*\"graph\" + 0.023*\"vertex\" + 0.023*\"edge\" + 0.020*\"set\" + 0.018*\"problem\"\n",
      "4: 0.102*\"data\" + 0.061*\"image\" + 0.029*\"feature\" + 0.025*\"object\" + 0.020*\"from\"\n",
      "5: 0.035*\"user\" + 0.020*\"agent\" + 0.017*\"service\" + 0.016*\"information\" + 0.015*\"web\"\n",
      "6: 0.034*\"function\" + 0.032*\"matrix\" + 0.025*\"linear\" + 0.014*\"space\" + 0.013*\"dimensional\"\n",
      "7: 0.045*\"signal\" + 0.029*\"sensor\" + 0.026*\"system\" + 0.025*\"measurement\" + 0.021*\"noise\"\n",
      "8: 0.027*\"language\" + 0.020*\"relay\" + 0.020*\"program\" + 0.016*\"word\" + 0.011*\"programming\"\n",
      "9: 0.024*\"be\" + 0.020*\"can\" + 0.018*\"problem\" + 0.016*\"show\" + 0.016*\"number\"\n",
      "10: 0.055*\"model\" + 0.026*\"distribution\" + 0.018*\"probability\" + 0.016*\"measure\" + 0.015*\"information\"\n",
      "11: 0.025*\"time\" + 0.020*\"model\" + 0.018*\"dynamic\" + 0.010*\"simulation\" + 0.009*\"high\"\n",
      "12: 0.022*\"logic\" + 0.017*\"cloud\" + 0.016*\"theory\" + 0.016*\"proof\" + 0.014*\"automaton\"\n",
      "13: 0.130*\"bound\" + 0.051*\"lower\" + 0.034*\"lower_bound\" + 0.032*\"upper\" + 0.024*\"al\"\n",
      "14: 0.048*\"network\" + 0.025*\"wireless\" + 0.020*\"node\" + 0.019*\"power\" + 0.017*\"mobile\"\n",
      "15: 0.062*\"channel\" + 0.022*\"user\" + 0.021*\"interference\" + 0.020*\"capacity\" + 0.019*\"rate\"\n",
      "16: 0.113*\"code\" + 0.039*\"error\" + 0.024*\"decoding\" + 0.019*\"block\" + 0.018*\"binary\"\n",
      "17: 0.142*\"network\" + 0.032*\"node\" + 0.019*\"social\" + 0.014*\"structure\" + 0.013*\"community\"\n",
      "18: 0.041*\"algorithm\" + 0.034*\"method\" + 0.027*\"based\" + 0.019*\"problem\" + 0.018*\"approach\"\n",
      "19: 0.118*\"been\" + 0.082*\"ha\" + 0.057*\"ha_been\" + 0.055*\"have\" + 0.045*\"have_been\"\n"
     ]
    }
   ],
   "source": [
    "for i,topic in model_4.show_topics(formatted=True, num_topics=20, num_words=5):\n",
    "    print(str(i)+\": \"+ topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmBxUfU8YpqK"
   },
   "source": [
    "Conclusion and deeper insights are in the PDF file submitted with this code"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "FIT5212 - Assig1 - Final.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
